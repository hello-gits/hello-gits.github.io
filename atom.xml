<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>hnbian</title>
  
  <subtitle>今天阳光很暖</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.hnbian.cn/"/>
  <updated>2023-07-19T15:52:09.087Z</updated>
  <id>https://www.hnbian.cn/</id>
  
  <author>
    <name>hnbian</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>华为云编译好的 arm 架构Ambari 下载地址</title>
    <link href="https://www.hnbian.cn/posts/68f1de24.html"/>
    <id>https://www.hnbian.cn/posts/68f1de24.html</id>
    <published>2023-07-18T08:01:44.000Z</published>
    <updated>2023-07-19T15:52:09.087Z</updated>
    
    <content type="html"><![CDATA[<p>华为鲲鹏 aarch64 版本 Ambari HDP 下载地址</p><p><a href="https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/" target="_blank" rel="noopener">https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/</a></p><p>ambari<br><a href="https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/ambari/2.x/updates/2.7.3.0/ambari-2.7.3.0-centos7.tar.gz" target="_blank" rel="noopener">https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/ambari/2.x/updates/2.7.3.0/ambari-2.7.3.0-centos7.tar.gz</a></p><p>HDP<br><a href="https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/HDP/3.x/updates/3.1.0.0/HDP-3.1.0.0-centos7-rpm.tar.gz" target="_blank" rel="noopener">https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/HDP/3.x/updates/3.1.0.0/HDP-3.1.0.0-centos7-rpm.tar.gz</a></p><p>HDP-GPL<br><a href="https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/HDP-GPL/3.x/updates/3.1.0.0/HDP-GPL-3.1.0.0-centos7-gpl.tar.gz" target="_blank" rel="noopener">https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/HDP-GPL/3.x/updates/3.1.0.0/HDP-GPL-3.1.0.0-centos7-gpl.tar.gz</a></p><p>HDP-UTILS<br><a href="https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/HDP-UTILS-1.1.0.22/repos/HDP-UTILS-1.1.0.22-centos7.tar.gz" target="_blank" rel="noopener">https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/HDP-UTILS-1.1.0.22/repos/HDP-UTILS-1.1.0.22-centos7.tar.gz</a></p><h2 id="CPU架构概述"><a href="#CPU架构概述" class="headerlink" title="CPU架构概述"></a>CPU架构概述</h2><p>CPU（中央处理器）是计算机的核心部件，它负责执行计算机程序中的指令。CPU架构，也被称为计算机架构，是指CPU的设计和实现方式，包括指令集、数据类型、寻址方式、内存架构等。</p><p>CPU架构主要有以下几种：</p><ol><li><strong>x86架构</strong>：由Intel公司开发，广泛应用于个人电脑和服务器中。x86架构的特点是有丰富的指令集和强大的计算能力。</li><li><strong>ARM架构</strong>：主要应用于移动设备和嵌入式系统，特点是低功耗。ARM架构的CPU通常有较小的体积和较低的功耗，适合用于手机、平板电脑等便携设备。</li><li><strong>MIPS架构</strong>：主要应用于嵌入式系统和超级计算机。MIPS架构的CPU有简洁的指令集和高效的流水线设计。</li><li><strong>Power架构</strong>：由IBM公司开发，主要应用于高性能计算和大型服务器。Power架构的CPU有高效的指令调度和执行机制，适合用于大型服务器和超级计算机。</li><li><strong>SPARC架构</strong>：由Sun公司开发，主要应用于高端服务器。SPARC架构的CPU有高度可扩展的设计，适合用于大规模并行处理和高性能计算。</li></ol><p>以上就是CPU架构的基本概述，每种架构都有其特点和适用场景。在选择CPU架构时，需要根据实际的应用需求和性能要求来决定。</p><h2 id="ARM-架构介绍"><a href="#ARM-架构介绍" class="headerlink" title="ARM 架构介绍"></a>ARM 架构介绍</h2><p>ARM架构是一种处理器架构，由ARM公司设计并许可给其他公司使用。ARM架构的主要特点是其高效的能耗比，即在相同的功耗下，ARM架构可以提供更高的性能。这使得ARM架构非常适合用于移动设备和嵌入式系统。</p><p>ARM架构有多个版本，其中最新的版本是ARMv8。在ARMv8架构中，引入了一个新的64位执行状态，被称为AArch64。在AArch64状态下，处理器可以使用64位的寄存器和虚拟地址空间，从而提供更高的性能和更大的内存寻址能力。</p><p>因此，AArch64是ARM架构的一部分，是ARMv8架构中的64位执行状态。当我们说一个处理器支持AArch64，意味着这个处理器支持ARMv8架构，并且可以在64位状态下运行。</p><h2 id="华为鲲鹏系统介绍"><a href="#华为鲲鹏系统介绍" class="headerlink" title="华为鲲鹏系统介绍"></a>华为鲲鹏系统介绍</h2><p>华为鲲鹏是华为公司自主研发的一款基于ARM架构的高性能服务器处理器。鲲鹏处理器采用了先进的7纳米工艺，具有高性能、低功耗的特点，适用于数据中心、大数据处理、边缘计算等场景。</p><p>华为鲲鹏处理器的主要特点包括：</p><ol><li><strong>高性能</strong>：鲲鹏处理器采用了先进的7纳米工艺和高效的ARMv8架构，能够提供高性能的计算能力。</li><li><strong>低功耗</strong>：由于采用了ARM架构，鲲鹏处理器在提供高性能的同时，功耗较低。</li><li><strong>安全可靠</strong>：鲲鹏处理器内置了多种安全技术，包括硬件隔离、安全启动、安全加密等，可以提供高级别的安全保护。</li><li><strong>丰富的生态</strong>：华为与众多合作伙伴共同构建了基于鲲鹏处理器的软件和硬件生态，支持多种操作系统和应用软件，满足各种业务需求。</li></ol><p>鲲鹏处理器是华为在芯片领域的重要产品，是华为构建全场景智能解决方案的重要组成部分。</p><h3 id="鲲鹏作为服务器系统，-为什么能够用在arm架构上呢？"><a href="#鲲鹏作为服务器系统，-为什么能够用在arm架构上呢？" class="headerlink" title="鲲鹏作为服务器系统， 为什么能够用在arm架构上呢？"></a>鲲鹏作为服务器系统， 为什么能够用在arm架构上呢？</h3><p>华为鲲鹏服务器系统使用的是鲲鹏处理器，这款处理器基于ARM架构。ARM架构的主要优势在于其高效的能耗比，即在相同的功耗下，ARM架构可以提供更高的性能。这使得ARM架构非常适合用于数据中心和云计算环境，因为在这些环境中，能源效率是一个非常重要的考虑因素。</p><p>此外，ARM架构的另一个优势是其灵活的许可模式。ARM公司并不直接生产处理器，而是设计处理器架构，并将架构许可给其他公司。这使得像华为这样的公司可以基于ARM架构设计自己的处理器，以满足特定的性能和功耗需求。</p><p>因此，华为鲲鹏服务器系统能够使用ARM架构，主要是因为ARM架构的高能效和灵活的许可模式。这使得华为可以设计出性能强大、能耗低的鲲鹏处理器，从而提供高效的服务器系统。</p><h2 id="Apache-Ambari介绍"><a href="#Apache-Ambari介绍" class="headerlink" title="Apache Ambari介绍"></a>Apache Ambari介绍</h2><p>Apache Ambari是Apache 基金会的一个开源项目，主要用于管理、监控和部署Apache Hadoop集群。Ambari提供了一个用户友好的Web界面，使得Hadoop集群的管理变得更加简单和直观。</p><p>以下是Ambari的主要功能：</p><ol><li><strong>集群管理</strong>：Ambari可以帮助用户轻松地安装、配置和管理Hadoop集群。用户可以通过Ambari的Web界面进行集群的部署、扩展和升级。</li><li><strong>监控和报警</strong>：Ambari提供了丰富的监控功能，包括CPU使用率、磁盘使用率、网络流量等多种指标。同时，Ambari还支持基于阈值的报警，当某个指标超过预设的阈值时，Ambari会发送报警通知。</li><li><strong>服务管理</strong>：Ambari支持多种Hadoop生态系统的组件，包括HDFS、MapReduce、YARN、Hive、HBase等。用户可以通过Ambari的Web界面进行这些服务的启动、停止和配置。</li><li><strong>安全性</strong>：Ambari支持Kerberos认证，可以提供强大的安全性。同时，Ambari还支持集群的权限管理，可以对不同的用户赋予不同的权限。</li></ol><p>总的来说，Apache Ambari是一个强大的Hadoop集群管理工具，它可以大大简化Hadoop集群的管理工作，提高运维效率。</p><h2 id="对于AArch64架构的Ambari的必要性"><a href="#对于AArch64架构的Ambari的必要性" class="headerlink" title="对于AArch64架构的Ambari的必要性"></a>对于AArch64架构的Ambari的必要性</h2><p>随着ARM架构在服务器市场的逐渐崛起，基于ARM架构的服务器因其高性能和低功耗特性，越来越受到企业的青睐。然而，由于大部分的软件都是为x86架构设计的，对ARM架构的支持并不完善，这在一定程度上限制了ARM架构在大数据处理等领域的应用。</p><p>Apache Ambari作为Hadoop集群的管理工具，如果能够支持AArch64架构，将大大方便基于ARM架构服务器的大数据处理。支持AArch64架构的Ambari不仅可以在基于ARM的服务器上运行，充分利用ARM架构的性能优势，还可以丰富ARM架构的软件生态，使得更多的大数据工具和应用可以在ARM服务器上运行。</p><p>因此，开发和推广支持AArch64架构的Ambari具有重要的实际意义。这不仅可以帮助企业更好地利用ARM架构的优势，提高大数据处理的效率和性能，也有助于推动ARM架构在大数据处理等领域的广泛应用。</p><h2 id="开源鲲鹏AArch64版本Ambari的意义"><a href="#开源鲲鹏AArch64版本Ambari的意义" class="headerlink" title="开源鲲鹏AArch64版本Ambari的意义"></a>开源鲲鹏AArch64版本Ambari的意义</h2><p>华为开源鲲鹏AArch64版本的Ambari HDP，对于推动ARM架构在大数据处理领域的应用具有重要意义。</p><p>首先，这将进一步丰富ARM架构的软件生态，为基于ARM架构的大数据处理提供更多的选择。Ambari HDP是一个广泛使用的Hadoop集群管理工具，华为鲲鹏AArch64版本的Ambari HDP的开源，将使得更多基于ARM架构的服务器可以更方便地部署和管理Hadoop集群。</p><p>其次，这也将推动Hadoop生态的发展，使得Hadoop能够更好地适应多样化的硬件环境。随着ARM架构在服务器市场的崛起，Hadoop需要能够在各种不同的硬件架构上运行，华为鲲鹏AArch64版本的Ambari HDP的开源，将有助于实现这一目标。</p><p>最后，这也是华为对开源社区的一次重要贡献，将有助于提升华为在全球开源社区的影响力。通过开源鲲鹏AArch64版本的Ambari HDP，华为可以与全球的开发者共享其在大数据处理和ARM架构方面的技术成果，推动全球的技术交流和合作。</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;华为鲲鹏 aarch64 版本 Ambari HDP 下载地址&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mirrors.huaweicloud.com/kunpeng/yum/el/7/bigdata/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;
      
    
    </summary>
    
    
      <category term="ambari" scheme="https://www.hnbian.cn/categories/ambari/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="ambari" scheme="https://www.hnbian.cn/tags/ambari/"/>
    
      <category term="hdfs" scheme="https://www.hnbian.cn/tags/hdfs/"/>
    
  </entry>
  
  <entry>
    <title>对 kafka 中的消息进行 Avro 序列化</title>
    <link href="https://www.hnbian.cn/posts/bfc215f5.html"/>
    <id>https://www.hnbian.cn/posts/bfc215f5.html</id>
    <published>2023-07-01T16:40:13.000Z</published>
    <updated>2023-07-03T15:41:35.394Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Avro-介绍"><a href="#1-Avro-介绍" class="headerlink" title="1. Avro 介绍"></a>1. Avro 介绍</h2><p>Avro 是一种数据序列化系统，由 Apache Foundation 开发并维护。它提供了丰富的数据结构类型，并且可以用于编码结构化数据。Avro 主要被用于 Apache Hadoop 这样的大数据处理系统中，它可以提供高效而且紧凑的序列化以及反序列化操作。</p><p>Avro 的特点包括：</p><ol><li><strong>基于 JSON 的模式定义</strong>：Avro 使用 JSON 格式定义数据结构，这使得模式易于阅读和编写。</li><li><strong>编码与解码时模式独立</strong>：Avro 的一大特点是模式用于编码和解码，这允许对数据结构进行演化而无需修改所有读取数据的应用。这个特性对于长期存储大量数据的系统来说非常有用。</li><li><strong>高效</strong>：Avro 的二进制编码非常紧凑，这使得 Avro 特别适合于大数据场景。它没有其他一些序列化系统的大量开销，比如标记字段名。</li><li><strong>支持多种语言</strong>：Avro 支持许多编程语言，包括 Java, C, C++, C#, Python 和 Ruby 等。</li></ol><p>总的来说，Avro 是一个强大的工具，可以有效地处理复杂的数据结构，并且它的设计理念适应于大数据处理，能有效地处理大规模数据的序列化和反序列化操作。</p><h2 id="2-Avro-结合-kafka"><a href="#2-Avro-结合-kafka" class="headerlink" title="2. Avro 结合 kafka"></a>2. Avro 结合 kafka</h2><p>在分布式数据流处理系统中，Avro 和 Kafka 的结合带来了很多重要的好处：</p><ol><li><strong>模式演化：</strong> Avro 支持模式演化，这就意味着你可以在不中断服务的情况下修改你的数据模式。这对于实时数据流处理系统来说非常重要，因为它允许系统在不停机的情况下进行修改和升级。</li><li><strong>高效的序列化：</strong> Avro 提供了一种高效且紧凑的二进制数据格式，这对于 Kafka 这样的数据流处理系统来说非常重要。它可以帮助减少网络传输的开销和存储的需求。</li><li><strong>跨语言支持：</strong> Avro 支持多种编程语言，这对于在多种语言编写的服务中使用 Kafka 的系统来说非常有利。这就意味着，无论服务是用 Java、Python 还是其他语言编写的，都可以通过 Avro 和 Kafka 进行有效的数据交换。</li><li><strong>明确的数据契约：</strong> 由于 Avro 使用明确定义的模式，它提供了一种明确的数据契约，可以在生产者和消费者之间提供清晰的数据期望。这有助于提高系统的健壮性，并减少因数据不一致而产生的问题。</li></ol><p>因此，结合 Avro 和 Kafka 可以帮助构建一个健壮、高效且易于维护和演化的实时数据流处理系统。</p><h2 id="3-Avro-json-schema"><a href="#3-Avro-json-schema" class="headerlink" title="3. Avro json schema"></a>3. Avro json schema</h2><p><font color="red">UserBehavior.avsc，  注意 : 创建的文件后缀名一定要是 avsc</font></p><pre class=" language-json"><code class="language-json">这里是一个 avro 的json描述， 请你进行解读<span class="token punctuation">{</span>    <span class="token property">"namespace"</span><span class="token operator">:</span> <span class="token string">"com.hnbian"</span><span class="token punctuation">,</span> // 要生成  类的路径    <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"record"</span><span class="token punctuation">,</span> // 类型 avro 使用 record    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"UserBehavior"</span><span class="token punctuation">,</span> // 会自动生成对应的类名 UserBehavior.java    <span class="token property">"fields"</span><span class="token operator">:</span> <span class="token punctuation">[</span> // 要指定的字段        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"userId"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"itemId"</span><span class="token punctuation">,</span>  <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"categoryId"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"int"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"behavior"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span></code></pre><p>添加 avro json schema 以后，编译 （mvn compile） 项目后将会自动在 <code>com.hnbian</code> 包下生成 UserBehavior.java 类</p><p>类型说明：</p><ul><li>除了上面写的类型， avro 还支持其他多种类型</li></ul><ol><li><strong>基本类型（Primitive Types）：</strong><ul><li><code>null</code>: 表示空值或无值</li><li><code>boolean</code>: 表示布尔值，true 或 false</li><li><code>int</code>: 表示32位整数</li><li><code>long</code>: 表示64位整数</li><li><code>float</code>: 表示单精度浮点数</li><li><code>double</code>: 表示双精度浮点数</li><li><code>bytes</code>: 表示字节序列</li><li><code>string</code>: 表示 Unicode 字符序列</li></ul></li><li><strong>复合类型（Complex Types）：</strong><ul><li><code>record</code>: 表示一组带名字（名称必须唯一）的字段，每个字段都有自己的类型。这与大多数编程语言中的类或结构体类似。</li><li><code>enum</code>: 表示一组有名字的值，类似于 Java 的枚举。</li><li><code>array</code>: 表示一种类型的连续值。</li><li><code>map</code>: 表示一组键值对，其中键是 string 类型，值可以是任意类型。</li><li><code>union</code>: 表示可以是多种类型的值，例如，一个字段的类型可以是 int 或 null。</li><li><code>fixed</code>: 表示一个具有固定数目的字节的值。</li></ul></li></ol><p>以下是一个增加了其他类型的简单示例：</p><pre class=" language-json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"namespace"</span><span class="token operator">:</span> <span class="token string">"com.hnbian"</span><span class="token punctuation">,</span>    <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"record"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"UserBehavior"</span><span class="token punctuation">,</span>    <span class="token property">"fields"</span><span class="token operator">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"userId"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"itemId"</span><span class="token punctuation">,</span>  <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"categoryId"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"int"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"behavior"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"timestamp"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"isPurchased"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"boolean"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  // 新添加的 boolean 类型字段        <span class="token punctuation">{</span><span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"itemPrice"</span><span class="token punctuation">,</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"double"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  // 新添加的 double 类型字段        <span class="token punctuation">{</span>            <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"comments"</span><span class="token punctuation">,</span>             <span class="token property">"type"</span><span class="token operator">:</span> <span class="token punctuation">{</span> // 新添加的 array 类型字段                <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"array"</span><span class="token punctuation">,</span>                 <span class="token property">"items"</span><span class="token operator">:</span> <span class="token string">"string"</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span>            <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"attributes"</span><span class="token punctuation">,</span>             <span class="token property">"type"</span><span class="token operator">:</span> <span class="token punctuation">{</span> // 新添加的 map 类型字段                <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"map"</span><span class="token punctuation">,</span>                 <span class="token property">"values"</span><span class="token operator">:</span> <span class="token string">"string"</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">{</span>            <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"rating"</span><span class="token punctuation">,</span>             <span class="token property">"type"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"null"</span><span class="token punctuation">,</span> <span class="token string">"int"</span><span class="token punctuation">]</span> // 新添加的 union 类型字段        <span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span></code></pre><h2 id="4-maven-依赖与编译"><a href="#4-maven-依赖与编译" class="headerlink" title="4. maven 依赖与编译"></a>4. maven 依赖与编译</h2><h3 id="4-1-maven-依赖"><a href="#4-1-maven-依赖" class="headerlink" title="4.1 maven 依赖"></a>4.1 maven 依赖</h3><pre class=" language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">"</span></span>         <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>         <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">></span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.example<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>Kafka_avro_consumer<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0-SNAPSHOT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.source</span><span class="token punctuation">></span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.source</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.target</span><span class="token punctuation">></span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.target</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project.build.sourceEncoding</span><span class="token punctuation">></span></span>UTF-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project.build.sourceEncoding</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-streaming-java_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-clients_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-avro<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.avro<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>avro<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.10.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!--使用插件可以在 Maven 构建生命周期中生成 Avro schemas 的 Java 类--></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.avro<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>avro-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.8.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>generate-sources<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>schema<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>sourceDirectory</span><span class="token punctuation">></span></span>${project.basedir}/src/main/avro/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>sourceDirectory</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>outputDirectory</span><span class="token punctuation">></span></span>${project.basedir}/src/main/java/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>outputDirectory</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">></span></span></code></pre><h3 id="4-2-进行项目编译"><a href="#4-2-进行项目编译" class="headerlink" title="4.2 进行项目编译"></a>4.2 进行项目编译</h3><p>编译后的 UserBehavior 类</p><h2 id="5-测试数据"><a href="#5-测试数据" class="headerlink" title="5. 测试数据"></a>5. 测试数据</h2><pre class=" language-bash"><code class="language-bash">543462,1715,1464116,pv,1511658000662867,2244074,1575622,pv,1511658000561558,3611281,965809,pv,1511658000894923,3076029,1879194,pv,1511658000834377,4541270,3738615,pv,1511658000315321,942195,4339722,pv,1511658000625915,1162383,570735,pv,1511658000</code></pre><h2 id="6-自定义序列化类"><a href="#6-自定义序列化类" class="headerlink" title="6. 自定义序列化类"></a>6. 自定义序列化类</h2><p>包含定义序列化与反序列化两个方法</p><pre class=" language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>hnbian<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BinaryDecoder<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BinaryEncoder<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DecoderFactory<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>io<span class="token punctuation">.</span>EncoderFactory<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>specific<span class="token punctuation">.</span>SpecificDatumReader<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>specific<span class="token punctuation">.</span>SpecificDatumWriter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>Deserializer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>Serializer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>ByteArrayInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>ByteArrayOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * 自定义序列化和反序列化 */</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SimpleAvroSchemaJava</span> <span class="token keyword">implements</span> <span class="token class-name">Serializer</span><span class="token operator">&lt;</span>UserBehavior<span class="token operator">></span><span class="token punctuation">,</span> Deserializer<span class="token operator">&lt;</span>UserBehavior<span class="token operator">></span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> map<span class="token punctuation">,</span> <span class="token keyword">boolean</span> b<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">serialize</span><span class="token punctuation">(</span>String s<span class="token punctuation">,</span> UserBehavior userBehavior<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 创建序列化执行器</span>        SpecificDatumWriter<span class="token operator">&lt;</span>UserBehavior<span class="token operator">></span> writer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SpecificDatumWriter</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>userBehavior<span class="token punctuation">.</span><span class="token function">getSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建一个流 用存储序列化后的二进制文件</span>        ByteArrayOutputStream out <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ByteArrayOutputStream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建二进制编码器</span>        BinaryEncoder encoder <span class="token operator">=</span> EncoderFactory<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">directBinaryEncoder</span><span class="token punctuation">(</span>out<span class="token punctuation">,</span> null<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 数据入都流中</span>            writer<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>userBehavior<span class="token punctuation">,</span> encoder<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> out<span class="token punctuation">.</span><span class="token function">toByteArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> UserBehavior <span class="token function">deserialize</span><span class="token punctuation">(</span>String s<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> bytes<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 用来保存结果数据</span>        UserBehavior userBehavior <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">UserBehavior</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建输入流用来读取二进制文件</span>        ByteArrayInputStream arrayInputStream <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ByteArrayInputStream</span><span class="token punctuation">(</span>bytes<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建输入序列化执行器</span>        SpecificDatumReader<span class="token operator">&lt;</span>UserBehavior<span class="token operator">></span> stockSpecificDatumReader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SpecificDatumReader</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>userBehavior<span class="token punctuation">.</span><span class="token function">getSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建二进制解码器</span>        BinaryDecoder binaryDecoder <span class="token operator">=</span> DecoderFactory<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">directBinaryDecoder</span><span class="token punctuation">(</span>arrayInputStream<span class="token punctuation">,</span> null<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 数据读取</span>            userBehavior <span class="token operator">=</span> stockSpecificDatumReader<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>null<span class="token punctuation">,</span> binaryDecoder<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 结果返回</span>        <span class="token keyword">return</span> userBehavior<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h2 id="7-编写-kafka-生产者类"><a href="#7-编写-kafka-生产者类" class="headerlink" title="7. 编写 kafka 生产者类"></a>7. 编写 kafka 生产者类</h2><pre class=" language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>hnbian<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>KafkaProducer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BufferedReader<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FileReader<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** * 生产测试数据 **/</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">UserBehaviorProducerKafka</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> InterruptedException <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 从 CSV 文件中获取数据</span>        List<span class="token operator">&lt;</span>UserBehavior<span class="token operator">></span> data <span class="token operator">=</span> <span class="token function">getData</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建 Kafka 配置文件</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"node1:6667,node:6667,node3:6667"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// value.serializer 需要指定自定义的序列化类，否则将无效</span>        props<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> SimpleAvroSchemaJava<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建 Kafka 生产者</span>        KafkaProducer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> UserBehavior<span class="token operator">></span> userBehaviorProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 遍历数据</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>UserBehavior userBehavior <span class="token operator">:</span> data<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 创建 Kafka 消息</span>            ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> UserBehavior<span class="token operator">></span> producerRecord                 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">,</span> userBehavior<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 将消息发送到 Kafka</span>            userBehaviorProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">)</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"数据写入成功"</span> <span class="token operator">+</span> data<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 每次发送数据后，线程休眠1秒</span>            Thread<span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 从 CSV 文件中读取数据的函数</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> List<span class="token operator">&lt;</span>UserBehavior<span class="token operator">></span> <span class="token function">getData</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 初始化一个存放 UserBehavior 对象的列表</span>        ArrayList<span class="token operator">&lt;</span>UserBehavior<span class="token operator">></span> userBehaviors <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 创建一个从 CSV 文件读取数据的 BufferedReader 对象</span>            BufferedReader br <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileReader</span><span class="token punctuation">(</span><span class="token string">"UserBehavior.csv"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            String line<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 读取文件中的每一行数据</span>            <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>line <span class="token operator">=</span> br<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 使用逗号分隔每一行数据，得到一个字符串数组</span>                String<span class="token punctuation">[</span><span class="token punctuation">]</span> split <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">// 使用字符串数组中的数据创建一个 UserBehavior 对象，并添加到列表中</span>                userBehaviors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>                    <span class="token keyword">new</span> <span class="token class-name">UserBehavior</span><span class="token punctuation">(</span>                        Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>split<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token punctuation">,</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>split<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>split<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token punctuation">,</span> split<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>                        <span class="token punctuation">,</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>split<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 打印出任何异常信息</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 返回包含所有 UserBehavior 对象的列表</span>        <span class="token keyword">return</span> userBehaviors<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h2 id="8-编写kafka-消费者类"><a href="#8-编写kafka-消费者类" class="headerlink" title="8. 编写kafka 消费者类"></a>8. 编写kafka 消费者类</h2><pre class=" language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>hnbian<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecords<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>KafkaConsumer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Collections<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/** 消费数据 测试数据 **/</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">UserBehaviorConsumer</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        Properties prop <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        prop<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"node1:6667,node2:6667,node3:6667"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        prop<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"UserBehavior"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        prop<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 设置反序列化类为自定义的avro反序列化类</span>        prop<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> SimpleAvroSchemaJava<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> UserBehavior<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>prop<span class="token punctuation">)</span><span class="token punctuation">;</span>        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Collections<span class="token punctuation">.</span><span class="token function">singletonList</span><span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> UserBehavior<span class="token operator">></span> poll <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> UserBehavior<span class="token operator">></span> stringStockConsumerRecord <span class="token operator">:</span> poll<span class="token punctuation">)</span> <span class="token punctuation">{</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>stringStockConsumerRecord<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h2 id="9-异常"><a href="#9-异常" class="headerlink" title="9. 异常"></a>9. 异常</h2><p>在反序列化时可能遇见一些异常信息如下：</p><pre class=" language-java"><code class="language-java">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token operator">:</span> Failed to deserialize Avro record<span class="token punctuation">.</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>formats<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>AvroRowDeserializationSchema<span class="token punctuation">.</span><span class="token function">deserialize</span><span class="token punctuation">(</span>AvroRowDeserializationSchema<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">170</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>formats<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>AvroRowDeserializationSchema<span class="token punctuation">.</span><span class="token function">deserialize</span><span class="token punctuation">(</span>AvroRowDeserializationSchema<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">78</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span>KeyedDeserializationSchemaWrapper<span class="token punctuation">.</span><span class="token function">deserialize</span><span class="token punctuation">(</span>KeyedDeserializationSchemaWrapper<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">44</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>internal<span class="token punctuation">.</span>Kafka09Fetcher<span class="token punctuation">.</span><span class="token function">runFetchLoop</span><span class="token punctuation">(</span>Kafka09Fetcher<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">142</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>FlinkKafkaConsumerBase<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>FlinkKafkaConsumerBase<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">738</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>StreamSource<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>StreamSource<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">94</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>StreamSource<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>StreamSource<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">58</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>SourceStreamTask<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>SourceStreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">99</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">300</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">704</span><span class="token punctuation">)</span>    at java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>Thread<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Thread<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">748</span><span class="token punctuation">)</span>Caused by<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>AvroRuntimeException<span class="token operator">:</span> Malformed data<span class="token punctuation">.</span> Length is negative<span class="token operator">:</span> <span class="token operator">-</span><span class="token number">53</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BinaryDecoder<span class="token punctuation">.</span><span class="token function">doReadBytes</span><span class="token punctuation">(</span>BinaryDecoder<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">336</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BinaryDecoder<span class="token punctuation">.</span><span class="token function">readString</span><span class="token punctuation">(</span>BinaryDecoder<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">263</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>io<span class="token punctuation">.</span>ResolvingDecoder<span class="token punctuation">.</span><span class="token function">readString</span><span class="token punctuation">(</span>ResolvingDecoder<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">201</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">readString</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">422</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">readString</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">414</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">readWithoutConversion</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">181</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">153</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">readField</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">232</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>specific<span class="token punctuation">.</span>SpecificDatumReader<span class="token punctuation">.</span><span class="token function">readField</span><span class="token punctuation">(</span>SpecificDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">122</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">readRecord</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">222</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">readWithoutConversion</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">175</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">153</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericDatumReader<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>GenericDatumReader<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">145</span><span class="token punctuation">)</span>    at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>formats<span class="token punctuation">.</span>avro<span class="token punctuation">.</span>AvroRowDeserializationSchema<span class="token punctuation">.</span><span class="token function">deserialize</span><span class="token punctuation">(</span>AvroRowDeserializationSchema<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">167</span><span class="token punctuation">)</span></code></pre><p>请检查你的序列化与反序列化时使用的 schema 是否一致， 包括字段名称， 字段类型， 字段顺序等等。</p><h2 id="10-其他"><a href="#10-其他" class="headerlink" title="10. 其他"></a>10. 其他</h2><p>在进行反序列化时还有一种情况， 如果Kafka中的数据字段比较多， 但是我们不需要那么多的数据， 只需要其中的某些字段， avro 在进行反序列化的定义schema 的时候可以按字段顺序反序列化部分字段， 但是中间不能有空出来的字段</p><p>如序列化 schema 如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">{</span>    <span class="token string">"namespace"</span><span class="token keyword">:</span> <span class="token string">"com.hnbian"</span>,    <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"record"</span>,    <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"UserBehavior"</span>,    <span class="token string">"fields"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"userId"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"itemId"</span>,  <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"categoryId"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"int"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"behavior"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"timestamp"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span></code></pre><p>在反序列化时， 可以定义</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">{</span>    <span class="token string">"namespace"</span><span class="token keyword">:</span> <span class="token string">"com.hnbian"</span>,    <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"record"</span>,    <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"UserBehavior"</span>,    <span class="token string">"fields"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"userId"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"itemId"</span>,  <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"categoryId"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"int"</span><span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true"># 减掉了最后两个字段</span></code></pre><p>但是不能如下定义：</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">{</span>    <span class="token string">"namespace"</span><span class="token keyword">:</span> <span class="token string">"com.hnbian"</span>,    <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"record"</span>,    <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"UserBehavior"</span>,    <span class="token string">"fields"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"userId"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"itemId"</span>,  <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"behavior"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span>,        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"timestamp"</span>, <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"long"</span><span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true"># 减去了中间的 categoryId 字段</span><span class="token comment" spellcheck="true"># 这时也会报反序列化异常 Failed to deserialize Avro record.</span></code></pre><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-Avro-介绍&quot;&gt;&lt;a href=&quot;#1-Avro-介绍&quot; class=&quot;headerlink&quot; title=&quot;1. Avro 介绍&quot;&gt;&lt;/a&gt;1. Avro 介绍&lt;/h2&gt;&lt;p&gt;Avro 是一种数据序列化系统，由 Apache Foundation 开发并维
      
    
    </summary>
    
    
      <category term="kafka" scheme="https://www.hnbian.cn/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://www.hnbian.cn/tags/kafka/"/>
    
      <category term="avro" scheme="https://www.hnbian.cn/tags/avro/"/>
    
  </entry>
  
  <entry>
    <title>DolphinScheduler 部署文档</title>
    <link href="https://www.hnbian.cn/posts/723b083d.html"/>
    <id>https://www.hnbian.cn/posts/723b083d.html</id>
    <published>2023-03-20T12:30:37.000Z</published>
    <updated>2023-04-30T15:42:28.969Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本文档部署了最新的 3.14 版本， 官网上的部署文档有些错误， 本文中进行了修复</li></ul><h2 id="1-DolphinScheduler-简介"><a href="#1-DolphinScheduler-简介" class="headerlink" title="1. DolphinScheduler 简介"></a>1. DolphinScheduler 简介</h2><p><code>Apache DolphinScheduler</code> 官网地址： <a href="https://dolphinscheduler.apache.org/zh-cn" target="_blank" rel="noopener">https://dolphinscheduler.apache.org/zh-cn</a></p><p><code>Apache DolphinScheduler</code> 是一个分布式易扩展的可视化工作流任务调度，平台致力于解决数据处理流程中错综复杂的依赖关系，适用于企业级场景，提供了一个可视化操作任务、工作流和全生命周期数据处理过程的解决方案。</p><p><code>Apache DolphinScheduler</code> 旨在解决复杂的大数据任务依赖关系，并为应用程序提供数据和各种 OPS 编排中的关系。 解决数据研发ETL依赖错综复杂，无法监控任务健康状态的问题。 DolphinScheduler 以 <code>DAG</code>（ Directed Acyclic Graph，DAG ，有向无环图）流式方式组装任务，可以及时监控任务的执行状态，支持重试、指定节点恢复失败、暂停、恢复、终止任务等操作。</p><blockquote><p>有向无环图是一种图形数据结构，其中的边具有方向性，且不存在任何从一个顶点出发经过若干边回到该顶点的环路。换句话说，它是一个有向图，其中所有的边都有一个方向，并且图中不存在回路。</p><p>在有向无环图中，每个顶点表示一个实体，每个有向边表示实体之间的关系或依赖。由于不存在回路，有向无环图可以表示具有线性、分支或其他更复杂拓扑结构的依赖关系。在计算机科学和数据处理领域，有向无环图具有广泛应用，如编译器的优化、任务调度、数据流编程、贝叶斯网络等。</p></blockquote><h2 id="2-特性"><a href="#2-特性" class="headerlink" title="2. 特性"></a>2. 特性</h2><p>简单易用：DAG监控界面，所有流程定义都是可视化，通过拖拽任务完成定制DAG，通过API方式与第三方系统集成。一<br>键部署</p><p>高可靠性：去中心化的多Master和多Worker股务对尊架构避免单Master压力过大，另外采用任务缓冲队列来道免过载</p><p>高扩展性：支持自定义任务类型，调度器使用分布式调度，调度能力随集群线性增长，Master和和Worker支持动态上下线</p><p>丰富的使用场景：支持多租户，支持暂停恢复提作。景密贴合大数据生态，提供Spark，Hive。M/R，Python，shell等近20种任务类型</p><ul><li><p>简单易用</p><p><strong>可视化 DAG</strong>: 用户友好的，通过拖拽定义工作流的，运行时控制工具</p><p><strong>模块化操作</strong>: 模块化有助于轻松定制和维护。</p></li><li><p>丰富的使用场景</p><p><strong>支持多种任务类型</strong>: 支持Shell、MR、Spark、SQL 等20余种任务类型，支持跨语言，易于扩展</p><p><strong>丰富的工作流操作</strong>: 工作流程可以定时、暂停、恢复和停止，便于维护和控制全局和本地参数。</p></li><li><p><strong>高可靠性（High Reliability）</strong>: 去中心化设计，确保稳定性。 原生 HA 任务队列支持，提供过载容错能力。 DolphinScheduler 能提供高度稳健的环境。</p></li><li><p><strong>高扩展性（High Scalability）</strong>: 支持多租户和在线资源管理。支持每天10万个数据任务的稳定运行。</p></li></ul><h2 id="3-架构概览"><a href="#3-架构概览" class="headerlink" title="3. 架构概览"></a>3. 架构概览</h2><h3 id="3-1-架构图"><a href="#3-1-架构图" class="headerlink" title="3.1 架构图"></a>3.1 架构图</h3><p><img src="https://images.hnbian.cn/202304191049086.jpg?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="DolphinScheduler 架构图"></p><h3 id="3-2-组件说明"><a href="#3-2-组件说明" class="headerlink" title="3.2 组件说明"></a>3.2 组件说明</h3><h4 id="3-2-1-MasterServer"><a href="#3-2-1-MasterServer" class="headerlink" title="3.2.1  MasterServer"></a>3.2.1  <strong>MasterServer</strong></h4><p>MasterServer 采用分布式无中心设计理念，MasterServer 主要负责 DAG 任务切分、任务提交监控，并同时监听其它 MasterServer 和WorkerServer 的健康状态。 MasterServer 服务启动时向 Zookeeper 注册临时节点，通过监听 Zookeeper 临时节点变化来进行容错处理。 MasterServer 基于 netty 提供监听服务。</p><p>该服务内主要包含: </p><ul><li><strong>DistributedQuartz ：</strong>分布式调度组件，主要负责定时任务的启停操作，当 quartz 调起任务后，Master 内部会有线程池具体负责处理任务的后续操作；</li><li><strong>MasterSchedulerService ：</strong>是一个扫描线程，定时扫描数据库中的 <code>t_ds_command</code> 表，根据不同的命令类型进行不同的业务操作；</li><li><strong>WorkflowExecuteRunnable ：</strong>主要是负责DAG任务切分、任务提交监控、各种不同事件类型的逻辑处理；</li><li><strong>TaskExecuteRunnable ：</strong>主要负责任务的处理和持久化，并生成任务事件提交到工作流的事件队列；</li><li><strong>EventExecuteService ：</strong>主要负责工作流实例的事件队列的轮询；</li><li><strong>StateWheelExecuteThread ：</strong>主要负责工作流和任务超时、任务重试、任务依赖的轮询，并生成对应的工作流或任务事件提交到工作流的事件队列；</li><li><strong>FailoverExecuteThread ：</strong>主要负责 Master 容错和 Worker 容错的相关逻辑；</li></ul><h4 id="3-2-2-WorkerServer"><a href="#3-2-2-WorkerServer" class="headerlink" title="3.2.2 WorkerServer"></a>3.2.2 <strong>WorkerServer</strong></h4><p>WorkerServer 也采用分布式无中心设计理念，WorkerServer 主要负责任务的执行和提供日志服务。 WorkerServe r服务启动时向Zookeeper 注册临时节点，并维持心跳。 WorkerServer 基于 netty 提供监听服务。</p><p>该服务包含：</p><ul><li><strong>WorkerManagerThread ：</strong>主要负责任务队列的提交，不断从任务队列中领取任务，提交到线程池处理；</li><li><strong>TaskExecuteThread ：</strong>主要负责任务执行的流程，根据不同的任务类型进行任务的实际处理；</li><li><strong>RetryReportTaskStatusThread ：</strong>主要负责定时轮询向Master汇报任务的状态，直到 Master 回复状态的 ack，避免任务状态丢失；</li></ul><h4 id="3-2-3-LoggerServer"><a href="#3-2-3-LoggerServer" class="headerlink" title="3.2.3 LoggerServer"></a>3.2.3 LoggerServer</h4><p>LoggerServer 提供任务执行日志查看功能，可以实现直接在UI页面查看任务日志，而无需再去服务器中查看</p><h4 id="3-2-4-ZooKeeper"><a href="#3-2-4-ZooKeeper" class="headerlink" title="3.2.4 ZooKeeper"></a>3.2.4 <strong>ZooKeeper</strong></h4><p>ZooKeeper 服务，系统中的 MasterServer 和 WorkerServer 节点都通过 ZooKeeper 来进行集群管理和容错。另外系统还基于ZooKeeper 进行事件监听和分布式锁。 之前的版本曾经基于 Redis 实现过队列，不过希望 DolphinScheduler 依赖到的组件尽量地少，所以最后还是去掉了 Redis 实现。</p><h4 id="3-2-5-AlertServer"><a href="#3-2-5-AlertServer" class="headerlink" title="3.2.5 AlertServer"></a>3.2.5 <strong>AlertServer</strong></h4><p>提供告警服务，通过不同告警插件的方式实现Email、微信、短信等告警手段。</p><h4 id="3-2-6-ApiServer"><a href="#3-2-6-ApiServer" class="headerlink" title="3.2.6 ApiServer"></a>3.2.6 <strong>ApiServer</strong></h4><p>API接口层，主要负责处理前端UI层的请求。该服务统一提供RESTful api向外部提供请求服务。</p><h4 id="3-2-7-UI"><a href="#3-2-7-UI" class="headerlink" title="3.2.7 UI"></a>3.2.7 <strong>UI</strong></h4><p>系统的前端页面，提供系统的各种可视化操作界面。</p><h2 id="4-名词解释"><a href="#4-名词解释" class="headerlink" title="4. 名词解释"></a>4. 名词解释</h2><p>在对 Apache DolphinScheduler 了解之前，我们先来认识一下调度系统常用的名词</p><table><thead><tr><th>名词</th><th>释义</th></tr></thead><tbody><tr><td>DAG</td><td>全称 Directed Acyclic Graph，简称 DAG。工作流中的 Task 任务以有向无环图的形式组装起来，从入度为零的节点进行拓扑遍历，直到无后继节点为止。举例如下图：</td></tr><tr><td>流程定义</td><td>通过拖拽任务节点并建立任务节点的关联所形成的可视化 <strong>DAG</strong></td></tr><tr><td>流程实例</td><td>流程实例是流程定义的实例化，可以通过手动启动或定时调度生成。每运行一次流程定义，产生一个流程实例</td></tr><tr><td>任务实例</td><td>任务实例是流程定义中任务节点的实例化，标识着某个具体的任务</td></tr><tr><td>任务类型</td><td>目前支持有 SHELL、SQL、SUB_PROCESS(子流程)、PROCEDURE、MR、SPARK、PYTHON、DEPENDENT(依赖)，同时计划支持动态插件扩展，注意：其中 <strong>SUB_PROCESS</strong>类型的任务需要关联另外一个流程定义，被关联的流程定义是可以单独启动执行的</td></tr><tr><td>调度方式</td><td>系统支持基于 cron 表达式的定时调度和手动调度。命令类型支持：启动工作流、从当前节点开始执行、恢复被容错的工作流、恢复暂停流程、从失败节点开始执行、补数、定时、重跑、暂停、停止、恢复等待线程。 其中 <strong>恢复被容错的工作流</strong> 和 <strong>恢复等待线程</strong> 两种命令类型是由调度内部控制使用，外部无法调用</td></tr><tr><td>定时调度</td><td>系统采用 <strong>quartz</strong> 分布式调度器，并同时支持cron表达式可视化的生成</td></tr><tr><td>依赖</td><td>系统不单单支持 <strong>DAG</strong> 简单的前驱和后继节点之间的依赖，同时还提供<strong>任务依赖</strong>节点，支持<strong>流程间的自定义任务依赖</strong></td></tr><tr><td>优先级</td><td>支持流程实例和任务实例的优先级，如果流程实例和任务实例的优先级不设置，则默认是先进先出</td></tr><tr><td>邮件告警</td><td>支持 <strong>SQL任务</strong> 查询结果邮件发送，流程实例运行结果邮件告警及容错告警通知</td></tr><tr><td>失败策略</td><td>对于并行运行的任务，如果有任务失败，提供两种失败策略处理方式，<strong>继续</strong>是指不管并行运行任务的状态，直到流程失败结束。<strong>结束</strong>是指一旦发现失败任务，则同时Kill掉正在运行的并行任务，流程失败结束</td></tr><tr><td>补数</td><td>补历史数据，支持<strong>区间并行</strong>和<strong>串行</strong>两种补数方式，其日期选择方式包括<strong>日期范围</strong>和<strong>日期枚举</strong>两种</td></tr></tbody></table><p><img src="https://images.hnbian.cn/202304191049087.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="glossary"></p><h2 id="5-部署前的准备"><a href="#5-部署前的准备" class="headerlink" title="5. 部署前的准备"></a>5. 部署前的准备</h2><h3 id="5-1-环境建议"><a href="#5-1-环境建议" class="headerlink" title="5.1 环境建议"></a>5.1 环境建议</h3><h4 id="5-1-1-软硬件环境建议配置"><a href="#5-1-1-软硬件环境建议配置" class="headerlink" title="5.1.1 软硬件环境建议配置"></a>5.1.1 软硬件环境建议配置</h4><p>DolphinScheduler 作为一款开源分布式工作流任务调度系统，可以很好地部署和运行在 Intel 架构服务器及主流虚拟化环境下，并支持主流的 Linux 操作系统环境</p><h4 id="5-1-2-Linux-操作系统版本要求"><a href="#5-1-2-Linux-操作系统版本要求" class="headerlink" title="5.1.2 Linux 操作系统版本要求"></a>5.1.2 Linux 操作系统版本要求</h4><table><thead><tr><th align="left">操作系统</th><th align="center">版本</th></tr></thead><tbody><tr><td align="left">Red Hat Enterprise Linux</td><td align="center">7.0 及以上</td></tr><tr><td align="left">CentOS</td><td align="center">7.0 及以上</td></tr><tr><td align="left">Oracle Enterprise Linux</td><td align="center">7.0 及以上</td></tr><tr><td align="left">Ubuntu LTS</td><td align="center">16.04 及以上</td></tr></tbody></table><blockquote><p><strong>注意：</strong> 以上 Linux 操作系统可运行在物理服务器以及 VMware、KVM、XEN 主流虚拟化环境上</p></blockquote><h4 id="5-1-3-服务器建议配置"><a href="#5-1-3-服务器建议配置" class="headerlink" title="5.1.3 服务器建议配置"></a>5.1.3 服务器建议配置</h4><p>DolphinScheduler 支持运行在 Intel x86-64 架构的 64 位通用硬件服务器平台。对生产环境的服务器硬件配置有以下建议：</p><h4 id="5-1-4-生产环境"><a href="#5-1-4-生产环境" class="headerlink" title="5.1.4 生产环境"></a>5.1.4 生产环境</h4><table><thead><tr><th><strong>CPU</strong></th><th><strong>内存</strong></th><th><strong>硬盘类型</strong></th><th><strong>网络</strong></th><th><strong>实例数量</strong></th></tr></thead><tbody><tr><td>4核+</td><td>8 GB+</td><td>SAS</td><td>千兆网卡</td><td>1+</td></tr></tbody></table><blockquote><p><strong>注意：</strong></p><ul><li>以上建议配置为部署 DolphinScheduler 的最低配置，生产环境强烈推荐使用更高的配置</li><li>硬盘大小配置建议 50GB+ ，系统盘和数据盘分开</li></ul></blockquote><h4 id="5-1-5-网络要求"><a href="#5-1-5-网络要求" class="headerlink" title="5.1.5 网络要求"></a>5.1.5 网络要求</h4><p>DolphinScheduler正常运行提供如下的网络端口配置：</p><table><thead><tr><th>组件</th><th>默认端口</th><th>说明</th></tr></thead><tbody><tr><td>MasterServer</td><td>5678</td><td>非通信端口，只需本机端口不冲突即可</td></tr><tr><td>WorkerServer</td><td>1234</td><td>非通信端口，只需本机端口不冲突即可</td></tr><tr><td>ApiApplicationServer</td><td>12345</td><td>提供后端通信端口</td></tr></tbody></table><blockquote><p><strong>注意：</strong></p><ul><li>MasterServer 和 WorkerServer 不需要开启网络间通信，只需本机端口不冲突即可</li><li>管理员可根据实际环境中 DolphinScheduler 组件部署方案，在网络侧和主机侧开放相关端口</li></ul></blockquote><h4 id="5-1-6-客户端-Web-浏览器要求"><a href="#5-1-6-客户端-Web-浏览器要求" class="headerlink" title="5.1.6 客户端 Web 浏览器要求"></a>5.1.6 客户端 Web 浏览器要求</h4><p>DolphinScheduler 推荐 Chrome 以及使用 Chromium 内核的较新版本浏览器访问前端可视化操作界面</p><h3 id="5-2-部署模式介绍"><a href="#5-2-部署模式介绍" class="headerlink" title="5.2 部署模式介绍"></a>5.2 部署模式介绍</h3><p>DolphinScheduler 支持多种部署模式,包括 单机模式(Standalone)、伪集群模式(Pseudo-Cluster)、集群模式(Cluster) 等。</p><ul><li>单模式</li></ul><p>单机模式(standalone)模式下，所有服务均集中于一个 StandaloneServer 进程中，并且其中内置了注册中心 Zookeeper 和数据库 H2。只需配置 JDK 环境，就可一键启动DolphinScheduler，快速体验其功能。</p><ul><li>伪集群模式</li></ul><p>伪集群模式+(Pseudo-Cluster)是在单台机器部署 DolphinScheduler 各项服务，该模式下master、worker、apiserver、logger server 等服务都只在同一台机器上。Zookeeper 和 数据库需单独安装并进行相应配置。</p><blockquote><p>单机模式跟为集群模式的区别， 单机模式所有服务在一个进程中， 为集群不同服务在不同进程中</p></blockquote><ul><li>集群模式</li></ul><p>集群模式(Cluster)与伪集群模式的区别就是在多台机器部署 DolphinScheduler 各项服务，并且 Master、Worker 等服务可配置多个。</p><h3 id="5-3-安装jdk"><a href="#5-3-安装jdk" class="headerlink" title="5.3 安装jdk"></a>5.3 安装jdk</h3><p>JDK：下载 JDK1.8+，如果你是集群安装Dolphin Scheduler，那么在集群的每一个节点都需要安装JDK，安装并配置 <code>JAVA_HOME</code> 环境变量，并将其下的 <code>bin</code> 目录追加到 <code>PATH</code> 环境变量中。并确保 <code>JAVA_HOME</code> 正确配置，如果你的环境中已存在，可以跳过这步。</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 解压安装包</span><span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span> <span class="token function">tar</span> -zxvf jdk-8u191-linux-x64.tar.gzroot@node2 opt<span class="token punctuation">]</span> <span class="token function">cd</span> jdk1.8.0_191/<span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span> ll总用量 25976drwxr-xr-x. 2 10 143     4096 10月  6 2018 bin-r--r--r--. 1 10 143     3244 10月  6 2018 COPYRIGHTdrwxr-xr-x. 3 10 143      132 10月  6 2018 include-rw-r--r--. 1 10 143  5207154 9月  12 2018 javafx-src.zipdrwxr-xr-x. 5 10 143      185 10月  6 2018 jredrwxr-xr-x. 5 10 143      245 10月  6 2018 lib-r--r--r--. 1 10 143       40 10月  6 2018 LICENSEdrwxr-xr-x. 4 10 143       47 10月  6 2018 <span class="token function">man</span>-r--r--r--. 1 10 143      159 10月  6 2018 README.html-rw-r--r--. 1 10 143      424 10月  6 2018 release-rw-r--r--. 1 10 143 21101479 10月  6 2018 src.zip-rw-r--r--. 1 10 143   108062 9月  12 2018 THIRDPARTYLICENSEREADME-JAVAFX.txt-r--r--r--. 1 10 143   155003 10月  6 2018 THIRDPARTYLICENSEREADME.txt<span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span> <span class="token function">pwd</span>/opt/jdk1.8.0_191<span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 配置环境变量</span><span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span> vim /etc/profile<span class="token comment" spellcheck="true"># 文件底部增加如下配置</span><span class="token comment" spellcheck="true"># jdk 安装地址</span><span class="token function">export</span> JAVA_HOME<span class="token operator">=</span>/opt/jdk1.8.0_191PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$JAVA_HOME</span>/bin<span class="token comment" spellcheck="true"># 刷新配置文件</span><span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span> <span class="token function">source</span> /etc/profile<span class="token comment" spellcheck="true"># 打印Java home</span><span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span> <span class="token keyword">echo</span> <span class="token variable">$JAVA_HOME</span>/opt/jdk1.8.0_191<span class="token comment" spellcheck="true"># 查看 java 版本进行验证</span><span class="token punctuation">[</span>root@node2 jdk1.8.0_191<span class="token punctuation">]</span> java -version<span class="token comment" spellcheck="true"># 打印除下列 java 版本信息 说明jdk安装成功</span>java version <span class="token string">"1.8.0_191"</span>Java<span class="token punctuation">(</span>TM<span class="token punctuation">)</span> SE Runtime Environment <span class="token punctuation">(</span>build 1.8.0_191-b12<span class="token punctuation">)</span>Java HotSpot<span class="token punctuation">(</span>TM<span class="token punctuation">)</span> 64-Bit Server VM <span class="token punctuation">(</span>build 25.191-b12, mixed mode<span class="token punctuation">)</span></code></pre><h3 id="5-4-下载安装文件"><a href="#5-4-下载安装文件" class="headerlink" title="5.4 下载安装文件"></a>5.4 下载安装文件</h3><p>可以根据你的需要选择不同的版本，下载安装包地址如下：</p><p>安装包下载地址： <a href="https://dolphinscheduler.apache.org/zh-cn/download" target="_blank" rel="noopener">https://dolphinscheduler.apache.org/zh-cn/download</a></p><p>把下载好的安装包上传到服务器上</p><h2 id="6-单节点安装"><a href="#6-单节点安装" class="headerlink" title="6. 单节点安装"></a>6. 单节点安装</h2><p>Standalone 仅适用于 DolphinScheduler 的快速体验.</p><p>如果你是新手，想要体验 DolphinScheduler 的功能，推荐使用Standalone方式体检。如果你想体验更完整的功能，或者更大的任务量，推荐使用 伪集群部署 。如果你是在生产中使用，推荐使用集群部署 或者 kubernetes</p><p>注意： 单节点模式仅建议 20 个以下工作流使用，因为其采用内存式的 H2 Database, Zookeeper Testing Server，任务过多可能导致不稳定，并且如果重启或者停止 standalone-server 会导致内存中数据库里的数据清空。 如果您要连接外部数据库，比如 mysql 或者postgresql，请看<a href="https://dolphinscheduler.apache.org/zh-cn/docs/3.1.4/guide/installation/standalone#配置数据库" target="_blank" rel="noopener">配置数据库</a></p><h3 id="6-1-解压并启动-DolphinScheduler"><a href="#6-1-解压并启动-DolphinScheduler" class="headerlink" title="6.1 解压并启动 DolphinScheduler"></a>6.1 解压并启动 DolphinScheduler</h3><p>二进制压缩包中有 standalone 启动的脚本，解压后即可快速启动。切换到有 sudo 权限的用户，运行脚本</p><pre class=" language-shell"><code class="language-shell"># 解压并运行 Standalone Server[root@node2 opt]# tar -zxvf apache-dolphinscheduler-3.1.4-bin.tar.gz# 进入到  DolphinScheduler 安装路径[root@node2 opt]# cd apache-dolphinscheduler-3.1.4-bin/# 执行启动脚本[root@node2 apache-dolphinscheduler-3.1.4-bin]# bin/dolphinscheduler-daemon.sh start standalone-serverBegin start standalone-server......starting standalone-server, logging to /opt/apache-dolphinscheduler-3.1.4-bin/standalone-server/logsOverwrite standalone-server/conf/dolphinscheduler_env.sh using bin/env/dolphinscheduler_env.sh.End start standalone-server.# 查看运行进程[root@node2 apache-dolphinscheduler-3.1.4-bin]# jps -l | grep dolphinscheduler8285 org.apache.dolphinscheduler.StandaloneServer</code></pre><h3 id="6-2-访问系统"><a href="#6-2-访问系统" class="headerlink" title="6.2 访问系统"></a>6.2 访问系统</h3><p>浏览器访问地址 <a href="http://localhost:12345/dolphinscheduler/ui" target="_blank" rel="noopener">http://localhost:12345/dolphinscheduler/ui</a> 即可登录系统UI</p><p>默认的用户名和密码是  admin / dolphinscheduler123</p><p><img src="https://images.hnbian.cn/202304191049088.jpg?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="登录页面"></p><p><img src="https://images.hnbian.cn/202304191049089.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="系统主页"></p><h3 id="6-3-启停服务"><a href="#6-3-启停服务" class="headerlink" title="6.3 启停服务"></a>6.3 启停服务</h3><p>脚本 <code>./bin/dolphinscheduler-daemon.sh</code> 除了可以快捷启动 standalone 外，还能停止服务运行，全部命令如下</p><pre class=" language-shell"><code class="language-shell"># 启动 Standalone Server 服务bash ./bin/dolphinscheduler-daemon.sh start standalone-server# 停止 Standalone Server 服务bash ./bin/dolphinscheduler-daemon.sh stop standalone-server</code></pre><h3 id="6-4-切换元数据库"><a href="#6-4-切换元数据库" class="headerlink" title="6.4 切换元数据库"></a>6.4 切换元数据库</h3><p>Standalone server 使用 H2 数据库作为其元数据存储数据，这是为了上手简单，用户在启动服务器之前不需要启动数据库。但是如果用户想将元数据库存储在 MySQL 或 PostgreSQL 等其他数据库中，他们必须更改一些配置。我们这里以 MySQL 为例来说明如何配置外部数据库。</p><h4 id="6-4-1-上传驱动"><a href="#6-4-1-上传驱动" class="headerlink" title="6.4.1 上传驱动"></a>6.4.1 上传驱动</h4><p>将 MySQL 的驱动包上传到 DolphinScheduler 的每个模块的 libs 目录下，其中包括 </p><ol><li><code>standalone-server/libs/standalone-server/</code></li><li><code>tools/libs/</code></li><li><code>api-server/libs</code> </li><li><code>alert-server/libs</code> </li><li><code>master-server/libs</code> </li><li><code>worker-server/libs</code></li></ol><h4 id="6-4-2-修改配置"><a href="#6-4-2-修改配置" class="headerlink" title="6.4.2 修改配置"></a>6.4.2 修改配置</h4><ul><li>修改 <code>bin/env/dolphinscheduler_env.sh</code> 设定下列环境变量，修改如下配置：</li></ul><pre class=" language-bash"><code class="language-bash">vim bin/env/dolphinscheduler_env.sh<span class="token function">export</span> DATABASE<span class="token operator">=</span>mysql<span class="token function">export</span> SPRING_PROFILES_ACTIVE<span class="token operator">=</span>jdbc:mysql://192.168.1.73:3306/ds1?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8<span class="token operator">&amp;</span>useSSL<span class="token operator">=</span>false<span class="token function">export</span> SPRING_DATASOURCE_USERNAME<span class="token operator">=</span>root<span class="token function">export</span> SPRING_DATASOURCE_PASSWORD<span class="token operator">=</span>root123</code></pre><ul><li>修改 <code>tools/conf/application.yaml</code>中 MySQL 的相关配置</li></ul><pre class=" language-bash"><code class="language-bash">vim tools/conf/application.yaml<span class="token comment" spellcheck="true"># 修改下面的 mysql url 跟前面的配置保持一致</span>---spring:  config:    activate:      on-profile: mysql  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://192.168.1.73:3306/ds1?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8</code></pre><ul><li>修改  <code>standalone-server/conf/application.yaml</code> 中的 MySQL 相关配置</li></ul><pre class=" language-bash"><code class="language-bash">vim standalone-server/conf/application.yaml---------spring:  config:    activate:      on-profile: mysql  sql:     init:       schema-locations: classpath:sql/dolphinscheduler_mysql.sql  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://192.168.1.73:3306/ds1?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8    username: root    password: root@123</code></pre><h4 id="6-4-3-初始化数据库"><a href="#6-4-3-初始化数据库" class="headerlink" title="6.4.3 初始化数据库"></a>6.4.3 初始化数据库</h4><pre class=" language-bash"><code class="language-bash"><span class="token function">bash</span> tools/bin/upgrade-schema.sh<span class="token punctuation">..</span>.2023-03-27 08:00:19.540  INFO 10055 --- <span class="token punctuation">[</span>           main<span class="token punctuation">]</span> o.a.d.common.utils.ScriptRunner          <span class="token keyword">:</span> sql: CREATE TABLE <span class="token variable"><span class="token variable">`</span>t_ds_fav_task<span class="token variable">`</span></span> <span class="token punctuation">(</span>     <span class="token variable"><span class="token variable">`</span><span class="token function">id</span><span class="token variable">`</span></span>        bigint      NOT NULL AUTO_INCREMENT COMMENT <span class="token string">'favorite task id'</span>,     <span class="token variable"><span class="token variable">`</span>task_name<span class="token variable">`</span></span> varchar<span class="token punctuation">(</span>64<span class="token punctuation">)</span> NOT NULL COMMENT <span class="token string">'favorite task name'</span>,     <span class="token variable"><span class="token variable">`</span>user_id<span class="token variable">`</span></span>   int         NOT NULL COMMENT <span class="token string">'user id'</span>,     PRIMARY KEY <span class="token punctuation">(</span><span class="token variable"><span class="token variable">`</span><span class="token function">id</span><span class="token variable">`</span></span><span class="token punctuation">)</span> <span class="token punctuation">)</span> ENGINE <span class="token operator">=</span> InnoDB   AUTO_INCREMENT <span class="token operator">=</span> 1   DEFAULT CHARSET <span class="token operator">=</span> utf8 2023-03-27 08:00:20.208  INFO 10055 --- <span class="token punctuation">[</span>           main<span class="token punctuation">]</span> .d.UpgradeDolphinScheduler<span class="token variable">$UpgradeRunner</span> <span class="token keyword">:</span> init DolphinScheduler finished2023-03-27 08:00:20.216  INFO 10055 --- <span class="token punctuation">[</span>ionShutdownHook<span class="token punctuation">]</span> com.zaxxer.hikari.HikariDataSource       <span class="token keyword">:</span> DolphinScheduler - Shutdown initiated<span class="token punctuation">..</span>.2023-03-27 08:00:20.220  INFO 10055 --- <span class="token punctuation">[</span>ionShutdownHook<span class="token punctuation">]</span> com.zaxxer.hikari.HikariDataSource       <span class="token keyword">:</span> DolphinScheduler - Shutdown completed.</code></pre><p><img src="https://images.hnbian.cn/202304191049090.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="dolphinscheduler 在 MySQL 中的元数据"></p><h3 id="6-5-启动-standalone-server"><a href="#6-5-启动-standalone-server" class="headerlink" title="6.5 启动 standalone-server"></a>6.5 启动 standalone-server</h3><p>此时你已经连接上mysql，重启 或 停止 standalone-server 并不会清空您数据库里的数据</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 启动 Standalone Server 服务</span><span class="token function">bash</span> ./bin/dolphinscheduler-daemon.sh start standalone-server</code></pre><p>进入下面的页面说明已经安装成功</p><p><img src="https://images.hnbian.cn/202304191049089.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="系统主页"></p><h2 id="7-伪集群部署"><a href="#7-伪集群部署" class="headerlink" title="7. 伪集群部署"></a>7. 伪集群部署</h2><p>伪集群部署目的是在单台机器部署 DolphinScheduler 服务，该模式下 master、worker、api server 都在同一台机器上</p><p>如果你是新手，想要体验 DolphinScheduler 的功能，推荐使用 Standalone 方式体检。如果你想体验更完整的功能，或者更大的任务量，推荐使用 伪集群部署 。如果你是在生产中使用，推荐使用 集群部署 或者 kubernetes</p><h3 id="7-1-准备工作"><a href="#7-1-准备工作" class="headerlink" title="7.1 准备工作"></a>7.1 准备工作</h3><ul><li><p><a href="https://dolphinscheduler.apache.org/zh-cn/download" target="_blank" rel="noopener">下载安装包</a></p></li><li><p>安装数据库：<a href="https://www.postgresql.org/download/" target="_blank" rel="noopener">PostgreSQL</a> (8.2.15+) 或者 <a href="https://dev.mysql.com/downloads/mysql/" target="_blank" rel="noopener">MySQL</a> (5.7+)，两者任选其一即可，如 MySQL 则需要  <code>JDBC Driver 8.0.16</code></p></li><li><p>部署注册中心 <a href="https://zookeeper.apache.org/releases.html" target="_blank" rel="noopener">ZooKeeper</a> (3.4.6+, 不包含 3.4.6) ，<a href="https://zookeeper.apache.org/releases.html" target="_blank" rel="noopener">下载地址</a></p></li><li><p>进程树分析</p><ul><li>macOS安装 <code>pstree</code></li><li>Fedora/Red/Hat/CentOS/Ubuntu/Debian 安装 <code>psmisc</code></li></ul><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 如果是集群模式，每个节点都需要安装</span><span class="token function">sudo</span> yum <span class="token function">install</span> -y psmisc</code></pre></li></ul><blockquote><p>注意: DolphinScheduler 本身不依赖 Hadoop、Hive、Spark，但如果你运行的任务需要依赖他们，就需要有对应的环境支持</p></blockquote><h3 id="7-2-配置用户免密执行权限"><a href="#7-2-配置用户免密执行权限" class="headerlink" title="7.2 配置用户免密执行权限"></a>7.2 配置用户免密执行权限</h3><p>任务执行服务是以 <code>sudo -u {linux-user}</code> 切换不同 linux 用户的方式来实现多租户运行作业，所以部署用户需要有 sudo 权限，而且是免密的。所以这里需配置用户的免密权限</p><p>创建部署用户，并且一定要配置 <code>sudo</code> 免密。以创建 dolphinscheduler 用户为例</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 创建用户需使用 root 登录</span><span class="token function">useradd</span> dolphinscheduler<span class="token comment" spellcheck="true"># 为 dolphinscheduler 用户设置密码，密码为  “dolphinscheduler”</span><span class="token keyword">echo</span> <span class="token string">"dolphinscheduler"</span> <span class="token operator">|</span> <span class="token function">passwd</span> --stdin dolphinscheduler<span class="token comment" spellcheck="true"># 配置 sudo 免密</span><span class="token function">sed</span> -i <span class="token string">'<span class="token variable">$adolphinscheduler</span>  ALL=(ALL)  NOPASSWD: NOPASSWD: ALL'</span> /etc/sudoers<span class="token function">sed</span> -i <span class="token string">'s/Defaults    requirett/#Defaults    requirett/g'</span> /etc/sudoers<span class="token comment" spellcheck="true"># 修改目录权限，使得dolphinscheduler用户对 apache-dolphinscheduler-3.1.4-bin 目录有操作权限</span><span class="token function">chown</span> -R dolphinscheduler:dolphinscheduler apache-dolphinscheduler-3.1.4-bin</code></pre><ul><li>如果发现 <code>/etc/sudoers</code> 文件中有 “Defaults requiretty” 这行，也请注释掉</li></ul><h3 id="7-3-配置SSH免密登陆"><a href="#7-3-配置SSH免密登陆" class="headerlink" title="7.3 配置SSH免密登陆"></a>7.3 配置SSH免密登陆</h3><p>配置单节点免密登录可实现无缝的自动化脚本执行，提高任务成功率，同时简化本地节点的管理和维护过程。</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 切换用户</span><span class="token function">su</span> dolphinscheduler<span class="token comment" spellcheck="true"># 使用RSA 算法生成一对密钥 ，密码为 '' 即没有密码</span>ssh-keygen -t rsa -P <span class="token string">''</span> -f ~/.ssh/id_rsa<span class="token comment" spellcheck="true"># 实现免密登录</span><span class="token function">cat</span> ~/.ssh/id_rsa.pub <span class="token operator">>></span> ~/.ssh/authorized_keys<span class="token function">chmod</span> 600 ~/.ssh/authorized_keys</code></pre><p>配置完成后，可以通过运行命令 <code>ssh localhost</code> 判断是否成功，如果不需要输入密码就能ssh登陆则证明成功</p><h3 id="7-4-配置-zookeeper-单节点"><a href="#7-4-配置-zookeeper-单节点" class="headerlink" title="7.4 配置 zookeeper(单节点)"></a>7.4 配置 zookeeper(单节点)</h3><h4 id="7-4-1-下载安装文件"><a href="#7-4-1-下载安装文件" class="headerlink" title="7.4.1 下载安装文件"></a>7.4.1 下载安装文件</h4><p>zookeeper 下载地址：<a href="http://archive.apache.org/dist/zookeeper/" target="_blank" rel="noopener">http://archive.apache.org/dist/zookeeper/</a></p><p>根据自己的需要下载对应版本，这里下载的版本是 3.5.6</p><h4 id="7-4-2-解压安装包"><a href="#7-4-2-解压安装包" class="headerlink" title="7.4.2 解压安装包"></a>7.4.2 解压安装包</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 将下载的安装包上传到服务器</span><span class="token comment" spellcheck="true"># 切换文件夹</span><span class="token punctuation">[</span>root@node1 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /opt/</span><span class="token comment" spellcheck="true"># 解压 安装包</span><span class="token punctuation">[</span>root@node1 opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tar -zxvf apache-zookeeper-3.5.6-bin.tar.gz</span><span class="token punctuation">[</span>root@node1 opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>总用量 30452-rw-r--r-- 1 root root 9230052 10月 16 08:35 apache-zookeeper-3.5.6-bin.tar.gzdrwxr-xr-x 8 root root    4096 1月  30 11:34 zookeeper-3.5.6</code></pre><h4 id="7-4-3-创建所需文件夹"><a href="#7-4-3-创建所需文件夹" class="headerlink" title="7.4.3 创建所需文件夹"></a>7.4.3 创建所需文件夹</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 切换文件夹</span><span class="token punctuation">[</span>root@node1 opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd zookeeper-3.5.6/</span><span class="token comment" spellcheck="true"># 创建数据文件夹（Zookeeper之后产生的数据会存储在该文件夹中）</span><span class="token punctuation">[</span>root@node1 opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># mkdir data</span><span class="token comment" spellcheck="true"># 创建日志文件夹（Zookeeper之后产生的日志数据会存储在该文件夹中）</span><span class="token punctuation">[</span>root@node1 opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># mkdir logs</span><span class="token punctuation">[</span>root@node1 zookeeper-3.5.6<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>总用量 48drwxr-xr-x 2 1000 1000  4096 10月  9 04:14 bindrwxr-xr-x 2 1000 1000  4096 1月  29 22:24 confdrwxr-xr-x 3 root root  4096 1月  29 22:24 data <span class="token comment" spellcheck="true"># 数据文件夹</span>drwxr-xr-x 5 1000 1000  4096 10月  9 04:15 docsdrwxr-xr-x 2 root root  4096 1月  29 21:50 lib-rw-r--r-- 1 1000 1000 11358 10月  5 19:27 LICENSE.txtdrwxr-xr-x 3 root root  4096 1月  29 22:12 logs <span class="token comment" spellcheck="true"># 日志文件夹</span>-rw-r--r-- 1 1000 1000   432 10月  9 04:14 NOTICE.txt-rw-r--r-- 1 1000 1000  1560 10月  9 04:14 README.md-rw-r--r-- 1 1000 1000  1347 10月  5 19:27 README_packaging.txt</code></pre><h4 id="7-4-4-修改配置文件"><a href="#7-4-4-修改配置文件" class="headerlink" title="7.4.4 修改配置文件"></a>7.4.4 修改配置文件</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 切换文件夹</span><span class="token punctuation">[</span>root@node1 zookeeper-3.5.6<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd conf</span><span class="token punctuation">[</span>root@node1 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>总用量 16-rw-r--r-- 1 1000 1000  535 10月  5 19:27 configuration.xsl-rw-r--r-- 1 1000 1000 2712 10月  5 19:27 log4j.properties-rw-r--r-- 1 1000 1000  922 10月  9 04:14 zoo_sample.cfg<span class="token comment" spellcheck="true"># 修改配置文件名称，默认是使用zoo.cfg，固定的</span><span class="token punctuation">[</span>root@node1 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cp zoo_sample.cfg zoo.cfg</span><span class="token punctuation">[</span>root@node1 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim zoo.cfg</span>在配置文件中增加或修改一下内容<span class="token comment" spellcheck="true"># 指定数据文件夹</span>dataDir<span class="token operator">=</span>/opt/zookeeper-3.5.6/data<span class="token comment" spellcheck="true"># 指定数据日志文件夹</span>dataLogDir<span class="token operator">=</span>/opt/zookeeper-3.5.6/logs<span class="token comment" spellcheck="true"># the port at which the clients will connect</span>clientPort<span class="token operator">=</span>2181<span class="token comment" spellcheck="true">#2888,3888 are election port</span>server.0<span class="token operator">=</span>node1:2888:3888</code></pre><h4 id="7-4-5-启动服务"><a href="#7-4-5-启动服务" class="headerlink" title="7.4.5 启动服务"></a>7.4.5 启动服务</h4><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@node1 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /opt/zookeeper-3.5.6/bin</span><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#</span><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>总用量 56-rwxr-xr-x 1 1000 1000 2067 10月  9 04:14 zkCleanup.sh-rwxr-xr-x 1 1000 1000 1621 10月  9 04:14 zkCli.sh <span class="token comment" spellcheck="true"># zookeeper 客户端</span>-rwxr-xr-x 1 1000 1000 3690 10月  5 19:27 zkEnv.sh-rwxr-xr-x 1 1000 1000 4573 10月  9 04:14 zkServer-initialize.sh-rwxr-xr-x 1 1000 1000 9386 10月  9 04:14 zkServer.sh <span class="token comment" spellcheck="true"># zookeeper 服务器相关命令</span>-rwxr-xr-x 1 1000 1000 1385 10月  5 19:27 zkTxnLogToolkit.sh<span class="token comment" spellcheck="true">#启动zookeeper服务，restart 重启</span><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># zkServer.sh start</span>ZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper-3.5.6/bin/<span class="token punctuation">..</span>/conf/zoo.cfgStarting zookeeper <span class="token punctuation">..</span>. STARTED<span class="token comment" spellcheck="true">#查看zookeeper服务状态</span><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># zkServer.sh status</span>ZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper-3.5.6/bin/<span class="token punctuation">..</span>/conf/zoo.cfgClient port found: 2181. Client address: localhost.Mode: standalone <span class="token comment" spellcheck="true"># 单节点模式</span><span class="token comment" spellcheck="true">#停止zookeeper服务</span><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># zkServer.sh stop</span>ZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper-3.5.6/bin/<span class="token punctuation">..</span>/conf/zoo.cfgStopping zookeeper <span class="token punctuation">..</span>. STOPPED</code></pre><h4 id="7-4-6-查看zookeeper进程"><a href="#7-4-6-查看zookeeper进程" class="headerlink" title="7.4.6 查看zookeeper进程"></a>7.4.6 查看zookeeper进程</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 查看Java进程</span><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># jps -l </span>7696 org.apache.zookeeper.server.quorum.QuorumPeerMain8311 sun.tools.jps.Jps<span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true">#根据端口查看进程信息</span><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># lsof -i:2181</span>COMMAND  PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAMEjava    7696 root   49u  IPv4 1194504      0t0  TCP *:eforward <span class="token punctuation">(</span>LISTEN<span class="token punctuation">)</span></code></pre><p>如果没有lsof服务可以使用  <strong>yum install lsof</strong> 安装</p><h4 id="7-4-7-启动客户端"><a href="#7-4-7-启动客户端" class="headerlink" title="7.4.7 启动客户端"></a>7.4.7 启动客户端</h4><ul><li>连接本机</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># zkCli.sh #默认连接本机</span>Connecting to localhost:2181<span class="token punctuation">..</span>.Welcome to ZooKeeper<span class="token operator">!</span>JLine support is enabled<span class="token punctuation">..</span>.WATCHER::WatchedEvent state:SyncConnected type:None path:null<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 0<span class="token punctuation">]</span><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 0<span class="token punctuation">]</span> quit <span class="token comment" spellcheck="true"># 退出客户端</span>WATCHER::WatchedEvent state:Closed type:None path:null</code></pre><ul><li>连接远程zookeeper服务</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@node1 bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># zkCli.sh -server localhost:2181 # 连接远程服务</span>Connecting to localhost:2181<span class="token punctuation">..</span>.Welcome to ZooKeeper<span class="token operator">!</span>JLine support is enabled<span class="token punctuation">..</span>.WATCHER::WatchedEvent state:SyncConnected type:None path:null<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 0<span class="token punctuation">]</span></code></pre><h3 id="7-5-修改相关配置"><a href="#7-5-修改相关配置" class="headerlink" title="7.5 修改相关配置"></a>7.5 修改相关配置</h3><p>完成基础环境的准备后，需要根据你的机器环境修改配置文件。配置文件可以在目录 <code>bin/env</code> 中找到，他们分别是 并命名为 <code>install_env.sh</code> 和 <code>dolphinscheduler_env.sh</code>。</p><h4 id="7-5-1-修改-install-env-sh"><a href="#7-5-1-修改-install-env-sh" class="headerlink" title="7.5.1 修改 install_env.sh"></a>7.5.1 修改 <code>install_env.sh</code></h4><p>文件 <code>install_env.sh</code> 描述了哪些机器将被安装 DolphinScheduler 以及每台机器对应安装哪些服务。您可以在路径 <code>bin/env/install_env.sh</code> 中找到此文件，配置详情如下。</p><pre class=" language-shell"><code class="language-shell">vim bin/env/install_env.sh# ---------------------------------------------------------# INSTALL MACHINE# ---------------------------------------------------------# 由于 master、worker 和 API 服务器部署在单个节点上，因此服务器的 IP 为机器 IP 或本地主机（localhost）ips="localhost"sshPort="22"masters="localhost"workers="localhost:default"alertServer="localhost"apiServers="localhost"# DolphinScheduler 安装路径，如果不存在将自动创建。installPath=/opt/dolphinscheduler# 部署用户，需要配置了免密执行权限和免密登录deployUser="dolphinscheduler"</code></pre><h4 id="7-5-2-修改-dolphinscheduler-env-sh"><a href="#7-5-2-修改-dolphinscheduler-env-sh" class="headerlink" title="7.5.2 修改 dolphinscheduler_env.sh"></a>7.5.2 修改 <code>dolphinscheduler_env.sh</code></h4><p>文件 <code>./bin/env/dolphinscheduler_env.sh</code> 描述了下列配置：</p><ul><li>DolphinScheduler 的数据库配置，详细配置方法见<a href="https://dolphinscheduler.apache.org/zh-cn/docs/3.1.4/guide/installation/pseudo-cluster#初始化数据库" target="_blank" rel="noopener">初始化数据库</a></li><li>一些任务类型外部依赖路径或库文件，如 <code>JAVA_HOME</code> 和 <code>SPARK_HOME</code>都是在这里定义的</li><li>注册中心<code>zookeeper</code></li><li>服务端相关配置，比如缓存，时区设置等</li></ul><p>如果您不使用某些任务类型，您可以忽略任务外部依赖项，但您必须根据您的环境更改 <code>JAVA_HOME</code>、注册中心和数据库相关配置。</p><pre class=" language-sh"><code class="language-sh">vim ./bin/env/dolphinscheduler_env.sh# JAVA_HOME, will use it to start DolphinScheduler serverexport JAVA_HOME=/usr/java/jdk1.8.0_181# 与数据库相关的配置，设置数据库类型、用户名和密码export DATABASE=mysqlexport SPRING_PROFILES_ACTIVE=${DATABASE}export SPRING_DATASOURCE_URL=jdbc:mysql://192.168.1.73:3306/ds2?useUnicode=true&characterEncoding=UTF-8&useSSL=falseexport SPRING_DATASOURCE_USERNAME=rootexport SPRING_DATASOURCE_PASSWORD=root@123# Registry center configuration, determines the type and link of the registry centerexport REGISTRY_TYPE=zookeeperexport REGISTRY_ZOOKEEPER_CONNECT_STRING=192.168.1.73:2181</code></pre><h4 id="7-5-3-修改一些-application-yaml-配置文件"><a href="#7-5-3-修改一些-application-yaml-配置文件" class="headerlink" title="7.5.3 修改一些 application.yaml 配置文件"></a>7.5.3 修改一些 <code>application.yaml</code> 配置文件</h4><ul><li>tools 模块配置文件， 在进行数据库初始化时会用到</li></ul><pre class=" language-bash"><code class="language-bash">vim tools/conf/application.yaml<span class="token comment" spellcheck="true"># 修改下面的 mysql url 跟前面的配置保持一致</span>---spring:  config:    activate:      on-profile: mysql  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://192.168.1.73:3306/ds2?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8</code></pre><ul><li>alert-server 模块</li></ul><pre class=" language-bash"><code class="language-bash">vim alert-server/conf/application.yaml---spring:  config:    activate:      on-profile: mysql  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://192.168.1.73:3306/ds2?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8<span class="token operator">&amp;</span>useSSL<span class="token operator">=</span>false    username: root    password: root@123</code></pre><ul><li>api-server 模块</li></ul><pre class=" language-bash"><code class="language-bash">vim api-server/conf/application.yaml---spring:  config:    activate:      on-profile: mysql  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://192.168.1.73:3306/ds2?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8<span class="token operator">&amp;</span>useSSL<span class="token operator">=</span>false    username: root    password: root@123</code></pre><pre class=" language-bash"><code class="language-bash">vim master-server/conf/application.yaml---spring:  config:    activate:      on-profile: mysql  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://192.168.1.73:3306/ds2?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8<span class="token operator">&amp;</span>useSSL<span class="token operator">=</span>false    username: root    password: root@123</code></pre><ul><li>worker-server 模块</li></ul><pre class=" language-bash"><code class="language-bash">vim worker-server/conf/application.yaml---spring:  config:    activate:      on-profile: mysql  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://192.168.1.73:3306/ds2?useUnicode<span class="token operator">=</span>true<span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF-8<span class="token operator">&amp;</span>useSSL<span class="token operator">=</span>false    username: root    password: root@123</code></pre><h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><p><strong>在初始化数据库之前 需要创建好数据库， 这里配置的是 ds2</strong></p><p>初始化数据库之前需要把驱动包拷贝到对应的模块 libs 目录下</p><pre class=" language-bash"><code class="language-bash"><span class="token function">cp</span> mysql-connector-java-8.0.16.jar alert-server/libs/<span class="token function">cp</span> mysql-connector-java-8.0.16.jar api-server/libs/<span class="token function">cp</span> mysql-connector-java-8.0.16.jar master-server/libs/<span class="token function">cp</span> mysql-connector-java-8.0.16.jar standalone-server/libs/<span class="token function">cp</span> mysql-connector-java-8.0.16.jar tools/libs/<span class="token function">cp</span> mysql-connector-java-8.0.16.jar worker-server/libs/</code></pre><ul><li>初始化数据库</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">bash</span> tools/bin/upgrade-schema.sh<span class="token punctuation">..</span>.2023-03-28 08:34:42.575  INFO 11235 --- <span class="token punctuation">[</span>ionShutdownHook<span class="token punctuation">]</span> com.zaxxer.hikari.HikariDataSource       <span class="token keyword">:</span> DolphinScheduler - Shutdown initiated<span class="token punctuation">..</span>.2023-03-28 08:34:42.580  INFO 11235 --- <span class="token punctuation">[</span>ionShutdownHook<span class="token punctuation">]</span> com.zaxxer.hikari.HikariDataSource       <span class="token keyword">:</span> DolphinScheduler - Shutdown completed.</code></pre><h3 id="部署-DolphinScheduler"><a href="#部署-DolphinScheduler" class="headerlink" title="部署 DolphinScheduler"></a>部署 DolphinScheduler</h3><p>使用上面创建的<strong>部署用户</strong>运行以下命令完成部署，部署后的运行日志将存放在 logs 文件夹内</p><pre class=" language-shell"><code class="language-shell"># 使用 dolphinscheduler 用户进行安装bash ./bin/install.sh1.create directory2.scp resourceslocalhost:defaultscp dirs to localhost//opt/dolphinscheduler_single_cluster startingstart to scp bin to localhost//opt/dolphinscheduler_single_cluster............localhost  Begin status master-server......master-server  [  RUNNING  ]End status master-server.localhost  Begin status worker-server......worker-server  [  RUNNING  ]End status worker-server.localhost  Begin status alert-server......alert-server  [  RUNNING  ]End status alert-server.localhost  Begin status api-server......api-server  [  RUNNING  ]End status api-server.# 查看进程[dolphinscheduler@node2 dolphinscheduler_single_cluster_install_package]$ jps -l31429 sun.tools.jps.Jps20886 org.apache.dolphinscheduler.alert.AlertServer31129 org.apache.dolphinscheduler.server.worker.WorkerServer31177 org.apache.dolphinscheduler.alert.AlertServer31082 org.apache.dolphinscheduler.server.master.MasterServer31226 org.apache.dolphinscheduler.api.ApiApplicationServer</code></pre><blockquote><p><strong><em>注意:\</em></strong> 第一次部署的话，可能出现 5 次<code>sh: bin/dolphinscheduler-daemon.sh: No such file or directory</code>相关信息，此为非重要信息直接忽略即可</p></blockquote><ul><li>查看日志</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">tail</span> -200f alert-server/logs/dolphinscheduler-alert.log<span class="token function">tail</span> -200f api-server/logs/dolphinscheduler-api.log<span class="token function">tail</span> -200f master-server/logs/dolphinscheduler-master.log<span class="token function">tail</span> -200f worker-server/logs/dolphinscheduler-worker.log</code></pre><h3 id="登录-DolphinScheduler"><a href="#登录-DolphinScheduler" class="headerlink" title="登录 DolphinScheduler"></a>登录 DolphinScheduler</h3><p>浏览器访问地址 <a href="http://localhost:12345/dolphinscheduler/ui" target="_blank" rel="noopener">http://localhost:12345/dolphinscheduler/ui</a> 即可登录系统UI。默认的用户名和密码是 <strong>admin/dolphinscheduler123</strong></p><h3 id="启停服务"><a href="#启停服务" class="headerlink" title="启停服务"></a>启停服务</h3><pre class=" language-shell"><code class="language-shell"># 一键停止集群所有服务bash ./bin/stop-all.sh# 一键开启集群所有服务bash ./bin/start-all.sh# 启动 Masterbash ./bin/dolphinscheduler-daemon.sh start master-server# 停止 masterbash ./bin/dolphinscheduler-daemon.sh stop master-server# 查看 master 状态bash ./bin/dolphinscheduler-daemon.sh status master-server# 启停 Workerbash ./bin/dolphinscheduler-daemon.sh start worker-serverbash ./bin/dolphinscheduler-daemon.sh stop worker-serverbash ./bin/dolphinscheduler-daemon.sh status worker-server# 启停 Apibash ./bin/dolphinscheduler-daemon.sh start api-serverbash ./bin/dolphinscheduler-daemon.sh stop api-serverbash ./bin/dolphinscheduler-daemon.sh status api-server# 启停 Alertbash ./bin/dolphinscheduler-daemon.sh start alert-serverbash ./bin/dolphinscheduler-daemon.sh stop alert-serverbash ./bin/dolphinscheduler-daemon.sh status alert-server</code></pre><blockquote><p><strong><em>注意1:\</em></strong>: 每个服务在路径 <code>&lt;service&gt;/conf/dolphinscheduler_env.sh</code> 中都有 <code>dolphinscheduler_env.sh</code> 文件，这是可以为微 服务需求提供便利。意味着您可以基于不同的环境变量来启动各个服务，只需要在对应服务中配置 <code>&lt;service&gt;/conf/dolphinscheduler_env.sh</code> 然后通过 <code>&lt;service&gt;/bin/start.sh</code> 命令启动即可。但是如果您使用命令 <code>/bin/dolphinscheduler-daemon.sh start &lt;service&gt;</code> 启动服务器，它将会用文件 <code>bin/env/dolphinscheduler_env.sh</code> 覆盖 <code>&lt;service&gt;/conf/dolphinscheduler_env.sh</code> 然后启动服务，目的是为了减少用户修改配置的成本.</p><p><strong><em>注意2:\</em></strong>：服务用途请具体参见《系统架构设计》小节。Python gateway service 默认与 api-server 一起启动，如果您不想启动 Python gateway service 请通过更改 api-server 配置文件 <code>api-server/conf/application.yaml</code> 中的 <code>python-gateway.enabled : false</code> 来禁用它。</p></blockquote><h2 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h2><p>集群部署(Cluster)使用的脚本和配置文件与 伪集群部署 中的配置一样，所以所需要的步骤也与伪集群部署大致一样。下面的部署文档中省略了大部分章节， 仅介绍了集群部署过程中与伪分布式部署配置上有差异的部分。</p><p>区别就是伪集群部署针对的是一台机器，而集群部署(Cluster)需要针对多台机器，且两者 “ 修改相关配置 ” 步骤区别较大</p><h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><table><thead><tr><th>节点</th><th>服务</th></tr></thead><tbody><tr><td>192.168.1.72</td><td>MasterServer, WorkerServer, ApiServer, AlertServer</td></tr><tr><td>192.168.1.71</td><td>WorkerServer</td></tr></tbody></table><h3 id="安装-JDK"><a href="#安装-JDK" class="headerlink" title="安装 JDK"></a>安装 JDK</h3><p>前面介绍过了， 这里略过。</p><h3 id="安装-psmisc"><a href="#安装-psmisc" class="headerlink" title="安装 psmisc"></a>安装 psmisc</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 在所有节点执行</span><span class="token function">sudo</span> yum <span class="token function">install</span> -y psmisc</code></pre><h3 id="配置用户免密执行权限"><a href="#配置用户免密执行权限" class="headerlink" title="配置用户免密执行权限"></a>配置用户免密执行权限</h3><p>所有节点都需要配置， 详细内容见 伪集群部署中的 <code>配置用户免密执行权限</code>  章节</p><h3 id="配置SSH免密登陆"><a href="#配置SSH免密登陆" class="headerlink" title="配置SSH免密登陆"></a>配置SSH免密登陆</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 切换用户</span><span class="token function">su</span> dolphinscheduler<span class="token comment" spellcheck="true"># 使用RSA 算法生成一对密钥 ，密码为 '' 即没有密码</span>ssh-keygen -t rsa -P <span class="token string">''</span> -f ~/.ssh/id_rsa<span class="token comment" spellcheck="true"># 实现免密登录</span><span class="token function">cat</span> ~/.ssh/id_rsa.pub <span class="token operator">>></span> ~/.ssh/authorized_keys<span class="token function">chmod</span> 600 ~/.ssh/authorized_keys<span class="token comment" spellcheck="true"># 免密登录到其他节点</span>ssh-copy-id ip<span class="token comment" spellcheck="true"># ip 为想要登录的节点</span></code></pre><h3 id="配置-zookeeper"><a href="#配置-zookeeper" class="headerlink" title="配置 zookeeper"></a>配置 zookeeper</h3><p>根据需求，zookeeper 配置集群或者单节点均可， 详细配置见上述章节</p><h3 id="修改相关配置"><a href="#修改相关配置" class="headerlink" title="修改相关配置"></a>修改相关配置</h3><h4 id="修改-install-env-sh"><a href="#修改-install-env-sh" class="headerlink" title="修改 install_env.sh"></a>修改 <code>install_env.sh</code></h4><p>除了上述的部分还有一些有区别的配置如下：</p><pre class=" language-bash"><code class="language-bash">vim bin/env/install_env.sh<span class="token comment" spellcheck="true"># 修改如下配置</span><span class="token comment" spellcheck="true"># ---------------------------------------------------------</span><span class="token comment" spellcheck="true"># INSTALL MACHINE</span><span class="token comment" spellcheck="true"># ---------------------------------------------------------</span><span class="token comment" spellcheck="true"># 由于 master、worker 和 API 服务器部署在单个节点上，因此服务器的 IP 为机器 IP 或本地主机（localhost）</span>ips<span class="token operator">=</span><span class="token string">"192.168.1.72,192.168.1.71"</span>sshPort<span class="token operator">=</span><span class="token string">"22"</span>masters<span class="token operator">=</span><span class="token string">"localhost"</span><span class="token comment" spellcheck="true"># worker组就是多个 worker 组成了一个组，创建任务时 可以指定任务分片到哪些worker中执行</span>workers<span class="token operator">=</span><span class="token string">"192.168.1.72:default,192.168.1.71:default"</span>alertServer<span class="token operator">=</span><span class="token string">"192.168.1.72:default"</span>apiServers<span class="token operator">=</span><span class="token string">"192.168.1.72:default"</span><span class="token comment" spellcheck="true"># DolphinScheduler 安装路径，如果不存在将自动创建。需要写当前用户有权限的路径</span>installPath<span class="token operator">=</span>/opt/dolphinscheduler<span class="token comment" spellcheck="true"># 部署用户，需要配置了免密执行权限和免密登录，将来作为启动dolphinScheduler的用户</span>deployUser<span class="token operator">=</span><span class="token string">"dolphinscheduler"</span></code></pre><h4 id="修改-dolphinscheduler-env-sh"><a href="#修改-dolphinscheduler-env-sh" class="headerlink" title="修改 dolphinscheduler_env.sh"></a>修改 <code>dolphinscheduler_env.sh</code></h4><p>详细见伪集群安装部分的 修改 <code>dolphinscheduler_env.sh</code>  配置章节</p><h4 id="修改一些-application-yaml-配置文件"><a href="#修改一些-application-yaml-配置文件" class="headerlink" title="修改一些 application.yaml 配置文件"></a>修改一些 <code>application.yaml</code> 配置文件</h4><p>详细见伪集群安装部分的 修改一些 <code>application.yaml</code>  配置章节</p><h3 id="初始化数据库-1"><a href="#初始化数据库-1" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><p>详细见伪集群安装部分的 初始化数据库  配置章节</p><h3 id="部署-DolphinScheduler-1"><a href="#部署-DolphinScheduler-1" class="headerlink" title="部署 DolphinScheduler"></a>部署 DolphinScheduler</h3><p>详细见伪集群安装部分的 部署 DolphinScheduler 配置章节</p><h3 id="登录-DolphinScheduler-1"><a href="#登录-DolphinScheduler-1" class="headerlink" title="登录 DolphinScheduler"></a>登录 DolphinScheduler</h3><p>详细见伪集群安装部分的 登录 DolphinScheduler 配置章节</p><h3 id="启停服务-1"><a href="#启停服务-1" class="headerlink" title="启停服务"></a>启停服务</h3><p>详细见伪集群安装部分的 启停服务 配置章节</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;本文档部署了最新的 3.14 版本， 官网上的部署文档有些错误， 本文中进行了修复&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;1-DolphinScheduler-简介&quot;&gt;&lt;a href=&quot;#1-DolphinScheduler-简介&quot; class=&quot;headerl
      
    
    </summary>
    
    
      <category term="dolphinScheduler" scheme="https://www.hnbian.cn/categories/dolphinScheduler/"/>
    
    
      <category term="dolphinScheduler" scheme="https://www.hnbian.cn/tags/dolphinScheduler/"/>
    
  </entry>
  
  <entry>
    <title>使用 assembly 对 SpringBoot 代码打包</title>
    <link href="https://www.hnbian.cn/posts/ea571375.html"/>
    <id>https://www.hnbian.cn/posts/ea571375.html</id>
    <published>2023-03-17T08:18:16.000Z</published>
    <updated>2023-03-17T16:02:22.251Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><p>最近向服务器上部署 spring boot项目时，会遇到一个问题，那就是 spring boot 打包时，会将自己写的代码和项目的所有依赖文件打成一个可执行的 jar 包。通常我们的项目都是运行在服务器上的，当项目更新时，每次都要向服务器上传这个包。如果项目的依赖包很多，那么这个文件就会非常大。最近堡垒机网络不稳定， 上传包的时候总是失败， 导致部署效率很低。</p><ul><li>默认的 maven 配置</li></ul><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.springframework.boot<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spring-boot-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span></code></pre><p>如果能将项目外部依赖和自己的代码包分开打包，当修改项目后，只需要再次覆盖修改后的包，那就可以完美解决这个问题</p><h2 id="2-解决方案"><a href="#2-解决方案" class="headerlink" title="2. 解决方案"></a>2. 解决方案</h2><p>可以使用 maven 的<code>assembly</code>插件 将项目代码与依赖分别打包。</p><h3 id="2-1-Assembly-介绍"><a href="#2-1-Assembly-介绍" class="headerlink" title="2.1 Assembly 介绍"></a>2.1 Assembly 介绍</h3><p>Maven Assembly 插件是 Maven 的一个插件，用于将多个 Maven 项目构建成一个归档文件（如 jar、zip、tar.gz 等），方便部署和发布。</p><p>该插件通过描述归档文件的内容和组成部分，可以将一个项目的多个模块打包成一个单独的归档文件，也可以将一个模块的多个子模块打包成一个单独的归档文件。该插件支持不同类型的归档文件，例如 jar、zip、tar.gz 等，还可以支持自定义的归档文件类型。</p><p>Maven Assembly 插件的使用通常需要配置一个 XML 文件，该文件描述了归档文件的组成部分和各个部分的打包规则。通过该文件可以定义哪些文件需要包含在归档文件中，以及这些文件的排列方式、文件名和目录结构等。同时，还可以通过 Maven 的过滤器机制对文件进行过滤和替换，以适应不同的环境需求。</p><p>使用 Maven Assembly 插件，可以将多个项目、模块或者组件组合成一个归档文件，实现一次性部署和发布的效果，方便开发和维护。</p><h3 id="2-2-创建配置文件"><a href="#2-2-创建配置文件" class="headerlink" title="2.2 创建配置文件"></a>2.2 创建配置文件</h3><p>在项目中创建一个文件与配置文件，<code>src/main/assembly/assembly.xml</code></p><p><img src="https://images.hnbian.cn/windows/image-20230317160530728.png" alt></p><h3 id="2-3-配置assembly-xml文件"><a href="#2-3-配置assembly-xml文件" class="headerlink" title="2.3 配置assembly.xml文件"></a>2.3 配置assembly.xml文件</h3><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>assembly</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2<span class="token punctuation">"</span></span>          <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>          <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!--        必须写，否则打包时会有 assembly ID must be present and non-empty 错误        这个名字最终会追加到打包的名字的末尾，如项目的名字为 speed-api-0.0.1-SNAPSHOT,        则最终生成的包名为 speed-api-0.0.1-SNAPSHOT-bin.zip     --></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>bin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!-- 打包后的文件格式,可以是zip,tar,tar.gz,tar.bz2,jar,war,dir --></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>formats</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>format</span><span class="token punctuation">></span></span>zip<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>format</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>formats</span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!-- 压缩包下是否生成和项目名相同的根目录 --></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>includeBaseDirectory</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>includeBaseDirectory</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencySets</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencySet</span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 不使用项目的artifact，第三方jar不要解压，打包进zip文件的lib目录 --></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>useProjectArtifact</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>useProjectArtifact</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>outputDirectory</span><span class="token punctuation">></span></span>lib<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>outputDirectory</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>unpack</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>unpack</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencySet</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencySets</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>fileSets</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 把项目相关的说明文件，打包进zip文件的根目录 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>fileSet</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>directory</span><span class="token punctuation">></span></span>${project.basedir}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>directory</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>outputDirectory</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>outputDirectory</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>includes</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span><span class="token punctuation">></span></span>README*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span><span class="token punctuation">></span></span>LICENSE*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span><span class="token punctuation">></span></span>NOTICE*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>includes</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>fileSet</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 把项目的配置文件，打包进zip文件的config目录 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>fileSet</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>directory</span><span class="token punctuation">></span></span>${project.basedir}/src/main/resources<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>directory</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>outputDirectory</span><span class="token punctuation">></span></span>config<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>outputDirectory</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>fileSet</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 把项目的脚本文件，打包进zip文件的bin目录 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>fileSet</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>directory</span><span class="token punctuation">></span></span>${project.basedir}/src/main/bin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>directory</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>outputDirectory</span><span class="token punctuation">></span></span>bin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>outputDirectory</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>fileSet</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 把项目自己编译出来的jar文件，打包进zip文件的根目录 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>fileSet</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>directory</span><span class="token punctuation">></span></span>${project.build.directory}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>directory</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>outputDirectory</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>outputDirectory</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>includes</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span><span class="token punctuation">></span></span>*.jar<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>includes</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>fileSet</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>fileSets</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>assembly</span><span class="token punctuation">></span></span></code></pre><h3 id="2-4-pom-xml-的配置"><a href="#2-4-pom-xml-的配置" class="headerlink" title="2.4 pom.xml 的配置"></a>2.4 pom.xml 的配置</h3><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 指定启动类，将依赖打成外部jar包 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-jar-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>archive</span><span class="token punctuation">></span></span>                    <span class="token comment" spellcheck="true">&lt;!-- 生成的jar中，不要包含pom.xml和pom.properties这两个文件 --></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>addMavenDescriptor</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>addMavenDescriptor</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>manifest</span><span class="token punctuation">></span></span>                        <span class="token comment" spellcheck="true">&lt;!-- 是否要把第三方jar放到manifest的classpath中 --></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>addClasspath</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>addClasspath</span><span class="token punctuation">></span></span>                        <span class="token comment" spellcheck="true">&lt;!-- 外部依赖jar包的最终位置 --></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>classpathPrefix</span><span class="token punctuation">></span></span>lib/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>classpathPrefix</span><span class="token punctuation">></span></span>                        <span class="token comment" spellcheck="true">&lt;!-- 项目启动类 --></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 这里写你的主类 --></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>manifest</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>archive</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 使用assembly打包 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptors</span><span class="token punctuation">></span></span>                    <span class="token comment" spellcheck="true">&lt;!-- assembly配置文件位置 --></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptor</span><span class="token punctuation">></span></span>src/main/assembly/assembly.xml<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptor</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptors</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 打包发布时，跳过单元测试 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-surefire-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>skipTests</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>skipTests</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span></code></pre><h3 id="2-5-打包效果"><a href="#2-5-打包效果" class="headerlink" title="2.5 打包效果"></a>2.5 打包效果</h3><p><img src="https://images.hnbian.cn/windows/image-20230317160857245.png" alt="target 文件夹内容"></p><p><img src="https://images.hnbian.cn/windows/image-20230317160953233.png" alt="压缩文件中的内容"></p><h2 id="3-项目部署与运行"><a href="#3-项目部署与运行" class="headerlink" title="3. 项目部署与运行"></a>3. 项目部署与运行</h2><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 将压缩文件上传到服务器</span><span class="token punctuation">[</span>root@node1 opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>total 543916-rw-r--r-- 1 root root 474052725 Mar 17 15:42 flink-1.16.1-bin-scala_2.12.tgz-rw-r--r-- 1 root root  82900972 Mar 17 16:15 milvus-api-0.0.1-SNAPSHOT-bin.zip<span class="token comment" spellcheck="true"># 2. 解压</span>unzip milvus-api-0.0.1-SNAPSHOT-bin.zip -d milvus-api/<span class="token comment" spellcheck="true"># 3. 切换路径</span><span class="token punctuation">[</span>root@node1 opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd milvus-api</span><span class="token comment" spellcheck="true"># 查看文件列表</span><span class="token punctuation">[</span>root@node1 milvus-api<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>total 72drwxr-xr-x 2 root root    56 Mar  2 14:41 configdrwxr-xr-x 2 root root  8192 Mar 17 11:17 lib-rw-r--r-- 1 root root 54706 Mar 17 11:18 milvus-api-0.0.1-SNAPSHOT.jar-rw-r--r-- 1 root root    35 Aug 18  2022 README.md<span class="token comment" spellcheck="true"># 4. 执行  治理没有另外写执行脚本， 可以自己编写一个</span><span class="token punctuation">[</span>root@node1 milvus-api<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># java -jar milvus-api-0.0.1-SNAPSHOT.jar</span>SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding <span class="token keyword">in</span> <span class="token punctuation">[</span>jar:file:/opt/milvus-api/lib/logback-classic-1.2.3.jar<span class="token operator">!</span>/org/slf4j/impl/StaticLoggerBinder.class<span class="token punctuation">]</span>SLF4J: Found binding <span class="token keyword">in</span> <span class="token punctuation">[</span>jar:file:/opt/milvus-api/lib/log4j-slf4j-impl-2.10.0.jar<span class="token operator">!</span>/org/slf4j/impl/StaticLoggerBinder.class<span class="token punctuation">]</span>SLF4J: See http://www.slf4j.org/codes.html<span class="token comment" spellcheck="true">#multiple_bindings for an explanation.</span>SLF4J: Actual binding is of <span class="token function">type</span> <span class="token punctuation">[</span>ch.qos.logback.classic.util.ContextSelectorStaticBinder<span class="token punctuation">]</span>  <span class="token keyword">.</span>   ____          _            __ _ _ /\\ / ___<span class="token string">'_ __ _ _(_)_ __  __ _ \ \ \ \( ( )\___ | '</span>_ <span class="token operator">|</span> <span class="token string">'_| | '</span>_ \/ _` <span class="token operator">|</span> \ \ \ \ \\/  ___<span class="token punctuation">)</span><span class="token operator">|</span> <span class="token operator">|</span>_<span class="token punctuation">)</span><span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">|</span> <span class="token operator">||</span> <span class="token punctuation">(</span>_<span class="token operator">|</span> <span class="token operator">|</span>  <span class="token punctuation">)</span> <span class="token punctuation">)</span> <span class="token punctuation">)</span> <span class="token punctuation">)</span>  '  <span class="token operator">|</span>____<span class="token operator">|</span> .__<span class="token operator">|</span>_<span class="token operator">|</span> <span class="token operator">|</span>_<span class="token operator">|</span>_<span class="token operator">|</span> <span class="token operator">|</span>_\__, <span class="token operator">|</span> / / / / <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span>_<span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">|</span>___/<span class="token operator">=</span>/_/_/_/ :: Spring Boot ::        <span class="token punctuation">(</span>v2.0.4.RELEASE<span class="token punctuation">)</span></code></pre><p>后续再次更新服务只需要更新业务代码就好， 无需更新繁多的依赖文件了。</p><p>参考文档： <a href="https://www.zhangjava.com/springboot%E5%B0%86%E9%A1%B9%E7%9B%AE%E4%B8%8E%E4%BE%9D%E8%B5%96%E5%88%86%E5%BC%80%E6%89%93%E5%8C%85/" target="_blank" rel="noopener">https://www.zhangjava.com/springboot%E5%B0%86%E9%A1%B9%E7%9B%AE%E4%B8%8E%E4%BE%9D%E8%B5%96%E5%88%86%E5%BC%80%E6%89%93%E5%8C%85/</a></p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1. 背景&quot;&gt;&lt;/a&gt;1. 背景&lt;/h2&gt;&lt;p&gt;最近向服务器上部署 spring boot项目时，会遇到一个问题，那就是 spring boot 打包时，会将自己写的代
      
    
    </summary>
    
    
      <category term="java" scheme="https://www.hnbian.cn/categories/java/"/>
    
    
      <category term="java" scheme="https://www.hnbian.cn/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Async Hbase 时频繁遇到 too many open file 异常</title>
    <link href="https://www.hnbian.cn/posts/87e287bc.html"/>
    <id>https://www.hnbian.cn/posts/87e287bc.html</id>
    <published>2023-03-14T01:46:10.000Z</published>
    <updated>2023-03-14T15:24:58.186Z</updated>
    
    <content type="html"><![CDATA[<p>在使用 Async Hbase 时频繁遇到 too many open file 异常，程序自动重启后会立即报错，具体报错日志如下：</p><ul><li>flink版本：1.16.0</li><li>asynchbase版本：1.8.2</li></ul><pre class=" language-java"><code class="language-java"><span class="token number">2023</span><span class="token operator">-</span><span class="token number">03</span><span class="token operator">-</span><span class="token number">08</span> <span class="token number">16</span><span class="token operator">:</span><span class="token number">15</span><span class="token operator">:</span><span class="token number">39</span>org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>ChannelException<span class="token operator">:</span> Failed to create a selector<span class="token punctuation">.</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>AbstractNioSelector<span class="token punctuation">.</span><span class="token function">openSelector</span><span class="token punctuation">(</span>AbstractNioSelector<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">343</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>AbstractNioSelector<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>AbstractNioSelector<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">100</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>AbstractNioWorker<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>AbstractNioWorker<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">52</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>NioWorker<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>NioWorker<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">45</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>NioWorkerPool<span class="token punctuation">.</span><span class="token function">createWorker</span><span class="token punctuation">(</span>NioWorkerPool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">45</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>NioWorkerPool<span class="token punctuation">.</span><span class="token function">createWorker</span><span class="token punctuation">(</span>NioWorkerPool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">28</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>AbstractNioWorkerPool<span class="token punctuation">.</span><span class="token function">newWorker</span><span class="token punctuation">(</span>AbstractNioWorkerPool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">143</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>AbstractNioWorkerPool<span class="token punctuation">.</span><span class="token function">init</span><span class="token punctuation">(</span>AbstractNioWorkerPool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">81</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>NioWorkerPool<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>NioWorkerPool<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">39</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>async<span class="token punctuation">.</span>HBaseClient<span class="token punctuation">.</span><span class="token function">defaultChannelFactory</span><span class="token punctuation">(</span>HBaseClient<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">707</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>async<span class="token punctuation">.</span>HBaseClient<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>HBaseClient<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">507</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>async<span class="token punctuation">.</span>HBaseClient<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>HBaseClient<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">496</span><span class="token punctuation">)</span>at com<span class="token punctuation">.</span>topgame<span class="token punctuation">.</span>function<span class="token punctuation">.</span>HbaseDimTrackerAsyncFunc<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>HbaseDimTrackerAsyncFunc<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">37</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>util<span class="token punctuation">.</span>FunctionUtils<span class="token punctuation">.</span><span class="token function">openFunction</span><span class="token punctuation">(</span>FunctionUtils<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">34</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>AbstractUdfStreamOperator<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>AbstractUdfStreamOperator<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">100</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>async<span class="token punctuation">.</span>AsyncWaitOperator<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>AsyncWaitOperator<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">214</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>RegularOperatorChain<span class="token punctuation">.</span><span class="token function">initializeStateAndOpenOperators</span><span class="token punctuation">(</span>RegularOperatorChain<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">107</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">restoreGates</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">726</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTaskActionExecutor$<span class="token number">1</span><span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span>StreamTaskActionExecutor<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">55</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">restoreInternal</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">702</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">restore</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">669</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">runWithSystemExitMonitoring</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">935</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">restoreAndInvoke</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">904</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">doRun</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">728</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">550</span><span class="token punctuation">)</span>at java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>Thread<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Thread<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">748</span><span class="token punctuation">)</span>Caused by<span class="token operator">:</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token operator">:</span> Too many open filesat sun<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>ch<span class="token punctuation">.</span>IOUtil<span class="token punctuation">.</span><span class="token function">makePipe</span><span class="token punctuation">(</span>Native Method<span class="token punctuation">)</span>at sun<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>ch<span class="token punctuation">.</span>EPollSelectorImpl<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>EPollSelectorImpl<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">65</span><span class="token punctuation">)</span>at sun<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>ch<span class="token punctuation">.</span>EPollSelectorProvider<span class="token punctuation">.</span><span class="token function">openSelector</span><span class="token punctuation">(</span>EPollSelectorProvider<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">36</span><span class="token punctuation">)</span>at java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>Selector<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>Selector<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">227</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>SelectorUtil<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>SelectorUtil<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">63</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>jboss<span class="token punctuation">.</span>netty<span class="token punctuation">.</span>channel<span class="token punctuation">.</span>socket<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>AbstractNioSelector<span class="token punctuation">.</span><span class="token function">openSelector</span><span class="token punctuation">(</span>AbstractNioSelector<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">341</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token number">25</span> more</code></pre><p>对当前程序使用文件描述符数量进行监控，发现当程序抛出如下错误自动重启后，程序使用文件描述符数量激增。错误日志如下</p><pre class=" language-java"><code class="language-java">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token operator">:</span> Could not perform checkpoint <span class="token number">5</span> <span class="token keyword">for</span> operator async wait <span class="token function">operator</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">9</span><span class="token punctuation">)</span>#<span class="token number">0</span><span class="token punctuation">.</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">triggerCheckpointOnBarrier</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1238</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>CheckpointBarrierHandler<span class="token punctuation">.</span><span class="token function">notifyCheckpoint</span><span class="token punctuation">(</span>CheckpointBarrierHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">147</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span><span class="token function">triggerCheckpoint</span><span class="token punctuation">(</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">287</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>access$<span class="token function">100</span><span class="token punctuation">(</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">64</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>SingleCheckpointBarrierHandler$ControllerImpl<span class="token punctuation">.</span><span class="token function">triggerGlobalCheckpoint</span><span class="token punctuation">(</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">488</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>AbstractAlignedBarrierHandlerState<span class="token punctuation">.</span><span class="token function">triggerGlobalCheckpoint</span><span class="token punctuation">(</span>AbstractAlignedBarrierHandlerState<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">74</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>AbstractAlignedBarrierHandlerState<span class="token punctuation">.</span><span class="token function">barrierReceived</span><span class="token punctuation">(</span>AbstractAlignedBarrierHandlerState<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">66</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>lambda$processBarrier$<span class="token function">2</span><span class="token punctuation">(</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">234</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span><span class="token function">markCheckpointAlignedAndTransformState</span><span class="token punctuation">(</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">262</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span><span class="token function">processBarrier</span><span class="token punctuation">(</span>SingleCheckpointBarrierHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">231</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>CheckpointedInputGate<span class="token punctuation">.</span><span class="token function">handleEvent</span><span class="token punctuation">(</span>CheckpointedInputGate<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">181</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>CheckpointedInputGate<span class="token punctuation">.</span><span class="token function">pollNext</span><span class="token punctuation">(</span>CheckpointedInputGate<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">159</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>AbstractStreamTaskNetworkInput<span class="token punctuation">.</span><span class="token function">emitNext</span><span class="token punctuation">(</span>AbstractStreamTaskNetworkInput<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">110</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>io<span class="token punctuation">.</span>StreamOneInputProcessor<span class="token punctuation">.</span><span class="token function">processInput</span><span class="token punctuation">(</span>StreamOneInputProcessor<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">65</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">processInput</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">542</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>mailbox<span class="token punctuation">.</span>MailboxProcessor<span class="token punctuation">.</span><span class="token function">runMailboxLoop</span><span class="token punctuation">(</span>MailboxProcessor<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">231</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">runMailboxLoop</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">831</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">780</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">runWithSystemExitMonitoring</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">935</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">restoreAndInvoke</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">914</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">doRun</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">728</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>taskmanager<span class="token punctuation">.</span>Task<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Task<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">550</span><span class="token punctuation">)</span>at java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>Thread<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>Thread<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">748</span><span class="token punctuation">)</span>Caused by<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>checkpoint<span class="token punctuation">.</span>CheckpointException<span class="token operator">:</span> Could not complete snapshot <span class="token number">5</span> <span class="token keyword">for</span> operator async wait <span class="token function">operator</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">9</span><span class="token punctuation">)</span>#<span class="token number">0</span><span class="token punctuation">.</span> Failure reason<span class="token operator">:</span> Checkpoint was declined<span class="token punctuation">.</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>StreamOperatorStateHandler<span class="token punctuation">.</span><span class="token function">snapshotState</span><span class="token punctuation">(</span>StreamOperatorStateHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">269</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>StreamOperatorStateHandler<span class="token punctuation">.</span><span class="token function">snapshotState</span><span class="token punctuation">(</span>StreamOperatorStateHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">173</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>AbstractStreamOperator<span class="token punctuation">.</span><span class="token function">snapshotState</span><span class="token punctuation">(</span>AbstractStreamOperator<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">345</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>RegularOperatorChain<span class="token punctuation">.</span><span class="token function">checkpointStreamOperator</span><span class="token punctuation">(</span>RegularOperatorChain<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">228</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>RegularOperatorChain<span class="token punctuation">.</span><span class="token function">buildOperatorSnapshotFutures</span><span class="token punctuation">(</span>RegularOperatorChain<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">213</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>RegularOperatorChain<span class="token punctuation">.</span><span class="token function">snapshotState</span><span class="token punctuation">(</span>RegularOperatorChain<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">192</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>SubtaskCheckpointCoordinatorImpl<span class="token punctuation">.</span><span class="token function">takeSnapshotSync</span><span class="token punctuation">(</span>SubtaskCheckpointCoordinatorImpl<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">726</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>SubtaskCheckpointCoordinatorImpl<span class="token punctuation">.</span><span class="token function">checkpointState</span><span class="token punctuation">(</span>SubtaskCheckpointCoordinatorImpl<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">363</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span>lambda$performCheckpoint$<span class="token function">13</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1281</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTaskActionExecutor$<span class="token number">1</span><span class="token punctuation">.</span><span class="token function">runThrowing</span><span class="token punctuation">(</span>StreamTaskActionExecutor<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">50</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">performCheckpoint</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1269</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>StreamTask<span class="token punctuation">.</span><span class="token function">triggerCheckpointOnBarrier</span><span class="token punctuation">(</span>StreamTask<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1226</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token number">22</span> moreCaused by<span class="token operator">:</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ConcurrentModificationExceptionat java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>HashMap$HashIterator<span class="token punctuation">.</span><span class="token function">nextNode</span><span class="token punctuation">(</span>HashMap<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1442</span><span class="token punctuation">)</span>at java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>HashMap$EntryIterator<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span>HashMap<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1476</span><span class="token punctuation">)</span>at java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>HashMap$EntryIterator<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span>HashMap<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">1474</span><span class="token punctuation">)</span>at com<span class="token punctuation">.</span>esotericsoftware<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span>serializers<span class="token punctuation">.</span>MapSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>MapSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">156</span><span class="token punctuation">)</span>at com<span class="token punctuation">.</span>esotericsoftware<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span>serializers<span class="token punctuation">.</span>MapSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>MapSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">21</span><span class="token punctuation">)</span>at com<span class="token punctuation">.</span>esotericsoftware<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span>Kryo<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>Kryo<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">862</span><span class="token punctuation">)</span>at com<span class="token punctuation">.</span>esotericsoftware<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span>serializers<span class="token punctuation">.</span>CollectionSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>CollectionSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">131</span><span class="token punctuation">)</span>at com<span class="token punctuation">.</span>esotericsoftware<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span>serializers<span class="token punctuation">.</span>CollectionSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>CollectionSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">22</span><span class="token punctuation">)</span>at com<span class="token punctuation">.</span>esotericsoftware<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span>Kryo<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>Kryo<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">862</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>typeutils<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span>KryoSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>KryoSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">308</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>typeutils<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>TupleSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>TupleSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">115</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>typeutils<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>TupleSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>TupleSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">37</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>streamrecord<span class="token punctuation">.</span>StreamElementSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>StreamElementSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">106</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>streamrecord<span class="token punctuation">.</span>StreamElementSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>StreamElementSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">46</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>ArrayListSerializer<span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>ArrayListSerializer<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">75</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>PartitionableListState<span class="token punctuation">.</span>&lt;init<span class="token operator">></span><span class="token punctuation">(</span>PartitionableListState<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">65</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>PartitionableListState<span class="token punctuation">.</span><span class="token function">deepCopy</span><span class="token punctuation">(</span>PartitionableListState<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">79</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>DefaultOperatorStateBackendSnapshotStrategy<span class="token punctuation">.</span><span class="token function">syncPrepareResources</span><span class="token punctuation">(</span>DefaultOperatorStateBackendSnapshotStrategy<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">77</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>DefaultOperatorStateBackendSnapshotStrategy<span class="token punctuation">.</span><span class="token function">syncPrepareResources</span><span class="token punctuation">(</span>DefaultOperatorStateBackendSnapshotStrategy<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">36</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>SnapshotStrategyRunner<span class="token punctuation">.</span><span class="token function">snapshot</span><span class="token punctuation">(</span>SnapshotStrategyRunner<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">77</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>DefaultOperatorStateBackend<span class="token punctuation">.</span><span class="token function">snapshot</span><span class="token punctuation">(</span>DefaultOperatorStateBackend<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">230</span><span class="token punctuation">)</span>at org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>operators<span class="token punctuation">.</span>StreamOperatorStateHandler<span class="token punctuation">.</span><span class="token function">snapshotState</span><span class="token punctuation">(</span>StreamOperatorStateHandler<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">230</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token number">33</span> more</code></pre><p>对文件描述符分析后发现，发现绝大部分文件描述符如下（占比：15.4k/15.9k）,怀疑是程序重启后之前的文件描述符没有释放</p><pre class=" language-bash"><code class="language-bash"><span class="token function">lsof</span> -U COMMAND    PID USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAMEjava    168258 yarn *648u  a_inode               0,10         0       8670 <span class="token punctuation">[</span>eventpoll<span class="token punctuation">]</span>java    168258 yarn *652r     FIFO                0,9       0t0  850723636 pipejava    168258 yarn *653w     FIFO                0,9       0t0  850723636 pipejava    168258 yarn *654u  a_inode               0,10         0       8670 <span class="token punctuation">[</span>eventpoll<span class="token punctuation">]</span>java    168258 yarn *655r     FIFO                0,9       0t0  850723637 pipejava    168258 yarn *656w     FIFO                0,9       0t0  850723637 pipejava    168258 yarn *657u  a_inode               0,10         0       8670 <span class="token punctuation">[</span>eventpoll<span class="token punctuation">]</span>java    168258 yarn *658r     FIFO                0,9       0t0  850723638 pipejava    168258 yarn *659w     FIFO                0,9       0t0  850723638 pipejava    168258 yarn *660u  a_inode               0,10         0       8670 <span class="token punctuation">[</span>eventpoll<span class="token punctuation">]</span>java    168258 yarn *661w     FIFO                0,9       0t0  850723639 pipe</code></pre><p>pom</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>asynchbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.8.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>关键代码如下：</p><pre class=" language-java"><code class="language-java">SingleOutputStreamOperator asyncFunc <span class="token operator">=</span> AsyncDataStream    <span class="token punctuation">.</span><span class="token function">orderedWaitWithRetry</span><span class="token punctuation">(</span>         source<span class="token punctuation">,</span>         <span class="token keyword">new</span> <span class="token class-name">HbaseDimensionAsyncFunc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token number">60</span><span class="token punctuation">,</span>         TimeUnit<span class="token punctuation">.</span>SECONDS<span class="token punctuation">,</span>         <span class="token number">300</span><span class="token punctuation">,</span>         <span class="token function">AsyFixedRetry</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token function">uid</span><span class="token punctuation">(</span><span class="token string">"asyncFunc"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HbaseDimensionAsyncFunc</span> <span class="token keyword">extends</span> <span class="token class-name">RichAsyncFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> ArrayList<span class="token operator">&lt;</span>HashMap<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">>>></span><span class="token punctuation">,</span> ArrayList<span class="token operator">&lt;</span>HashMap<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">>>></span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> HBaseClient client <span class="token operator">=</span> null<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// open() 方法在 RichAsyncFunction 生命周期中只会调用一次，用于初始化 Hbase 客户端</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">open</span><span class="token punctuation">(</span>Configuration configuration<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        client <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HBaseClient</span><span class="token punctuation">(</span>PropUtils<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token string">"bigdata.hosts"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// asyncInvoke() 方法是异步调用的核心逻辑，用于执行 Hbase 查询操作</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">asyncInvoke</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> ArrayList<span class="token operator">&lt;</span>HashMap<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">>>></span> o<span class="token punctuation">,</span> ResultFuture<span class="token operator">&lt;</span>ArrayList<span class="token operator">&lt;</span>HashMap<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">>>></span> resultFuture<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        String uuid <span class="token operator">=</span> o<span class="token punctuation">.</span>f0<span class="token punctuation">;</span>        List<span class="token operator">&lt;</span>GetRequest<span class="token operator">></span> requests <span class="token operator">=</span> <span class="token function">generateRequests</span><span class="token punctuation">(</span>uuid<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 使用异步 Hbase 客户端库查询 Hbase</span>        CompletableFuture<span class="token operator">&lt;</span>List<span class="token operator">&lt;</span>KeyValue<span class="token operator">>></span> future <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>requests<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 处理异步查询结果</span>        future<span class="token punctuation">.</span><span class="token function">thenApplyAsync</span><span class="token punctuation">(</span>keyValues <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 业务代码，对查询结果进行处理</span>            ArrayList<span class="token operator">&lt;</span>HashMap<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">>></span> result <span class="token operator">=</span> <span class="token function">processResult</span><span class="token punctuation">(</span>keyValues<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> result<span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">thenAcceptAsync</span><span class="token punctuation">(</span>result <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 将处理结果发送给 Flink 算子</span>            resultFuture<span class="token punctuation">.</span><span class="token function">complete</span><span class="token punctuation">(</span>Collections<span class="token punctuation">.</span><span class="token function">singletonList</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>通过代码看作业在Failover 时的确会有 HBaseClient 的资源泄露。</p><p>在 HbaseDimensionAsyncFunc 中重写一下 close 方法，释放掉 HBaseClient。</p><p>关闭资源时还需要注意一下事项：</p><ol><li>数据刷盘：在关闭连接时，需要将缓冲区中的数据刷盘，即将缓冲区中的数据写入磁盘。这可以确保数据被正确地保存到文件系统中，而不会丢失或损坏。</li><li>资源关闭：在释放资源之前，需要确保已经完成了所有的操作，并将资源关闭。需要在调用 <code>close()</code> 方法之前，确保所有的数据都已经被写入磁盘，然后再关闭。</li><li>Future 取消：在使用 Java 中的 <code>Future</code> 接口时，如果任务还没有完成，就需要取消它。在取消 <code>Future</code> 时，需要使用 <code>cancel()</code> 方法，并传递一个布尔值来指示是否需要中断任务的执行。这可以确保任务被正确地停止，并释放相关资源。</li></ol><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在使用 Async Hbase 时频繁遇到 too many open file 异常，程序自动重启后会立即报错，具体报错日志如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;flink版本：1.16.0&lt;/li&gt;
&lt;li&gt;asynchbase版本：1.8.2&lt;/li&gt;
&lt;/ul&gt;
&lt;pr
      
    
    </summary>
    
    
      <category term="hbase" scheme="https://www.hnbian.cn/categories/hbase/"/>
    
    
      <category term="hbase" scheme="https://www.hnbian.cn/tags/hbase/"/>
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
  </entry>
  
  <entry>
    <title>安装 Ambari 时遇到的异常记录</title>
    <link href="https://www.hnbian.cn/posts/e33b82cd.html"/>
    <id>https://www.hnbian.cn/posts/e33b82cd.html</id>
    <published>2023-03-08T07:12:49.000Z</published>
    <updated>2023-05-12T09:58:07.079Z</updated>
    
    <content type="html"><![CDATA[<ul><li>由于最近公司机房断电，导致几台测试环境 Ambari 服务器损坏， 所以对 Ambari服务进行了重装， 下面对此次安装过程中遇见的问题与解决办法进行记录</li></ul><h2 id="1-安装-unzip"><a href="#1-安装-unzip" class="headerlink" title="1. 安装 unzip"></a>1. 安装 unzip</h2><pre class=" language-bash"><code class="language-bash">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/var/lib/ambari-agent/cache/stack-hooks/before-INSTALL/scripts/hook.py"</span>, line 37, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    BeforeInstallHook<span class="token punctuation">(</span><span class="token punctuation">)</span>.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/libraries/script/script.py"</span>, line 352, <span class="token keyword">in</span> execute    method<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/stack-hooks/before-INSTALL/scripts/hook.py"</span>, line 33, <span class="token keyword">in</span> hook    install_packages<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/stack-hooks/before-INSTALL/scripts/shared_initialization.py"</span>, line 37, <span class="token keyword">in</span> install_packages    retry_count<span class="token operator">=</span>params.agent_stack_retry_count<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/base.py"</span>, line 125, <span class="token keyword">in</span> __new__    cls<span class="token punctuation">(</span>names_list.pop<span class="token punctuation">(</span>0<span class="token punctuation">)</span>, env, provider, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/base.py"</span>, line 166, <span class="token keyword">in</span> __init__    self.env.run<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/environment.py"</span>, line 160, <span class="token keyword">in</span> run    self.run_action<span class="token punctuation">(</span>resource, action<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/environment.py"</span>, line 124, <span class="token keyword">in</span> run_action    provider_action<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/providers/packaging.py"</span>, line 30, <span class="token keyword">in</span> action_install    self._pkg_manager.install_package<span class="token punctuation">(</span>package_name, self.__create_context<span class="token punctuation">(</span><span class="token punctuation">))</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/ambari_commons/repo_manager/yum_manager.py"</span>, line 219, <span class="token keyword">in</span> install_package    shell.repository_manager_executor<span class="token punctuation">(</span>cmd, self.properties, context<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/ambari_commons/shell.py"</span>, line 753, <span class="token keyword">in</span> repository_manager_executor    raise RuntimeError<span class="token punctuation">(</span>message<span class="token punctuation">)</span>RuntimeError: Failed to execute <span class="token function">command</span> <span class="token string">'/usr/bin/yum -y install unzip'</span>, exited with code <span class="token string">'1'</span>, message: <span class="token string">' One of the configured repositories failed (Unknown), and yum doesn'</span>t have enough cached data to continue. At this point the only safe thing yum can <span class="token keyword">do</span> is fail. There are a few ways to work <span class="token string">"fix"</span> this:     1. Contact the upstream <span class="token keyword">for</span> the repository and get them to fix the problem.     2. Reconfigure the baseurl/etc. <span class="token keyword">for</span> the repository, to point to a working        upstream. This is <span class="token function">most</span> often useful <span class="token keyword">if</span> you are using a newer        distribution release than is supported by the repository <span class="token punctuation">(</span>and the        packages <span class="token keyword">for</span> the previous distribution release still work<span class="token punctuation">)</span>.     3. Run the <span class="token function">command</span> with the repository temporarily disabled            yum --disablerepo<span class="token operator">=</span><span class="token operator">&lt;</span>repoid<span class="token operator">></span> <span class="token punctuation">..</span>.     4. Disable the repository permanently, so yum won't use it by default. Yum        will <span class="token keyword">then</span> just ignore the repository <span class="token keyword">until</span> you permanently <span class="token function">enable</span> it        again or use --enablerepo <span class="token keyword">for</span> temporary usage:            yum-config-manager --disable <span class="token operator">&lt;</span>repoid<span class="token operator">></span>        or            subscription-manager repos --disable<span class="token operator">=</span><span class="token operator">&lt;</span>repoid<span class="token operator">></span>     5. Configure the failing repository to be skipped, <span class="token keyword">if</span> it is unavailable.        Note that yum will try to contact the repo. when it runs <span class="token function">most</span> commands,        so will have to try and fail each <span class="token function">time</span> <span class="token punctuation">(</span>and thus. yum will be be much        slower<span class="token punctuation">)</span>. If it is a very temporary problem though, this is often a <span class="token function">nice</span>        compromise:            yum-config-manager --save --setopt<span class="token operator">=</span><span class="token operator">&lt;</span>repoid<span class="token operator">></span>.skip_if_unavailable<span class="token operator">=</span>trueCannot <span class="token function">find</span> a valid baseurl <span class="token keyword">for</span> repo: HDP-3.1-repo-2</code></pre><ul><li>下载</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 下载地址</span>http://www.rpmfind.net/linux/rpm2html/search.php?query<span class="token operator">=</span>unzip<span class="token operator">&amp;</span>submit<span class="token operator">=</span>Search+<span class="token punctuation">..</span>.<span class="token operator">&amp;</span>system<span class="token operator">=</span>centos<span class="token operator">&amp;</span>arch<span class="token operator">=</span><span class="token comment" spellcheck="true"># 下载文件</span>unzip-6.0-46.el8.x86_64.rpm<span class="token comment" spellcheck="true"># 或者 </span><span class="token function">wget</span> http://www.rpmfind.net/linux/centos/8-stream/BaseOS/x86_64/os/Packages/unzip-6.0-46.el8.x86_64.rpm</code></pre><ul><li>安装</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#1.查看 unzip 是否被安装</span>rpm -qa <span class="token operator">|</span> <span class="token function">grep</span> <span class="token function">zip</span><span class="token comment" spellcheck="true"># 2.先安装unzip：</span>rpm -ivh unzip-6.0-46.el8.x86_64.rpm</code></pre><h2 id="2-missing-libmysqlclient-so-18-64bit"><a href="#2-missing-libmysqlclient-so-18-64bit" class="headerlink" title="2. missing libmysqlclient.so.18()(64bit)"></a>2. missing libmysqlclient.so.18()(64bit)</h2><pre class=" language-bash"><code class="language-bash">Loaded plugins: fastestmirrorLoading mirror speeds from cached hostfileResolving Dependencies--<span class="token operator">></span> Running transaction check---<span class="token operator">></span> Package ambari-metrics-monitor.x86_64 0:2.7.3.0-139 will be installed--<span class="token operator">></span> Processing Dependency: python-devel <span class="token keyword">for</span> package: ambari-metrics-monitor-2.7.3.0-139.x86_64--<span class="token operator">></span> Processing Dependency: gcc <span class="token keyword">for</span> package: ambari-metrics-monitor-2.7.3.0-139.x86_64--<span class="token operator">></span> Finished Dependency ResolutionError: Package: ambari-metrics-monitor-2.7.3.0-139.x86_64 <span class="token punctuation">(</span>ambari-2.7.3.0<span class="token punctuation">)</span>           Requires: gccError: Package: ambari-metrics-monitor-2.7.3.0-139.x86_64 <span class="token punctuation">(</span>ambari-2.7.3.0<span class="token punctuation">)</span>           Requires: python-devel You could try using --skip-broken to work around the problem** Found 2 pre-existing rpmdb problem<span class="token punctuation">(</span>s<span class="token punctuation">)</span>, <span class="token string">'yum check'</span> output follows:2:postfix-2.10.1-9.el7.x86_64 has missing requires of libmysqlclient.so.18<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>64bit<span class="token punctuation">)</span>2:postfix-2.10.1-9.el7.x86_64 has missing requires of libmysqlclient.so.18<span class="token punctuation">(</span>libmysqlclient_18<span class="token punctuation">)</span><span class="token punctuation">(</span>64bit<span class="token punctuation">)</span></code></pre><ul><li>原因</li></ul><p>缺少包</p><ul><li>解决 安装 RPM 包</li></ul><p>重点关注：libmysqlclient.so.18()(64bit)</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 下载</span><span class="token function">wget</span> http://www.percona.com/redir/downloads/Percona-XtraDB-Cluster/5.5.37-25.10/RPM/rhel6/x86_64/Percona-XtraDB-Cluster-shared-55-5.5.37-25.10.756.el6.x86_64.rpm<span class="token comment" spellcheck="true"># 安装</span>rpm -ivh Percona-XtraDB-Cluster-shared-55-5.5.37-25.10.756.el6.x86_64.rpm</code></pre><h2 id="3-Cannot-find-a-valid-baseurl-for-repo-HDP-UTILS-1-1-0-22-repo-2"><a href="#3-Cannot-find-a-valid-baseurl-for-repo-HDP-UTILS-1-1-0-22-repo-2" class="headerlink" title="3. Cannot find a valid baseurl for repo: HDP-UTILS-1.1.0.22-repo-2"></a>3. Cannot find a valid baseurl for repo: HDP-UTILS-1.1.0.22-repo-2</h2><ul><li>报错日志</li></ul><pre class=" language-bash"><code class="language-bash">2023-03-08 11:48:20,944 - The <span class="token string">'hadoop-hdfs-datanode'</span> component did not advertise a version. This may indicate a problem with the component packaging.Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/var/lib/ambari-agent/cache/stacks/HDP/3.0/services/HDFS/package/scripts/datanode.py"</span>, line 126, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    DataNode<span class="token punctuation">(</span><span class="token punctuation">)</span>.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/libraries/script/script.py"</span>, line 352, <span class="token keyword">in</span> execute    method<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/stacks/HDP/3.0/services/HDFS/package/scripts/datanode.py"</span>, line 45, <span class="token keyword">in</span> <span class="token function">install</span>    self.install_packages<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/libraries/script/script.py"</span>, line 839, <span class="token keyword">in</span> install_packages    name <span class="token operator">=</span> self.format_package_name<span class="token punctuation">(</span>package<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/libraries/script/script.py"</span>, line 562, <span class="token keyword">in</span> format_package_name    <span class="token keyword">return</span> self.get_package_from_available<span class="token punctuation">(</span>name<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/libraries/script/script.py"</span>, line 529, <span class="token keyword">in</span> get_package_from_available    raise Fail<span class="token punctuation">(</span><span class="token string">"No package found for {0}(expected name: {1})"</span>.format<span class="token punctuation">(</span>name, name_with_version<span class="token punctuation">))</span>resource_management.core.exceptions.Fail: No package found <span class="token keyword">for</span> hadoop_<span class="token variable">${stack_version}</span><span class="token punctuation">(</span>expected name: hadoop_3_1<span class="token punctuation">)</span>stdout:   /var/lib/ambari-agent/data/output-247.txt2023-03-08 11:48:14,746 - Stack Feature Version Info: Cluster Stack<span class="token operator">=</span>3.1, Command Stack<span class="token operator">=</span>None, Command Version<span class="token operator">=</span>None -<span class="token operator">></span> 3.12023-03-08 11:48:14,754 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf2023-03-08 11:48:14,756 - Group<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 11:48:14,757 - Group<span class="token punctuation">[</span><span class="token string">'hadoop'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 11:48:14,758 - Group<span class="token punctuation">[</span><span class="token string">'users'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 11:48:14,758 - User<span class="token punctuation">[</span><span class="token string">'zookeeper'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'hadoop'</span><span class="token punctuation">]</span>, <span class="token string">'uid'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 11:48:14,759 - User<span class="token punctuation">[</span><span class="token string">'ams'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'hadoop'</span><span class="token punctuation">]</span>, <span class="token string">'uid'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 11:48:14,760 - User<span class="token punctuation">[</span><span class="token string">'ambari-qa'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'hadoop'</span>, <span class="token string">'users'</span><span class="token punctuation">]</span>, <span class="token string">'uid'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 11:48:14,761 - User<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'hdfs'</span>, <span class="token string">'hadoop'</span><span class="token punctuation">]</span>, <span class="token string">'uid'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 11:48:14,762 - File<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'content'</span><span class="token keyword">:</span> StaticFile<span class="token punctuation">(</span><span class="token string">'changeToSecureUid.sh'</span><span class="token punctuation">)</span>, <span class="token string">'mode'</span><span class="token keyword">:</span> 0555<span class="token punctuation">}</span>2023-03-08 11:48:14,763 - Execute<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 0'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'not_if'</span><span class="token keyword">:</span> <span class="token string">'(test <span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> -u ambari-qa<span class="token variable">)</span></span> -gt 1000) || (false)'</span><span class="token punctuation">}</span>2023-03-08 11:48:14,773 - Skipping Execute<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa 0'</span><span class="token punctuation">]</span> due to not_if2023-03-08 11:48:14,774 - Group<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 11:48:14,775 - User<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'hdfs'</span>, <span class="token string">'hadoop'</span>, u<span class="token string">'hdfs'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 11:48:14,775 - FS Type: HDFS2023-03-08 11:48:14,776 - Directory<span class="token punctuation">[</span><span class="token string">'/etc/hadoop'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'mode'</span><span class="token keyword">:</span> 0755<span class="token punctuation">}</span>2023-03-08 11:48:14,776 - Directory<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'owner'</span><span class="token keyword">:</span> <span class="token string">'hdfs'</span>, <span class="token string">'group'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'mode'</span><span class="token keyword">:</span> 01777<span class="token punctuation">}</span>2023-03-08 11:48:14,797 - Repository<span class="token punctuation">[</span><span class="token string">'HDP-3.1-repo-2'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'base_url'</span><span class="token keyword">:</span> <span class="token string">''</span>, <span class="token string">'action'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'prepare'</span><span class="token punctuation">]</span>, <span class="token string">'components'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'HDP'</span>, <span class="token string">'main'</span><span class="token punctuation">]</span>, <span class="token string">'repo_template'</span><span class="token keyword">:</span> <span class="token string">'[{{repo_id}}]\nname={{repo_id}}\n{% if mirror_list %}mirrorlist={{mirror_list}}{% else %}baseurl={{base_url}}{% endif %}\n\npath=/\nenabled=1\ngpgcheck=0'</span>, <span class="token string">'repo_file_name'</span><span class="token keyword">:</span> <span class="token string">'ambari-hdp-2'</span>, <span class="token string">'mirror_list'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 11:48:14,810 - Repository<span class="token punctuation">[</span><span class="token string">'HDP-UTILS-1.1.0.22-repo-2'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'base_url'</span><span class="token keyword">:</span> <span class="token string">''</span>, <span class="token string">'action'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'prepare'</span><span class="token punctuation">]</span>, <span class="token string">'components'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'HDP-UTILS'</span>, <span class="token string">'main'</span><span class="token punctuation">]</span>, <span class="token string">'repo_template'</span><span class="token keyword">:</span> <span class="token string">'[{{repo_id}}]\nname={{repo_id}}\n{% if mirror_list %}mirrorlist={{mirror_list}}{% else %}baseurl={{base_url}}{% endif %}\n\npath=/\nenabled=1\ngpgcheck=0'</span>, <span class="token string">'repo_file_name'</span><span class="token keyword">:</span> <span class="token string">'ambari-hdp-2'</span>, <span class="token string">'mirror_list'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 11:48:14,815 - Repository<span class="token punctuation">[</span><span class="token string">'HDP-3.1-GPL-repo-2'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'base_url'</span><span class="token keyword">:</span> <span class="token string">'http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.0.0'</span>, <span class="token string">'action'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'prepare'</span><span class="token punctuation">]</span>, <span class="token string">'components'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'HDP-GPL'</span>, <span class="token string">'main'</span><span class="token punctuation">]</span>, <span class="token string">'repo_template'</span><span class="token keyword">:</span> <span class="token string">'[{{repo_id}}]\nname={{repo_id}}\n{% if mirror_list %}mirrorlist={{mirror_list}}{% else %}baseurl={{base_url}}{% endif %}\n\npath=/\nenabled=1\ngpgcheck=0'</span>, <span class="token string">'repo_file_name'</span><span class="token keyword">:</span> <span class="token string">'ambari-hdp-2'</span>, <span class="token string">'mirror_list'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 11:48:14,819 - Repository<span class="token punctuation">[</span>None<span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'action'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'create'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 11:48:14,820 - File<span class="token punctuation">[</span><span class="token string">'/tmp/tmp1hcs68'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'content'</span><span class="token keyword">:</span> <span class="token string">'[HDP-3.1-repo-2]\nname=HDP-3.1-repo-2\nbaseurl=\n\npath=/\nenabled=1\ngpgcheck=0\n[HDP-UTILS-1.1.0.22-repo-2]\nname=HDP-UTILS-1.1.0.22-repo-2\nbaseurl=\n\npath=/\nenabled=1\ngpgcheck=0\n[HDP-3.1-GPL-repo-2]\nname=HDP-3.1-GPL-repo-2\nbaseurl=http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.0.0\n\npath=/\nenabled=1\ngpgcheck=0'</span><span class="token punctuation">}</span>2023-03-08 11:48:14,821 - Writing File<span class="token punctuation">[</span><span class="token string">'/tmp/tmp1hcs68'</span><span class="token punctuation">]</span> because contents don<span class="token string">'t match2023-03-08 11:48:14,822 - File['</span>/tmp/tmpEskDfZ<span class="token string">'] {'</span>content<span class="token string">': StaticFile('</span>/etc/yum.repos.d/ambari-hdp-2.repo<span class="token string">')}2023-03-08 11:48:14,823 - Writing File['</span>/tmp/tmpEskDfZ<span class="token string">'] because contents don'</span>t match2023-03-08 11:48:14,823 - Rewriting /etc/yum.repos.d/ambari-hdp-2.repo since it has changed.2023-03-08 11:48:14,824 - File<span class="token punctuation">[</span><span class="token string">'/etc/yum.repos.d/ambari-hdp-2.repo'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'content'</span><span class="token keyword">:</span> StaticFile<span class="token punctuation">(</span><span class="token string">'/tmp/tmp1hcs68'</span><span class="token punctuation">)</span><span class="token punctuation">}</span>2023-03-08 11:48:14,825 - Writing File<span class="token punctuation">[</span><span class="token string">'/etc/yum.repos.d/ambari-hdp-2.repo'</span><span class="token punctuation">]</span> because contents don<span class="token string">'t match2023-03-08 11:48:14,826 - Package['</span>unzip<span class="token string">'] {'</span>retry_on_repo_unavailability<span class="token string">': False, '</span>retry_count<span class="token string">': 5}2023-03-08 11:48:14,963 - Skipping installation of existing package unzip2023-03-08 11:48:14,964 - Package['</span>curl<span class="token string">'] {'</span>retry_on_repo_unavailability<span class="token string">': False, '</span>retry_count<span class="token string">': 5}2023-03-08 11:48:14,974 - Skipping installation of existing package curl2023-03-08 11:48:14,974 - Package['</span>hdp-select<span class="token string">'] {'</span>retry_on_repo_unavailability<span class="token string">': False, '</span>retry_count<span class="token string">': 5}2023-03-08 11:48:14,983 - Skipping installation of existing package hdp-select2023-03-08 11:48:15,086 - call[('</span>ambari-python-wrap<span class="token string">', u'</span>/usr/bin/hdp-select<span class="token string">', '</span>versions<span class="token string">')] {}2023-03-08 11:48:15,126 - call returned (0, '</span><span class="token string">')2023-03-08 11:48:15,380 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf2023-03-08 11:48:15,382 - Stack Feature Version Info: Cluster Stack=3.1, Command Stack=None, Command Version=None -> 3.12023-03-08 11:48:15,410 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf2023-03-08 11:48:15,434 - Command repositories: HDP-3.1-repo-2, HDP-UTILS-1.1.0.22-repo-2, HDP-3.1-GPL-repo-22023-03-08 11:48:15,434 - Applicable repositories: HDP-3.1-repo-2, HDP-UTILS-1.1.0.22-repo-2, HDP-3.1-GPL-repo-22023-03-08 11:48:15,435 - Looking for matching packages in the following repositories: HDP-3.1-repo-2, HDP-UTILS-1.1.0.22-repo-2, HDP-3.1-GPL-repo-22023-03-08 11:48:15,671 - Command execution error: command = "/usr/bin/yum list available --showduplicates --disablerepo=* --enablerepo=HDP-3.1-repo-2", exit code = 1, stderr =  One of the configured repositories failed (Unknown), and yum doesn'</span>t have enough cached data to continue. At this point the only safe thing yum can <span class="token keyword">do</span> is fail. There are a few ways to work <span class="token string">"fix"</span> this:     1. Contact the upstream <span class="token keyword">for</span> the repository and get them to fix the problem.     2. Reconfigure the baseurl/etc. <span class="token keyword">for</span> the repository, to point to a working        upstream. This is <span class="token function">most</span> often useful <span class="token keyword">if</span> you are using a newer        distribution release than is supported by the repository <span class="token punctuation">(</span>and the        packages <span class="token keyword">for</span> the previous distribution release still work<span class="token punctuation">)</span>.     3. Run the <span class="token function">command</span> with the repository temporarily disabled            yum --disablerepo<span class="token operator">=</span><span class="token operator">&lt;</span>repoid<span class="token operator">></span> <span class="token punctuation">..</span>.     4. Disable the repository permanently, so yum won<span class="token string">'t use it by default. Yum        will then just ignore the repository until you permanently enable it        again or use --enablerepo for temporary usage:            yum-config-manager --disable &lt;repoid>        or            subscription-manager repos --disable=&lt;repoid>     5. Configure the failing repository to be skipped, if it is unavailable.        Note that yum will try to contact the repo. when it runs most commands,        so will have to try and fail each time (and thus. yum will be be much        slower). If it is a very temporary problem though, this is often a nice        compromise:            yum-config-manager --save --setopt=&lt;repoid>.skip_if_unavailable=trueCannot find a valid baseurl for repo: HDP-3.1-repo-22023-03-08 11:48:17,303 - Command execution error: command = "/usr/bin/yum list available --showduplicates --disablerepo=* --enablerepo=HDP-UTILS-1.1.0.22-repo-2", exit code = 1, stderr =  One of the configured repositories failed (Unknown), and yum doesn'</span>t have enough cached data to continue. At this point the only safe thing yum can <span class="token keyword">do</span> is fail. There are a few ways to work <span class="token string">"fix"</span> this:     1. Contact the upstream <span class="token keyword">for</span> the repository and get them to fix the problem.     2. Reconfigure the baseurl/etc. <span class="token keyword">for</span> the repository, to point to a working        upstream. This is <span class="token function">most</span> often useful <span class="token keyword">if</span> you are using a newer        distribution release than is supported by the repository <span class="token punctuation">(</span>and the        packages <span class="token keyword">for</span> the previous distribution release still work<span class="token punctuation">)</span>.     3. Run the <span class="token function">command</span> with the repository temporarily disabled            yum --disablerepo<span class="token operator">=</span><span class="token operator">&lt;</span>repoid<span class="token operator">></span> <span class="token punctuation">..</span>.     4. Disable the repository permanently, so yum won<span class="token string">'t use it by default. Yum        will then just ignore the repository until you permanently enable it        again or use --enablerepo for temporary usage:            yum-config-manager --disable &lt;repoid>        or            subscription-manager repos --disable=&lt;repoid>     5. Configure the failing repository to be skipped, if it is unavailable.        Note that yum will try to contact the repo. when it runs most commands,        so will have to try and fail each time (and thus. yum will be be much        slower). If it is a very temporary problem though, this is often a nice        compromise:            yum-config-manager --save --setopt=&lt;repoid>.skip_if_unavailable=trueCannot find a valid baseurl for repo: HDP-UTILS-1.1.0.22-repo-22023-03-08 11:48:20,895 - call[('</span>ambari-python-wrap<span class="token string">', u'</span>/usr/bin/hdp-select<span class="token string">', '</span>versions<span class="token string">')] {}2023-03-08 11:48:20,943 - call returned (0, '</span><span class="token string">')2023-03-08 11:48:20,944 - The '</span>hadoop-hdfs-datanode<span class="token string">' component did not advertise a version. This may indicate a problem with the component packaging.Command failed after 1 tries``<span class="token variable"><span class="token variable">`</span>- 解决方式检查 yum 源的配置## 4. repodata/repomd.xml: <span class="token punctuation">[</span>Errno 14<span class="token punctuation">]</span> HTTP Error 404 - Not Foundhttps://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.279/presto-server-0.279.tar.gz<span class="token variable">`</span></span>``bashOne of the configured repositories failed (HDP-3.1-repo-51), and yum doesn'</span>t have enough cached data to continue. At this point the only safe thing yum can <span class="token keyword">do</span> is fail. There are a few ways to work <span class="token string">"fix"</span> this:     1. Contact the upstream <span class="token keyword">for</span> the repository and get them to fix the problem.     2. Reconfigure the baseurl/etc. <span class="token keyword">for</span> the repository, to point to a working        upstream. This is <span class="token function">most</span> often useful <span class="token keyword">if</span> you are using a newer        distribution release than is supported by the repository <span class="token punctuation">(</span>and the        packages <span class="token keyword">for</span> the previous distribution release still work<span class="token punctuation">)</span>.     3. Run the <span class="token function">command</span> with the repository temporarily disabled            yum --disablerepo<span class="token operator">=</span>HDP-3.1-repo-51 <span class="token punctuation">..</span>.     4. Disable the repository permanently, so yum won<span class="token string">'t use it by default. Yum        will then just ignore the repository until you permanently enable it        again or use --enablerepo for temporary usage:            yum-config-manager --disable HDP-3.1-repo-51        or            subscription-manager repos --disable=HDP-3.1-repo-51     5. Configure the failing repository to be skipped, if it is unavailable.        Note that yum will try to contact the repo. when it runs most commands,        so will have to try and fail each time (and thus. yum will be be much        slower). If it is a very temporary problem though, this is often a nice        compromise:            yum-config-manager --save --setopt=HDP-3.1-repo-51.skip_if_unavailable=truefailure: repodata/repomd.xml from HDP-3.1-repo-51: [Errno 256] No more mirrors to try.http://192.168.71.100/hdp/HDP/centos7/repodata/repomd.xml: [Errno 14] HTTP Error 404 - Not FoundDesired version (2.7.3.0) of ambari-agent package is not available.Connection to node1 closed.SSH command execution finishedhost=node1, exitcode=1Command end time 2023-03-08 12:19:45``<span class="token variable"><span class="token variable">`</span>- 解决方式在 配置的 httpd 的文件夹中查找  HDP 下面的 repodata 文件夹  复制到  /hdp/HDP/centos7 下面例如我这里是 <span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span><span class="token function">bash</span># 找到对应文件夹的路径<span class="token punctuation">[</span>root@node1 3.1.0.0-78<span class="token punctuation">]</span># <span class="token function">cd</span> /var/www/html/hdp/HDP/centos7/3.1.0.0-78# 确认该文件夹的存在<span class="token punctuation">[</span>root@node1 3.1.0.0-78<span class="token punctuation">]</span># ll <span class="token operator">|</span> <span class="token function">grep</span> repoddrwxr-xr-x  2 zookeeper <span class="token function">users</span>  4096 Dec 11  2018 repodata# 拷贝到指定目录<span class="token punctuation">[</span>root@node1 3.1.0.0-78<span class="token punctuation">]</span># <span class="token function">cp</span> -R repodata /var/www/html/hdp/HDP/centos7<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span>## 5. httpd 配置的地址无法访问这个地址无法访问了http://s3.amazonaws.com/dev.hortonworks.com?delimiter<span class="token operator">=</span>/<span class="token operator">&amp;</span>prefix<span class="token operator">=</span>HDP/centos7/3.x/BUILDS/3.1.0.0-78/ <span class="token operator">!</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">(</span>https://images.hnbian.cn/202303150005563.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg<span class="token operator">==</span>/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA<span class="token operator">==</span>/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim<span class="token punctuation">)</span>- 解决方式可以去对应的文件夹删除 index.html 文件- 重启 <span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span><span class="token function">bash</span>systemctl restart httpd<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span><span class="token operator">!</span><span class="token punctuation">[</span>重启之后即可访问<span class="token punctuation">]</span><span class="token punctuation">(</span>https://images.hnbian.cn/202303150005072.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg<span class="token operator">==</span>/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA<span class="token operator">==</span>/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim<span class="token punctuation">)</span>## 6. HDP-2.5: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try<span class="token variable">`</span></span>``bashTraceback (most recent call last):  File "/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/hooks/before-INSTALL/scripts/hook.py", line 37, in &lt;module>    BeforeInstallHook().execute()  File "/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py", line 280, in execute    method(env)  File "/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/hooks/before-INSTALL/scripts/hook.py", line 34, in hook    install_packages()  File "/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/hooks/before-INSTALL/scripts/shared_initialization.py", line 37, in install_packages    retry_count=params.agent_stack_retry_count)  File "/usr/lib/python2.6/site-packages/resource_management/core/base.py", line 155, in __init__    self.env.run()  File "/usr/lib/python2.6/site-packages/resource_management/core/environment.py", line 160, in run    self.run_action(resource, action)  File "/usr/lib/python2.6/site-packages/resource_management/core/environment.py", line 124, in run_action    provider_action()  File "/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py", line 54, in action_install    self.install_package(package_name, self.resource.use_repos, self.resource.skip_repos)  File "/usr/lib/python2.6/site-packages/resource_management/core/providers/package/yumrpm.py", line 49, in install_package    self.checked_call_with_retries(cmd, sudo=True, logoutput=self.get_logoutput())  File "/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py", line 83, in checked_call_with_retries    return self._call_with_retries(cmd, is_checked=True, **kwargs)  File "/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py", line 91, in _call_with_retries    code, out = func(cmd, **kwargs)  File "/usr/lib/python2.6/site-packages/resource_management/core/shell.py", line 71, in inner    result = function(command, **kwargs)  File "/usr/lib/python2.6/site-packages/resource_management/core/shell.py", line 93, in checked_call    tries=tries, try_sleep=try_sleep)  File "/usr/lib/python2.6/site-packages/resource_management/core/shell.py", line 141, in _call_wrapper    result = _call(command, **kwargs_copy)  File "/usr/lib/python2.6/site-packages/resource_management/core/shell.py", line 294, in _call    raise Fail(err_msg)resource_management.core.exceptions.Fail: Execution of '</span>/usr/bin/yum -d 0 -e 0 -y <span class="token function">install</span> hdp-select<span class="token string">' returned 1.  One of the configured repositories failed (HDP-2.5), and yum doesn'</span>t have enough cached data to continue. At this point the only safe thing yum can <span class="token keyword">do</span> is fail. There are a few ways to work <span class="token string">"fix"</span> this:     1. Contact the upstream <span class="token keyword">for</span> the repository and get them to fix the problem.     2. Reconfigure the baseurl/etc. <span class="token keyword">for</span> the repository, to point to a working        upstream. This is <span class="token function">most</span> often useful <span class="token keyword">if</span> you are using a newer        distribution release than is supported by the repository <span class="token punctuation">(</span>and the        packages <span class="token keyword">for</span> the previous distribution release still work<span class="token punctuation">)</span>.     3. Disable the repository, so yum won<span class="token string">'t use it by default. Yum will then        just ignore the repository until you permanently enable it again or use        --enablerepo for temporary usage:            yum-config-manager --disable HDP-2.5     4. Configure the failing repository to be skipped, if it is unavailable.        Note that yum will try to contact the repo. when it runs most commands,        so will have to try and fail each time (and thus. yum will be be much        slower). If it is a very temporary problem though, this is often a nice        compromise:            yum-config-manager --save --setopt=HDP-2.5.skip_if_unavailable=truefailure: repodata/repomd.xml from HDP-2.5: [Errno 256] No more mirrors to try.http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.5.0.0/repodata/repomd.xml: [Errno 14] curl#6 - "Could not resolve host: public-repo-1.hortonworks.com; Name or service not known"``<span class="token variable"><span class="token variable">`</span>- 解决方法：仔仔细细的检查yum源的配置。修改yum源之后执行下面命令<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span><span class="token function">bash</span># 清除系统中缓存的所有仓库数据yum clean all# 更新系统中安装的所有软件包到最新版本yum update# 重建本地仓库缓存yum makecache<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span>- <span class="token variable">`</span></span>yum clean all<span class="token variable"><span class="token variable">`</span> 命令会清除系统中缓存的所有仓库数据，包括仓库元数据和软件包。这个命令可以用来解决仓库数据损坏或不一致的问题。- <span class="token variable">`</span></span>yum update<span class="token variable"><span class="token variable">`</span> 命令用于更新系统中安装的所有软件包到最新版本。它会检查仓库中可用的新版本软件包，并下载并安装它们。这个命令可以用来升级系统并修复已知的软件包漏洞或问题。- <span class="token variable">`</span></span>yum makecache<span class="token variable"><span class="token variable">`</span> 命令用于重建本地仓库缓存。它会重新下载并解析仓库中的元数据，并将其存储在本地缓存中。这个命令可以用来更新本地仓库数据，以便 yum 命令能够快速地访问和检索软件包信息。## 7. mailcap-2.1.41-2.el7.noarch: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span><span class="token function">bash</span>Error downloading packages:  hadoop_2_5_0_0_1245-2.7.3.2.5.0.0-1245.el6.x86_64: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try.  zookeeper_2_5_0_0_1245-3.4.6.2.5.0.0-1245.el6.noarch: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try.  spark_2_5_0_0_1245-yarn-shuffle-1.6.2.2.5.0.0-1245.el6.noarch: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try.  spark2_2_5_0_0_1245-yarn-shuffle-2.0.0.2.5.0.0-1245.el6.noarch: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try.  mailcap-2.1.41-2.el7.noarch: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try.<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span>- 解决方法仔仔细细的检查yum源的配置。修改yum源之后执行下面命令<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span><span class="token function">bash</span># 清除系统中缓存的所有仓库数据yum clean all# 更新系统中安装的所有软件包到最新版本yum update# 重建本地仓库缓存yum makecache<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span>## 8. repodata/repomd.xml: <span class="token punctuation">[</span>Errno 14<span class="token punctuation">]</span> HTTP Error 403 - Forbidden<span class="token variable">`</span></span>``bashFailed to execute command:  rpm -qa | grep smartsense- ||  yum -y install smartsense-hst ||  rpm -i /var/lib/ambari-agent/cache/stacks/HDP/2.1/services/SMARTSENSE/package/files/rpm/*.rpm; Exit code: 1; stdout: Loaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comNo package smartsense-hst available.; stderr: http://master/hdp/HDP/centos7/repodata/repomd.xml: [Errno 14] HTTP Error 403 - ForbiddenTrying other mirror.To address this issue please refer to the below knowledge base articlehttps://access.redhat.com/solutions/69319If above article doesn'</span>t <span class="token function">help</span> to resolve this issue please create a bug on https://bugs.centos.org/http://master/hdp/HDP-UTILS-1.1.0.21/repos/centos7/repodata/repomd.xml: <span class="token punctuation">[</span>Errno 14<span class="token punctuation">]</span> HTTP Error 403 - ForbiddenTrying other mirror.Error: Nothing to <span class="token keyword">do</span>error: File not found by glob: /var/lib/ambari-agent/cache/stacks/HDP/2.1/services/SMARTSENSE/package/files/rpm/*.rpmstdout:   /var/lib/ambari-agent/data/output-8245.txt2023-03-08 14:20:22,975 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf2023-03-08 14:20:22,975 - Group<span class="token punctuation">[</span><span class="token string">'spark'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 14:20:22,995 - Group<span class="token punctuation">[</span><span class="token string">'hadoop'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 14:20:22,995 - Group<span class="token punctuation">[</span><span class="token string">'users'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 14:20:22,995 - User<span class="token punctuation">[</span><span class="token string">'hive'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:22,995 - Adding user User<span class="token punctuation">[</span><span class="token string">'hive'</span><span class="token punctuation">]</span>2023-03-08 14:20:23,631 - User<span class="token punctuation">[</span><span class="token string">'zookeeper'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:23,632 - Adding user User<span class="token punctuation">[</span><span class="token string">'zookeeper'</span><span class="token punctuation">]</span>2023-03-08 14:20:24,248 - User<span class="token punctuation">[</span><span class="token string">'infra-solr'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:24,249 - User<span class="token punctuation">[</span><span class="token string">'ams'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:24,249 - Adding user User<span class="token punctuation">[</span><span class="token string">'ams'</span><span class="token punctuation">]</span>2023-03-08 14:20:24,949 - User<span class="token punctuation">[</span><span class="token string">'tez'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'users'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:24,949 - Adding user User<span class="token punctuation">[</span><span class="token string">'tez'</span><span class="token punctuation">]</span>2023-03-08 14:20:25,566 - User<span class="token punctuation">[</span><span class="token string">'spark'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:25,566 - Adding user User<span class="token punctuation">[</span><span class="token string">'spark'</span><span class="token punctuation">]</span>2023-03-08 14:20:26,200 - User<span class="token punctuation">[</span><span class="token string">'ambari-qa'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'users'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:26,200 - Adding user User<span class="token punctuation">[</span><span class="token string">'ambari-qa'</span><span class="token punctuation">]</span>2023-03-08 14:20:26,827 - User<span class="token punctuation">[</span><span class="token string">'flume'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:26,827 - Adding user User<span class="token punctuation">[</span><span class="token string">'flume'</span><span class="token punctuation">]</span>2023-03-08 14:20:27,533 - User<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:27,534 - Adding user User<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span>2023-03-08 14:20:28,260 - User<span class="token punctuation">[</span><span class="token string">'yarn'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:28,260 - Adding user User<span class="token punctuation">[</span><span class="token string">'yarn'</span><span class="token punctuation">]</span>2023-03-08 14:20:28,927 - User<span class="token punctuation">[</span><span class="token string">'mapred'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:28,927 - Adding user User<span class="token punctuation">[</span><span class="token string">'mapred'</span><span class="token punctuation">]</span>2023-03-08 14:20:29,553 - User<span class="token punctuation">[</span><span class="token string">'hbase'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:29,554 - Adding user User<span class="token punctuation">[</span><span class="token string">'hbase'</span><span class="token punctuation">]</span>2023-03-08 14:20:30,170 - User<span class="token punctuation">[</span><span class="token string">'hcat'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'gid'</span><span class="token keyword">:</span> <span class="token string">'hadoop'</span>, <span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:30,170 - Adding user User<span class="token punctuation">[</span><span class="token string">'hcat'</span><span class="token punctuation">]</span>2023-03-08 14:20:31,087 - File<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'content'</span><span class="token keyword">:</span> StaticFile<span class="token punctuation">(</span><span class="token string">'changeToSecureUid.sh'</span><span class="token punctuation">)</span>, <span class="token string">'mode'</span><span class="token keyword">:</span> 0555<span class="token punctuation">}</span>2023-03-08 14:20:31,130 - Execute<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'not_if'</span><span class="token keyword">:</span> <span class="token string">'(test <span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> -u ambari-qa<span class="token variable">)</span></span> -gt 1000) || (false)'</span><span class="token punctuation">}</span>2023-03-08 14:20:31,135 - Skipping Execute<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh ambari-qa /tmp/hadoop-ambari-qa,/tmp/hsperfdata_ambari-qa,/home/ambari-qa,/tmp/ambari-qa,/tmp/sqoop-ambari-qa'</span><span class="token punctuation">]</span> due to not_if2023-03-08 14:20:31,135 - Directory<span class="token punctuation">[</span><span class="token string">'/tmp/hbase-hbase'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'owner'</span><span class="token keyword">:</span> <span class="token string">'hbase'</span>, <span class="token string">'create_parents'</span><span class="token keyword">:</span> True, <span class="token string">'mode'</span><span class="token keyword">:</span> 0775, <span class="token string">'cd_access'</span><span class="token keyword">:</span> <span class="token string">'a'</span><span class="token punctuation">}</span>2023-03-08 14:20:31,136 - Changing owner <span class="token keyword">for</span> /tmp/hbase-hbase from 1013 to hbase2023-03-08 14:20:31,136 - File<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'content'</span><span class="token keyword">:</span> StaticFile<span class="token punctuation">(</span><span class="token string">'changeToSecureUid.sh'</span><span class="token punctuation">)</span>, <span class="token string">'mode'</span><span class="token keyword">:</span> 0555<span class="token punctuation">}</span>2023-03-08 14:20:31,137 - Execute<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh hbase /home/hbase,/tmp/hbase,/usr/bin/hbase,/var/log/hbase,/tmp/hbase-hbase'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'not_if'</span><span class="token keyword">:</span> <span class="token string">'(test <span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> -u hbase<span class="token variable">)</span></span> -gt 1000) || (false)'</span><span class="token punctuation">}</span>2023-03-08 14:20:31,140 - Skipping Execute<span class="token punctuation">[</span><span class="token string">'/var/lib/ambari-agent/tmp/changeUid.sh hbase /home/hbase,/tmp/hbase,/usr/bin/hbase,/var/log/hbase,/tmp/hbase-hbase'</span><span class="token punctuation">]</span> due to not_if2023-03-08 14:20:31,140 - Group<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>2023-03-08 14:20:31,141 - User<span class="token punctuation">[</span><span class="token string">'hdfs'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'fetch_nonlocal_groups'</span><span class="token keyword">:</span> True, <span class="token string">'groups'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'hadoop'</span>, u<span class="token string">'hdfs'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>2023-03-08 14:20:31,141 - Modifying user hdfs2023-03-08 14:20:32,157 - FS Type: 2023-03-08 14:20:32,158 - Directory<span class="token punctuation">[</span><span class="token string">'/etc/hadoop'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'mode'</span><span class="token keyword">:</span> 0755<span class="token punctuation">}</span>2023-03-08 14:20:32,158 - Creating directory Directory<span class="token punctuation">[</span><span class="token string">'/etc/hadoop'</span><span class="token punctuation">]</span> since it doesn<span class="token string">'t exist.2023-03-08 14:20:32,159 - Directory['</span>/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir<span class="token string">'] {'</span>owner<span class="token string">': '</span>hdfs<span class="token string">', '</span>group<span class="token string">': '</span>hadoop<span class="token string">', '</span>mode<span class="token string">': 01777}2023-03-08 14:20:32,160 - Changing owner for /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir from 1013 to hdfs2023-03-08 14:20:32,184 - Initializing 2 repositories2023-03-08 14:20:32,185 - Repository['</span>HDP-2.5<span class="token string">'] {'</span>base_url<span class="token string">': '</span>http://master/hdp/HDP/centos7/<span class="token string">', '</span>action<span class="token string">': ['</span>create<span class="token string">'], '</span>components<span class="token string">': [u'</span>HDP<span class="token string">', '</span>main<span class="token string">'], '</span>repo_template<span class="token string">': '</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token punctuation">{</span>repo_id<span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">]</span>\nname<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">{</span>repo_id<span class="token punctuation">}</span><span class="token punctuation">}</span>\n<span class="token punctuation">{</span>% <span class="token keyword">if</span> mirror_list %<span class="token punctuation">}</span>mirrorlist<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">{</span>mirror_list<span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">{</span>% <span class="token keyword">else</span> %<span class="token punctuation">}</span>baseurl<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">{</span>base_url<span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">{</span>% endif %<span class="token punctuation">}</span>\n\npath<span class="token operator">=</span>/\nenabled<span class="token operator">=</span>1\ngpgcheck<span class="token operator">=</span>0<span class="token string">', '</span>repo_file_name<span class="token string">': '</span>HDP<span class="token string">', '</span>mirror_list<span class="token string">': None}2023-03-08 14:20:32,250 - File['</span>/etc/yum.repos.d/HDP.repo<span class="token string">'] {'</span>content<span class="token string">': '</span><span class="token punctuation">[</span>HDP-2.5<span class="token punctuation">]</span>\nname<span class="token operator">=</span>HDP-2.5\nbaseurl<span class="token operator">=</span>http://master/hdp/HDP/centos7/\n\npath<span class="token operator">=</span>/\nenabled<span class="token operator">=</span>1\ngpgcheck<span class="token operator">=</span>0<span class="token string">'}2023-03-08 14:20:32,251 - Writing File['</span>/etc/yum.repos.d/HDP.repo<span class="token string">'] because contents don'</span>t match2023-03-08 14:20:32,251 - Repository<span class="token punctuation">[</span><span class="token string">'HDP-UTILS-1.1.0.21'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'base_url'</span><span class="token keyword">:</span> <span class="token string">'http://master/hdp/HDP-UTILS-1.1.0.21/repos/centos7/'</span>, <span class="token string">'action'</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">'create'</span><span class="token punctuation">]</span>, <span class="token string">'components'</span><span class="token keyword">:</span> <span class="token punctuation">[</span>u<span class="token string">'HDP-UTILS'</span>, <span class="token string">'main'</span><span class="token punctuation">]</span>, <span class="token string">'repo_template'</span><span class="token keyword">:</span> <span class="token string">'[{{repo_id}}]\nname={{repo_id}}\n{% if mirror_list %}mirrorlist={{mirror_list}}{% else %}baseurl={{base_url}}{% endif %}\n\npath=/\nenabled=1\ngpgcheck=0'</span>, <span class="token string">'repo_file_name'</span><span class="token keyword">:</span> <span class="token string">'HDP-UTILS'</span>, <span class="token string">'mirror_list'</span><span class="token keyword">:</span> None<span class="token punctuation">}</span>2023-03-08 14:20:32,254 - File<span class="token punctuation">[</span><span class="token string">'/etc/yum.repos.d/HDP-UTILS.repo'</span><span class="token punctuation">]</span> <span class="token punctuation">{</span><span class="token string">'content'</span><span class="token keyword">:</span> <span class="token string">'[HDP-UTILS-1.1.0.21]\nname=HDP-UTILS-1.1.0.21\nbaseurl=http://master/hdp/HDP-UTILS-1.1.0.21/repos/centos7/\n\npath=/\nenabled=1\ngpgcheck=0'</span><span class="token punctuation">}</span>2023-03-08 14:20:32,254 - Writing File<span class="token punctuation">[</span><span class="token string">'/etc/yum.repos.d/HDP-UTILS.repo'</span><span class="token punctuation">]</span> because contents don<span class="token string">'t match2023-03-08 14:20:32,254 - Package['</span>unzip<span class="token string">'] {'</span>retry_on_repo_unavailability<span class="token string">': False, '</span>retry_count<span class="token string">': 5}2023-03-08 14:20:33,429 - Skipping installation of existing package unzip2023-03-08 14:20:33,429 - Package['</span>curl<span class="token string">'] {'</span>retry_on_repo_unavailability<span class="token string">': False, '</span>retry_count<span class="token string">': 5}2023-03-08 14:20:33,438 - Skipping installation of existing package curl2023-03-08 14:20:33,438 - Package['</span>hdp-select<span class="token string">'] {'</span>retry_on_repo_unavailability<span class="token string">': False, '</span>retry_count<span class="token string">': 5}2023-03-08 14:20:33,445 - Skipping installation of existing package hdp-selectinstalling using command: {sudo} rpm -qa | grep smartsense- || {sudo} yum -y install smartsense-hst || {sudo} rpm -i /var/lib/ambari-agent/cache/stacks/HDP/2.1/services/SMARTSENSE/package/files/rpm/*.rpmCommand:  rpm -qa | grep smartsense- ||  yum -y install smartsense-hst ||  rpm -i /var/lib/ambari-agent/cache/stacks/HDP/2.1/services/SMARTSENSE/package/files/rpm/*.rpmExit code: 1Std Out: Loaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comNo package smartsense-hst available.Std Err: http://master/hdp/HDP/centos7/repodata/repomd.xml: [Errno 14] HTTP Error 403 - ForbiddenTrying other mirror.To address this issue please refer to the below knowledge base articlehttps://access.redhat.com/solutions/69319If above article doesn'</span>t <span class="token function">help</span> to resolve this issue please create a bug on https://bugs.centos.org/http://master/hdp/HDP-UTILS-1.1.0.21/repos/centos7/repodata/repomd.xml: <span class="token punctuation">[</span>Errno 14<span class="token punctuation">]</span> HTTP Error 403 - ForbiddenTrying other mirror.Error: Nothing to <span class="token keyword">do</span>error: File not found by glob: /var/lib/ambari-agent/cache/stacks/HDP/2.1/services/SMARTSENSE/package/files/rpm/*.rpmCommand failed after 1 tries<span class="token operator">&lt;</span>/module<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span><span class="token operator">&lt;</span>/repoid<span class="token operator">></span></code></pre><ul><li>解决方法</li></ul><p>在提供镜像服务的机器上执行以下命令：</p><pre class=" language-bash"><code class="language-bash">setenforce 0</code></pre><h2 id="9-File-not-found-by-glob-var-lib-ambari-agent-cache-stacks-HDP-2-1-…"><a href="#9-File-not-found-by-glob-var-lib-ambari-agent-cache-stacks-HDP-2-1-…" class="headerlink" title="9. File not found by glob: /var/lib/ambari-agent/cache/stacks/HDP/2.1 …"></a>9. File not found by glob: /var/lib/ambari-agent/cache/stacks/HDP/2.1 …</h2><pre class=" language-bash"><code class="language-bash">Failed to execute command:  rpm -qa <span class="token operator">|</span> <span class="token function">grep</span> smartsense- <span class="token operator">||</span>  yum -y <span class="token function">install</span> smartsense-hst <span class="token operator">||</span>  rpm -i /var/lib/ambari-agent/cache/stacks/HDP/2.1/services/SMARTSENSE/package/files/rpm/*.rpm<span class="token punctuation">;</span> Exit code: 1<span class="token punctuation">;</span> stdout: Loaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comNo package smartsense-hst available.<span class="token punctuation">;</span> stderr: Error: Nothing to <span class="token keyword">do</span>error: File not found by glob: /var/lib/ambari-agent/cache/stacks/HDP/2.1/services/SMARTSENSE/package/files/rpm/*.rpm</code></pre><ul><li>问题原因</li></ul><p>由于smartsense包是在ambari里面的，检查ambari repo是否正常。如果使用本地源，请查检base url。</p><h2 id="10-usr-hdp-current-hadoop-client-conf-doesn’t-exist"><a href="#10-usr-hdp-current-hadoop-client-conf-doesn’t-exist" class="headerlink" title="10. /usr/hdp/current/hadoop-client/conf doesn’t exist"></a>10. /usr/hdp/current/hadoop-client/conf doesn’t exist</h2><pre class=" language-bash"><code class="language-bash">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HBASE/0.96.0.2.0/package/scripts/hbase_client.py"</span>, line 82, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    HbaseClient<span class="token punctuation">(</span><span class="token punctuation">)</span>.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py"</span>, line 280, <span class="token keyword">in</span> execute    method<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HBASE/0.96.0.2.0/package/scripts/hbase_client.py"</span>, line 37, <span class="token keyword">in</span> <span class="token function">install</span>    self.configure<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HBASE/0.96.0.2.0/package/scripts/hbase_client.py"</span>, line 42, <span class="token keyword">in</span> configure    hbase<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'client'</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/ambari_commons/os_family_impl.py"</span>, line 89, <span class="token keyword">in</span> thunk    <span class="token keyword">return</span> fn<span class="token punctuation">(</span>*args, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HBASE/0.96.0.2.0/package/scripts/hbase.py"</span>, line 120, <span class="token keyword">in</span> hbase    group<span class="token operator">=</span>params.user_group  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/base.py"</span>, line 155, <span class="token keyword">in</span> __init__    self.env.run<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 160, <span class="token keyword">in</span> run    self.run_action<span class="token punctuation">(</span>resource, action<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 124, <span class="token keyword">in</span> run_action    provider_action<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/providers/xml_config.py"</span>, line 66, <span class="token keyword">in</span> action_create    encoding <span class="token operator">=</span> self.resource.encoding  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/base.py"</span>, line 155, <span class="token keyword">in</span> __init__    self.env.run<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 160, <span class="token keyword">in</span> run    self.run_action<span class="token punctuation">(</span>resource, action<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 124, <span class="token keyword">in</span> run_action    provider_action<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/system.py"</span>, line 120, <span class="token keyword">in</span> action_create    raise Fail<span class="token punctuation">(</span><span class="token string">"Applying %s failed, parent directory %s doesn't exist"</span> % <span class="token punctuation">(</span>self.resource, dirname<span class="token punctuation">))</span>resource_management.core.exceptions.Fail: Applying File<span class="token punctuation">[</span><span class="token string">'/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'</span><span class="token punctuation">]</span> failed, parent directory /usr/hdp/current/hadoop-client/conf doesn't exist</code></pre><ul><li>问题原因</li></ul><p>可能是由于之前安装过，但没有安装成功，导致在文件系统中存在一些文件，致使后续重试的安装出现问题。<br>解决方法：输入以下命令</p><pre><code>yum -y erase hdp-select</code></pre><h2 id="11-Could-not-resolve-host-repo-mysql-com-Name-or-service-not-known"><a href="#11-Could-not-resolve-host-repo-mysql-com-Name-or-service-not-known" class="headerlink" title="11. Could not resolve host: repo.mysql.com; Name or service not known"></a>11. Could not resolve host: repo.mysql.com; Name or service not known</h2><pre class=" language-bash"><code class="language-bash">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HIVE/0.12.0.2.0/package/scripts/mysql_server.py"</span>, line 64, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    MysqlServer<span class="token punctuation">(</span><span class="token punctuation">)</span>.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py"</span>, line 280, <span class="token keyword">in</span> execute    method<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HIVE/0.12.0.2.0/package/scripts/mysql_server.py"</span>, line 33, <span class="token keyword">in</span> <span class="token function">install</span>    self.install_packages<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py"</span>, line 567, <span class="token keyword">in</span> install_packages    retry_count<span class="token operator">=</span>agent_stack_retry_count<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/base.py"</span>, line 155, <span class="token keyword">in</span> __init__    self.env.run<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 160, <span class="token keyword">in</span> run    self.run_action<span class="token punctuation">(</span>resource, action<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 124, <span class="token keyword">in</span> run_action    provider_action<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 54, <span class="token keyword">in</span> action_install    self.install_package<span class="token punctuation">(</span>package_name, self.resource.use_repos, self.resource.skip_repos<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/yumrpm.py"</span>, line 49, <span class="token keyword">in</span> install_package    self.checked_call_with_retries<span class="token punctuation">(</span>cmd, sudo<span class="token operator">=</span>True, logoutput<span class="token operator">=</span>self.get_logoutput<span class="token punctuation">(</span><span class="token punctuation">))</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 83, <span class="token keyword">in</span> checked_call_with_retries    <span class="token keyword">return</span> self._call_with_retries<span class="token punctuation">(</span>cmd, is_checked<span class="token operator">=</span>True, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 91, <span class="token keyword">in</span> _call_with_retries    code, out <span class="token operator">=</span> func<span class="token punctuation">(</span>cmd, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 71, <span class="token keyword">in</span> inner    result <span class="token operator">=</span> function<span class="token punctuation">(</span>command, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 93, <span class="token keyword">in</span> checked_call    tries<span class="token operator">=</span>tries, try_sleep<span class="token operator">=</span>try_sleep<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 141, <span class="token keyword">in</span> _call_wrapper    result <span class="token operator">=</span> _call<span class="token punctuation">(</span>command, **kwargs_copy<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 294, <span class="token keyword">in</span> _call    raise Fail<span class="token punctuation">(</span>err_msg<span class="token punctuation">)</span>resource_management.core.exceptions.Fail: Execution of <span class="token string">'/usr/bin/yum -d 0 -e 0 -y install mysql-community-server'</span> returned 1.  One of the configured repositories failed <span class="token punctuation">(</span>MySQL Connectors Community<span class="token punctuation">)</span>, and yum doesn<span class="token string">'t have enough cached data to continue. At this point the only safe thing yum can do is fail. There are a few ways to work "fix" this:     1. Contact the upstream for the repository and get them to fix the problem.     2. Reconfigure the baseurl/etc. for the repository, to point to a working        upstream. This is most often useful if you are using a newer        distribution release than is supported by the repository (and the        packages for the previous distribution release still work).     3. Disable the repository, so yum won'</span>t use it by default. Yum will <span class="token keyword">then</span>        just ignore the repository <span class="token keyword">until</span> you permanently <span class="token function">enable</span> it again or use        --enablerepo <span class="token keyword">for</span> temporary usage:            yum-config-manager --disable mysql-connectors-community     4. Configure the failing repository to be skipped, <span class="token keyword">if</span> it is unavailable.        Note that yum will try to contact the repo. when it runs <span class="token function">most</span> commands,        so will have to try and fail each <span class="token function">time</span> <span class="token punctuation">(</span>and thus. yum will be be much        slower<span class="token punctuation">)</span>. If it is a very temporary problem though, this is often a <span class="token function">nice</span>        compromise:            yum-config-manager --save --setopt<span class="token operator">=</span>mysql-connectors-community.skip_if_unavailable<span class="token operator">=</span>truefailure: repodata/repomd.xml from mysql-connectors-community: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try.http://repo.mysql.com/yum/mysql-connectors-community/el/7/x86_64/repodata/repomd.xml: <span class="token punctuation">[</span>Errno 14<span class="token punctuation">]</span> curl<span class="token comment" spellcheck="true">#6 - "Could not resolve host: repo.mysql.com; Name or service not known"</span></code></pre><ul><li>问题原因<br>从以上最后两句可以看到，在repodata/下有个来自 mysql-connectors-community 的 repomd.xml 文件，而 repodata 这个目录是在ambari 源下的，因此，导致无法找到mysql安装源的原因应该是刚才刚刚加入的源没有完成识别出来，使用以下命令解决问题：</li></ul><pre class=" language-bash"><code class="language-bash">yum makecache</code></pre><p>如果还是不能解决这个问题，可以尝试手动安装 mysql community server 和 client。先安装 client，再安装 server，下载地址如下：</p><p><a href="http://repo.mysql.com/yum/mysql-5.6-community/el/7/x86_64/mysql-community-server-5.6.34-2.el7.x86_64.rpm" target="_blank" rel="noopener">http://repo.mysql.com/yum/mysql-5.6-community/el/7/x86_64/mysql-community-server-5.6.34-2.el7.x86_64.rpm</a></p><p><a href="http://repo.mysql.com/yum/mysql-5.6-community/el/7/x86_64/mysql-community-client-5.6.34-2.el7.x86_64.rpm" target="_blank" rel="noopener">http://repo.mysql.com/yum/mysql-5.6-community/el/7/x86_64/mysql-community-client-5.6.34-2.el7.x86_64.rpm</a></p><h2 id="12-mailcap-2-1-41-2-el7-noarch-Errno-256-No-more-mirrors-to-try"><a href="#12-mailcap-2-1-41-2-el7-noarch-Errno-256-No-more-mirrors-to-try" class="headerlink" title="12. mailcap-2.1.41-2.el7.noarch: [Errno 256] No more mirrors to try"></a>12. mailcap-2.1.41-2.el7.noarch: [Errno 256] No more mirrors to try</h2><pre class=" language-bash"><code class="language-bash">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HDFS/2.1.0.2.0/package/scripts/datanode.py"</span>, line 174, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    DataNode<span class="token punctuation">(</span><span class="token punctuation">)</span>.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py"</span>, line 280, <span class="token keyword">in</span> execute    method<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HDFS/2.1.0.2.0/package/scripts/datanode.py"</span>, line 49, <span class="token keyword">in</span> <span class="token function">install</span>    self.install_packages<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py"</span>, line 567, <span class="token keyword">in</span> install_packages    retry_count<span class="token operator">=</span>agent_stack_retry_count<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/base.py"</span>, line 155, <span class="token keyword">in</span> __init__    self.env.run<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 160, <span class="token keyword">in</span> run    self.run_action<span class="token punctuation">(</span>resource, action<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 124, <span class="token keyword">in</span> run_action    provider_action<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 54, <span class="token keyword">in</span> action_install    self.install_package<span class="token punctuation">(</span>package_name, self.resource.use_repos, self.resource.skip_repos<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/yumrpm.py"</span>, line 49, <span class="token keyword">in</span> install_package    self.checked_call_with_retries<span class="token punctuation">(</span>cmd, sudo<span class="token operator">=</span>True, logoutput<span class="token operator">=</span>self.get_logoutput<span class="token punctuation">(</span><span class="token punctuation">))</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 83, <span class="token keyword">in</span> checked_call_with_retries    <span class="token keyword">return</span> self._call_with_retries<span class="token punctuation">(</span>cmd, is_checked<span class="token operator">=</span>True, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 91, <span class="token keyword">in</span> _call_with_retries    code, out <span class="token operator">=</span> func<span class="token punctuation">(</span>cmd, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 71, <span class="token keyword">in</span> inner    result <span class="token operator">=</span> function<span class="token punctuation">(</span>command, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 93, <span class="token keyword">in</span> checked_call    tries<span class="token operator">=</span>tries, try_sleep<span class="token operator">=</span>try_sleep<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 141, <span class="token keyword">in</span> _call_wrapper    result <span class="token operator">=</span> _call<span class="token punctuation">(</span>command, **kwargs_copy<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 294, <span class="token keyword">in</span> _call    raise Fail<span class="token punctuation">(</span>err_msg<span class="token punctuation">)</span>resource_management.core.exceptions.Fail: Execution of <span class="token string">'/usr/bin/yum -d 0 -e 0 -y install hadoop_2_5_0_0_1245'</span> returned 1. No Presto metadata available <span class="token keyword">for</span> baseError downloading packages:  mailcap-2.1.41-2.el7.noarch: <span class="token punctuation">[</span>Errno 256<span class="token punctuation">]</span> No <span class="token function">more</span> mirrors to try.</code></pre><ul><li>问题原因</li></ul><p>no more mirrors to try，这是源有问题，检查源的配置，并进行更新源：</p><ul><li>解决</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 清除系统中缓存的所有仓库数据</span>yum clean all<span class="token comment" spellcheck="true"># 更新系统中安装的所有软件包到最新版本</span>yum update<span class="token comment" spellcheck="true"># 重建本地仓库缓存</span>yum makecache</code></pre><h2 id="13-cpio-rename-failed-Is-a-directory"><a href="#13-cpio-rename-failed-Is-a-directory" class="headerlink" title="13. cpio: rename failed - Is a directory"></a>13. cpio: rename failed - Is a directory</h2><pre class=" language-bash"><code class="language-bash">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HBASE/0.96.0.2.0/package/scripts/hbase_client.py"</span>, line 82, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    HbaseClient<span class="token punctuation">(</span><span class="token punctuation">)</span>.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py"</span>, line 280, <span class="token keyword">in</span> execute    method<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/common-services/HBASE/0.96.0.2.0/package/scripts/hbase_client.py"</span>, line 36, <span class="token keyword">in</span> <span class="token function">install</span>    self.install_packages<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py"</span>, line 567, <span class="token keyword">in</span> install_packages    retry_count<span class="token operator">=</span>agent_stack_retry_count<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/base.py"</span>, line 155, <span class="token keyword">in</span> __init__    self.env.run<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 160, <span class="token keyword">in</span> run    self.run_action<span class="token punctuation">(</span>resource, action<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/environment.py"</span>, line 124, <span class="token keyword">in</span> run_action    provider_action<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 54, <span class="token keyword">in</span> action_install    self.install_package<span class="token punctuation">(</span>package_name, self.resource.use_repos, self.resource.skip_repos<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/yumrpm.py"</span>, line 49, <span class="token keyword">in</span> install_package    self.checked_call_with_retries<span class="token punctuation">(</span>cmd, sudo<span class="token operator">=</span>True, logoutput<span class="token operator">=</span>self.get_logoutput<span class="token punctuation">(</span><span class="token punctuation">))</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 83, <span class="token keyword">in</span> checked_call_with_retries    <span class="token keyword">return</span> self._call_with_retries<span class="token punctuation">(</span>cmd, is_checked<span class="token operator">=</span>True, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/providers/package/__init__.py"</span>, line 91, <span class="token keyword">in</span> _call_with_retries    code, out <span class="token operator">=</span> func<span class="token punctuation">(</span>cmd, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 71, <span class="token keyword">in</span> inner    result <span class="token operator">=</span> function<span class="token punctuation">(</span>command, **kwargs<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 93, <span class="token keyword">in</span> checked_call    tries<span class="token operator">=</span>tries, try_sleep<span class="token operator">=</span>try_sleep<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 141, <span class="token keyword">in</span> _call_wrapper    result <span class="token operator">=</span> _call<span class="token punctuation">(</span>command, **kwargs_copy<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/python2.6/site-packages/resource_management/core/shell.py"</span>, line 294, <span class="token keyword">in</span> _call    raise Fail<span class="token punctuation">(</span>err_msg<span class="token punctuation">)</span>resource_management.core.exceptions.Fail: Execution of <span class="token string">'/usr/bin/yum -d 0 -e 0 -y install hbase_2_5_0_0_1245'</span> returned 1. Error unpacking rpm package hbase_2_5_0_0_1245-1.1.2.2.5.0.0-1245.el6.noarcherror: unpacking of archive failed on <span class="token function">file</span> /usr/hdp/2.5.0.0-1245/hbase/conf: cpio: <span class="token function">rename</span> failed - Is a directory</code></pre><ul><li>解决方法</li></ul><p>删除conf这个目录</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@node2 hbase-client<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /usr/hdp/2.5.0.0-1245/hbase/</span><span class="token punctuation">[</span>root@node2 hbase<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># rm -rf conf/</span></code></pre><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;由于最近公司机房断电，导致几台测试环境 Ambari 服务器损坏， 所以对 Ambari服务进行了重装， 下面对此次安装过程中遇见的问题与解决办法进行记录&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;1-安装-unzip&quot;&gt;&lt;a href=&quot;#1-安装-unzip&quot; 
      
    
    </summary>
    
    
      <category term="ambari" scheme="https://www.hnbian.cn/categories/ambari/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="ambari" scheme="https://www.hnbian.cn/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>Spark 数据倾斜分析与解决思路</title>
    <link href="https://www.hnbian.cn/posts/d8fad075.html"/>
    <id>https://www.hnbian.cn/posts/d8fad075.html</id>
    <published>2022-08-08T09:58:48.000Z</published>
    <updated>2023-05-06T01:31:47.507Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1. 背景介绍"></a>1. 背景介绍</h2><p>数据倾斜是在大数据计算中，经常会面临一个非常棘手的问题。数据倾斜会导致 Spark 作业性能大幅下降，这远远低于我们的期望。为了确保 Spark 作业的高性能，我们需要进行数据倾斜调优。数据倾斜调优是一项复杂的任务，需要采用多种技术方案来解决不同类型的数据倾斜问题。</p><h2 id="2-数据倾斜的影响"><a href="#2-数据倾斜的影响" class="headerlink" title="2. 数据倾斜的影响"></a>2. 数据倾斜的影响</h2><p>Spark 任务数据倾斜是指在分布式计算过程中，数据分布不均匀，导致个别任务处理的数据量远大于其他任务。这种现象会对Spark任务的性能和稳定性产生负面影响。以下是数据倾斜所带来的影响：</p><ol><li>性能下降：由于个别任务处理的数据量较大，需要更长的时间来完成。在Spark集群中，所有任务都必须完成后，整个作业才能结束。因此，处理时间较长的任务会拖慢整个作业的运行速度。</li><li>资源浪费：由于大部分任务较快地完成，集群中的其他节点可能会处于空闲状态，等待数据倾斜的任务完成。这种情况下，集群资源的利用率较低，导致资源浪费。</li><li>容易出现OOM（内存溢出）异常：数据倾斜可能导致单个任务的内存需求远超过预期。在处理大量数据时，可能触发OOM异常，导致任务失败。</li><li>可靠性降低：数据倾斜可能导致任务执行失败或长时间无法完成，影响整个作业的可靠性。</li></ol><h2 id="3-数据倾斜的原理"><a href="#3-数据倾斜的原理" class="headerlink" title="3. 数据倾斜的原理"></a>3. 数据倾斜的原理</h2><p><strong>数据倾斜的原理很简单</strong>：在执行shuffle操作时，需要将各节点上相同key的数据拉取到某个节点上的一个task进行处理，如按key进行聚合或join等操作。如果某个key对应的数据量特别大，就容易发生数据倾斜现象。</p><p>例如，绝大多数key可能仅对应1000条数据，但个别key却对应了100万条数据。这样的情况下，大部分task将只会处理1000条数据，并在1秒内完成。但个别task可能要处理100万条数据，需要运行一两个小时。这会导致整个Spark作业的运行时间被这些少数task拉长。因此，当出现数据倾斜时，Spark作业看起来运行得非常缓慢。甚至，由于某个task处理的数据量过大，可能会导致内存溢出。</p><p>从下面的图示中，我们可以观察到以下情况：</p><p>“hello”这个key在三个节点上对应了总共7条数据，这些数据将被拉取到同一个task中进行处理。</p><p>与此同时，“world”和“you”这两个key分别仅对应1条数据。因此，另外两个task只需分别处理1条数据。</p><p>由于第一个task需要处理的数据量更大，其运行时间将比另外两个task更长。整个stage的运行速度将由运行最慢的那个task决定。</p><img src="https://images.hnbian.cn/202305041735695.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt=" " style="zoom:67%;"><h2 id="4-定位数据倾斜"><a href="#4-定位数据倾斜" class="headerlink" title="4. 定位数据倾斜"></a>4. 定位数据倾斜</h2><h3 id="导致数据倾斜的算子"><a href="#导致数据倾斜的算子" class="headerlink" title="导致数据倾斜的算子"></a>导致数据倾斜的算子</h3><p>数据倾斜仅在 shuffle 过程中发生。以下是一些常用的可能触发shuffle操作的算子：<code>distinct</code>、<code>groupByKey</code>、<code>reduceByKey</code>、<code>aggregateByKey</code>、<code>join</code>、<code>cogroup</code>和<code>repartition</code>。当出现数据倾斜时，可能是由于代码中使用了这些算子之一所导致的。</p><h3 id="出现数据倾斜的-Stage"><a href="#出现数据倾斜的-Stage" class="headerlink" title="出现数据倾斜的 Stage"></a>出现数据倾斜的 Stage</h3><p>为了确定数据倾斜发生在哪个stage，可以通过检查Spark作业的运行日志或者Spark Web UI来定位。如果使用yarn-client模式提交作业，可以在本地日志中查看当前运行到了哪个stage。例如，可以参考这篇文章：<a href="https://www.hnbian.cn/posts/d47af904.html">Hive 数据倾斜问题定位排查及解决</a>。</p><p>如果使用yarn-cluster模式提交作业，可以通过Spark Web UI查看当前运行到了哪个stage。</p><p>此外，无论使用哪种提交模式，都可以在Spark Web UI上查看当前stage的各个task分配的数据量。通过这种方式，可以进一步确定是否是数据分配不均匀导致的数据倾斜。</p><p>如下图所示，我们可以从倒数第三列观察到每个task的运行时间。某些task执行非常快，仅需几秒钟即可完成；另一些task执行速度较慢，需要几分钟才能完成。仅从运行时间上看，我们已经可以确定出现了数据倾斜。此外，倒数第一列展示了每个task处理的数据量。可以明显看到，运行时间短的task仅需处理几百KB的数据，而运行时间长的task需要处理几千KB的数据，数据处理量相差10倍。这进一步确认了数据倾斜的发生。</p><p><img src="https://images.hnbian.cn/202305041743977.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="52sYt1c8t_EHnt_UWj-UU-transformed"></p><p>在确定数据倾斜发生在哪个stage之后，我们需要根据 stage 划分原理推算出倾斜的那个 stage 对应代码中的哪一部分。这部分代码中肯定会包含一个shuffle类算子。</p><p>要精确推算 stage 与代码之间的对应关系，需要对 Spark 源码有深入理解。但在此，我们可以介绍一个相对简单且实用的推算方法：只需观察 Spark 代码中出现的 shuffle 类算子或 Spark SQL 中出现的可能导致 shuffle 的语句（如group by语句），就可以判断，以这个地方为界限，划分出了前后两个stage。</p><p>以 Spark 最基础的入门程序 WordCount 为例，说明如何用最简单的方法大致推算出一个stage对应的代码。在下面的示例中，整个代码里只有一个<code>reduceByKey</code>算子会发生shuffle。因此，我们可以认为，以这个算子为界限，将划分出前后两个stage。</p><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 导入Spark配置类</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token comment" spellcheck="true">// 导入Spark上下文类</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token comment" spellcheck="true">// 创建Spark配置对象</span><span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 根据配置创建Spark上下文对象</span><span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 从HDFS上读取文本文件内容，并创建一个名为lines的RDD</span><span class="token keyword">val</span> lines <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://..."</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 将lines中的每一行用空格拆分成单词，得到一个名为words的RDD</span><span class="token keyword">val</span> words <span class="token operator">=</span> lines<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 为每个单词创建一个键值对，其中键是单词，值是1，得到一个名为pairs的RDD</span><span class="token keyword">val</span> pairs <span class="token operator">=</span> words<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// ======= stage 划分 ========</span><span class="token comment" spellcheck="true">// 根据键（单词）对值（计数）进行汇总，将同一个单词的计数相加，得到一个名为wordCounts的RDD</span><span class="token keyword">val</span> wordCounts <span class="token operator">=</span> pairs<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 收集wordCounts中的所有结果，并在控制台上逐行打印</span>wordCounts<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><ul><li>stage 0 主要负责执行从<code>textFile</code>到<code>map</code>操作，以及执行shuffle write操作。我们可以简单地将shuffle write操作理解为对<code>pairs</code> RDD中的数据进行分区操作，这样每个task处理的数据中，相同的key会写入同一个磁盘文件内。</li><li>stage 1 主要负责执行从<code>reduceByKey</code>到<code>collect</code>操作。在stage 1的各个task开始运行时，它们会首先执行shuffle read操作。执行shuffle read操作的task会从stage 0的各个task所在节点拉取属于自己需要处理的那些key，然后对同一个key进行全局性的聚合或join等操作。在这个例子中，这意味着对key的value值进行累加。在stage 1执行完<code>reduceByKey</code>算子之后，最终的<code>wordCounts</code> RDD就被计算出来了。接着，会执行<code>collect</code>算子，将所有数据拉取到Driver上，供我们遍历和打印输出。</li></ul><p>通过分析单词计数程序，我们希望能帮助大家了解最基本的stage划分原理，以及在两个stage边界处如何执行shuffle操作。这样，我们就能快速定位发生数据倾斜的stage对应代码的某个部分。</p><p>例如，在Spark Web UI或本地日志中，我们发现stage 1的某些task执行特别慢，判断stage 1出现了数据倾斜。此时，我们可以回到代码中，确定stage 1主要包括了<code>reduceByKey</code>这个shuffle类算子。基本上，我们可以确定是由<code>reduceByKey</code>算子导致的数据倾斜问题。</p><h2 id="5-出现内存溢出问题"><a href="#5-出现内存溢出问题" class="headerlink" title="5. 出现内存溢出问题"></a>5. 出现内存溢出问题</h2><p>解决内存溢出问题时，定位问题代码相对容易。我们建议直接查看yarn-client模式下本地日志的异常栈，或者通过YARN查看yarn-cluster模式下的日志中的异常栈。通常情况下，通过异常栈信息可以定位到代码中导致内存溢出的具体行数。接下来，在该行代码附近查找，通常会发现shuffle类算子。此时，很可能是这个算子导致了数据倾斜。</p><p>请注意，不能仅凭偶然发生的内存溢出就判断是否发生了数据倾斜。因为编写的代码中可能存在bug，或者数据异常偶然导致了内存溢出。因此，还是需要按照前面介绍的方法，通过Spark Web UI查看报错的那个stage的各个task的运行时间以及分配的数据量，才能确定是否确实是数据倾斜导致了内存溢出。</p><h2 id="6-查看导致倾斜key的分布"><a href="#6-查看导致倾斜key的分布" class="headerlink" title="6. 查看导致倾斜key的分布"></a>6. 查看导致倾斜key的分布</h2><p>在确定数据倾斜发生的位置后，通常需要分析导致数据倾斜的那个执行了shuffle操作的RDD或Hive表，并检查其中key的分布情况。这主要是为了为后续选择解决方案提供依据。根据不同的key分布以及不同的shuffle算子组合，可能需要选择不同的技术方案来解决问题。此时，根据你执行的操作也不同，可以有多种方式来查看key分布：</p><ul><li>如果数据倾斜是由Spark SQL中的group by或join语句导致的，可以查询SQL中涉及的表的key分布情况。</li><li>如果数据倾斜是由对Spark RDD执行的shuffle算子引起的，可以在Spark作业中添加代码来查看key分布，例如使用RDD.countByKey()。接着将统计出的各个key出现的次数通过collect或take操作获取到客户端并打印，这样便能查看key的分布情况。</li></ul><p>例如，在单词计数程序中，如果确定是 stage 1 的 reduceByKey 算子导致了数据倾斜，那么应该检查执行 reduceByKey 操作的 RDD 中的 key 分布情况。在此示例中，我们关注的是 pairs RDD。如下所示，我们可以先对 pairs 进行10%的样本抽取，然后使用 countByKey 算子统计每个 key 出现的次数，最后在客户端遍历并打印样本数据中各个 key 的出现次数。</p><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 对 pairs RDD 中的数据进行抽样，采样率为 10%（0.1），不放回抽样（false）</span><span class="token keyword">val</span> sampledPairs <span class="token operator">=</span> pairs<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 对抽样后的数据进行按 key 的计数统计</span><span class="token keyword">val</span> sampledWordCounts <span class="token operator">=</span> sampledPairs<span class="token punctuation">.</span>countByKey<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 遍历并打印样本数据中各个 key 的出现次数</span>sampledWordCounts<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h2 id="7-数据倾斜的解决方案"><a href="#7-数据倾斜的解决方案" class="headerlink" title="7. 数据倾斜的解决方案"></a>7. 数据倾斜的解决方案</h2><h3 id="7-1-提高shuffle操作的并行度"><a href="#7-1-提高shuffle操作的并行度" class="headerlink" title="7.1 提高shuffle操作的并行度"></a>7.1 提高shuffle操作的并行度</h3><ol><li><strong>适用场景</strong>：</li></ol><p>当必须直接处理数据倾斜时，优先考虑这个方案，因为它是最简单的处理数据倾斜的方法。</p><ol start="2"><li>实现思路</li></ol><p>在对 RDD 执行 shuffle 算子时，给算子传入一个参数，如 reduceByKey(1000)，该参数设置了 shuffle read task 的数量。对于 Spark SQL 中的 shuffle 类语句，如 group by、join 等，需要设置一个参数：spark.sql.shuffle.partitions，该参数代表了 shuffle read task 的并行度，其默认值为 200，对许多场景来说可能过小。</p><ol start="3"><li>实现原理</li></ol><p>增加 shuffle read task 的数量可让原本分配给一个 task 的多个 key 分配给多个 task，从而使每个 task 处理更少的数据。例如，如果原本有 5 个 key，每个 key 对应 10 条数据，这 5 个 key 都分配给一个 task，那么该 task 需要处理 50 条数据。增加了 shuffle read task 后，每个 task 只分配到一个 key，即每个 task 处理 10 条数据，自然每个 task 的执行时间会变短。</p><ol start="4"><li>优点</li></ol><p>实现相对简单，可有效缓解和减轻数据倾斜的影响。</p><ol start="5"><li>缺点</li></ol><p>仅缓解了数据倾斜，没有彻底消除问题，效果有限。</p><ol start="6"><li>实践经验</li></ol><p>该方案通常无法完全解决数据倾斜，因为在极端情况下，如某个 key 对应的数据量有 100 万，无论 task 数量增加到多少，这个 key 仍会分配到一个 task 中处理，导致数据倾斜。因此，这种方案只是在发现数据倾斜时尝试使用的第一种方法，试图用简单的方法缓解数据倾斜，或与其他方案结合使用。</p><h3 id="7-2-使用-ETL-预处理数据"><a href="#7-2-使用-ETL-预处理数据" class="headerlink" title="7.2 使用 ETL 预处理数据"></a>7.2 使用 ETL 预处理数据</h3><ol><li>适用场景</li></ol><p>这个方案适用于导致数据倾斜的原因是不均匀分布的 Hive 表。如果这个 Hive 表中的数据分布很不均匀（例如某个 key 有 100 万条数据，而其他 key 只有 10 条数据），并且业务场景需要频繁地使用 Spark 对这个 Hive 表进行分析操作，那么这个技术方案是比较合适的。</p><ol start="2"><li>实现思路</li></ol><p>可以考虑通过 Hive 进行数据预处理（例如，通过 Hive ETL 对数据按 key 进行聚合，或预先与其他表进行 join 操作），然后让 Spark 作业针对预处理后的 Hive 表进行操作。由于数据已经进行了预处理，Spark 作业中就不需要再使用原先的 shuffle 类算子进行类似操作了。</p><ol start="3"><li>实现原理</li></ol><p>这种方案从根本上解决了数据倾斜问题，因为它完全避免了在 Spark 中执行 shuffle 类算子，因此肯定不会出现数据倾斜。但是，这种方法只治标不治本，因为数据本身存在分布不均匀的问题，Hive ETL 中进行 group by 或 join 等 shuffle 操作时，仍会出现数据倾斜，导致 Hive ETL 速度较慢。我们只是将数据倾斜的问题提前到 Hive ETL 中，避免了 Spark 程序中的数据倾斜。</p><ol start="4"><li>优点</li></ol><p>实现简单便捷，效果非常好，完全避免了数据倾斜，大幅度提升了 Spark 作业的性能。</p><ol start="5"><li>缺点</li></ol><p>治标不治本，Hive ETL 中仍会出现数据倾斜。</p><ol start="6"><li>实践经验</li></ol><p>在 Java 系统与 Spark 结合使用的项目中，如果 Java 代码频繁调用 Spark 作业，且对 Spark 作业的执行性能要求较高，这种方案比较合适。将数据倾斜问题提前到上游的 Hive ETL，每天执行一次，只有那一次比较慢，之后每次 Java 调用 Spark 作业时，执行速度都会很快，提供更好的用户体验。</p><ol start="7"><li>项目实践经验</li></ol><p>美团·点评的交互式用户行为分析系统采用了这种方案。该系统主要允许用户通过 Java Web 系统提交数据分析统计任务，后端通过 Java 提交 Spark 作业进行数据分析统计。要求 Spark 作业速度快，尽量在 10 分钟以内，否则速度太慢，用户体验会受到影响。因此，项目将部分 Spark 作业的 shuffle 操作提前到 Hive ETL 中，让 Spark 直接使用预处理过的 Hive 中</p><h3 id="7-3-过滤导致倾斜的key"><a href="#7-3-过滤导致倾斜的key" class="headerlink" title="7.3 过滤导致倾斜的key"></a>7.3 过滤导致倾斜的key</h3><ol><li>适用场景</li></ol><p>这个方案适合当导致倾斜的 key 只有少数几个，且对计算结果的影响不大的情况。例如，99% 的 key 对应 10 条数据，但只有一个 key 对应了 100 万数据，从而导致数据倾斜。</p><ol start="2"><li>实现思路</li></ol><p>如果判断那些少数数据量特别多的 key 对作业的执行和计算结果不是特别重要，可以直接过滤掉这些 key。在 Spark SQL 中，可以使用 where 子句过滤掉这些 key；在 Spark Core 中，可以对 RDD 执行 filter 算子过滤掉这些 key。如果需要动态判断并过滤数据量最多的 key，可以使用 sample 算子对 RDD 进行采样，计算出每个 key 的数量，然后过滤掉数据量最多的 key。</p><ol start="3"><li>实现原理</li></ol><p>过滤掉导致数据倾斜的 key 后，这些 key 就不会参与计算，自然就不会产生数据倾斜。</p><ol start="4"><li>优点</li></ol><p>实现简单，效果很好，可以完全规避数据倾斜。</p><ol start="5"><li>缺点</li></ol><p>适用场景较少，大多数情况下，导致倾斜的 key 数量较多，并不仅限于少数几个。</p><ol start="6"><li>实践经验</li></ol><p>在项目中曾使用这种方案解决数据倾斜。有一次，某一天的 Spark 作业突然出现 OOM，经调查发现，是由于 Hive 表中某个 key 的数据异常导致数据量暴增。因此采取每次执行前先进行采样，计算出样本中数据量最大的几个 key，然后在程序中将这些 key 过滤掉。</p><h3 id="7-4-两阶段聚合"><a href="#7-4-两阶段聚合" class="headerlink" title="7.4 两阶段聚合"></a>7.4 两阶段聚合</h3><ol><li><strong>适用场景</strong>：</li></ol><p>两阶段聚合是一种适用于在对RDD执行reduceByKey等聚合类shuffle算子或在Spark SQL中使用group by语句进行分组聚合的方案。它通过结合局部聚合和全局聚合的方式，提高了数据处理效率。</p><ol start="2"><li>实现思路</li></ol><p>该方案的核心是进行两阶段聚合。首先是局部聚合，为每个 key 添加一个随机数，如 10 以内的随机数。这样，原先相同的 key 变得不同，例如 (hello, 1) 变为 (1_hello, 1) 和 (2_hello, 1)。接着对添加了随机数的数据执行 reduceByKey 等聚合操作进行局部聚合。局部聚合结果变为 (1_hello, 2) 和 (2_hello, 2)。然后去除各个 key 的前缀，再次进行全局聚合操作，得到最终结果，如 (hello, 4)。</p><ol start="3"><li>实现原理</li></ol><p>通过给原本相同的 key 添加随机前缀，将原本由一个 task 处理的数据分散到多个 task 上进行局部聚合，解决单个 task 处理数据量过多的问题。去除随机前缀后，再次进行全局聚合，得到最终结果。</p><ol start="4"><li>优点</li></ol><p>对于聚合类的 shuffle 操作导致的数据倾斜，效果较好。通常可以解决数据倾斜，或至少大幅度缓解数据倾斜，将 Spark 作业性能提升数倍以上。</p><ol start="5"><li>缺点</li></ol><p>仅适用于聚合类的 shuffle 操作，适用范围相对较窄。若为 join 类的 shuffle 操作，需使用其他解决方案。</p><p><img src="https://images.hnbian.cn/202305051556001.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><ul><li><ol><li>给RDD中的每个key都打上一个随机前缀</li></ol></li></ul><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 第一步，给RDD中的每个key都打上一个随机前缀。</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random<span class="token comment" spellcheck="true">// 假设已经存在一个键值对类型的RDD[(Long, Long)]</span><span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">?</span><span class="token operator">?</span><span class="token operator">?</span><span class="token comment" spellcheck="true">// 为每个键添加随机前缀，将原本相同的键变为多个不同的键</span><span class="token keyword">val</span> randomPrefixRdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd<span class="token punctuation">.</span>map <span class="token punctuation">{</span>  <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span>    <span class="token comment" spellcheck="true">// 生成一个0到9之间的随机数作为前缀</span>    <span class="token keyword">val</span> prefix <span class="token operator">=</span> Random<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 将随机数前缀与原始键连接，形成新的键，并返回新的键值对</span>    <span class="token punctuation">(</span>s<span class="token string">"${prefix}_$key"</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><pre class=" language-java"><code class="language-java">JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token operator">></span> randomPrefixRdd <span class="token operator">=</span> rdd<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>Long<span class="token operator">></span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                Random random <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">int</span> prefix <span class="token operator">=</span> random<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span>prefix <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ul><li><ol start="2"><li>对打上随机前缀的key进行局部聚合</li></ol></li></ul><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 对带有随机前缀的键值对进行局部聚合</span><span class="token keyword">val</span> localAggrRdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> randomPrefixRdd<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>v1<span class="token punctuation">,</span> v2<span class="token punctuation">)</span> <span class="token keyword">=></span> v1 <span class="token operator">+</span> v2<span class="token punctuation">)</span></code></pre><pre class=" language-java"><code class="language-java">JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token operator">></span> localAggrRdd <span class="token operator">=</span> randomPrefixRdd<span class="token punctuation">.</span> <span class="token function">reduceByKey</span> <span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">Function2</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Long <span class="token function">call</span><span class="token punctuation">(</span>Long v1<span class="token punctuation">,</span> Long v2<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ul><li><ol start="3"><li>去除RDD中每个key的随机前缀</li></ol></li></ul><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 移除随机前缀，还原为原始键值对</span><span class="token keyword">val</span> removedRandomPrefixRdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> localAggrRdd<span class="token punctuation">.</span>map <span class="token punctuation">{</span>  <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span>    <span class="token keyword">val</span> originalKey <span class="token operator">=</span> key<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong    <span class="token punctuation">(</span>originalKey<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><pre class=" language-java"><code class="language-java">JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> removedRandomPrefixRdd <span class="token operator">=</span> localAggrRdd<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span>Long<span class="token operator">></span><span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Long<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">long</span> originalKey <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>tuple<span class="token punctuation">.</span>_1<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span>originalKey<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ul><li><ol start="4"><li>对去除了随机前缀的RDD进行全局聚合</li></ol></li></ul><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 对移除随机前缀后的键值对进行全局聚合</span><span class="token keyword">val</span> globalAggrRdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> removedRandomPrefixRdd<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span></code></pre><pre class=" language-java"><code class="language-java">JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> globalAggrRdd <span class="token operator">=</span> removedRandomPrefixRdd<span class="token punctuation">.</span> <span class="token function">reduceByKey</span> <span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">Function2</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Long <span class="token function">call</span><span class="token punctuation">(</span>Long v1<span class="token punctuation">,</span> Long v2<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="7-5-将reduce-join转为map-join"><a href="#7-5-将reduce-join转为map-join" class="headerlink" title="7.5 将reduce join转为map join"></a>7.5 将reduce join转为map join</h3><ol><li>方案适用场景</li></ol><p>此方案适用于在对 RDD 进行 join 类操作，或在 Spark SQL 中使用 join 语句时，且其中一个 RDD 或表的数据量相对较小（如几百M或一两G）。</p><ol start="2"><li>方案实现思路</li></ol><p>使用 Broadcast 变量和 map 类算子来实现 join 操作，而非使用 join 算子，从而完全避免 shuffle 操作，彻底消除数据倾斜。首先，将较小的 RDD 数据通过 collect 算子拉取到 Driver 端内存，然后创建一个 Broadcast 变量。接着，对另一个 RDD 执行 map 类算子，在算子函数内从 Broadcast 变量中获取较小 RDD 的全量数据，并将其与当前 RDD 的每条数据按连接 key 进行比对。如果连接 key 相同，则按需将两个 RDD 的数据连接起来。</p><ol start="3"><li>方案实现原理</li></ol><p>普通的 join 操作会进行 shuffle，将相同 key 的数据拉取到一个 shuffle read task 中再进行join（reduce join）。而在一个较小的 RDD 中使用 map join（广播小RDD全量数据+map算子）可以避免 shuffle 操作，因此不会产生数据倾斜。</p><ol start="4"><li>方案优点</li></ol><p>对于因 join 操作引起的数据倾斜问题，该方案效果非常好，因为完全避免了 shuffle 操作，从而消除了数据倾斜。</p><ol start="5"><li>方案缺点</li></ol><p>适用场景较有限，只适用于一个大表和一个小表的情况。由于需要广播小表，这将消耗较多内存资源，同时在 Driver 和每个 Executor 内存中都会驻留一份小 RDD 的全量数据。如果广播的 RDD 数据量较大（如10G以上），可能会导致内存溢出。因此，该方案不适合两个大表的情况。</p><img src="https://images.hnbian.cn/202305051534766.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" style="zoom:67%;"><ul><li>代码示例：</li></ul><p>需要注意的是下面的做法，仅仅适用于rdd1中的key没有重复，全部是唯一的场景。如果rdd1中有多个相同的key，那么就得用flatMap类的操作，在进行join的时候不能用map，而是得遍历rdd1所有数据进行join。rdd2中每条数据都可能会返回多条join后的数据。</p><pre class=" language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 首先将数据量比较小的RDD的数据，collect到Driver中来。</span><span class="token keyword">val</span> rdd1Data<span class="token operator">:</span> List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toList<span class="token comment" spellcheck="true">// 然后使用Spark的广播功能，将小RDD的数据转换成广播变量，这样每个Executor就只有一份RDD的数据。</span><span class="token comment" spellcheck="true">// 可以尽可能节省内存空间，并且减少网络传输性能开销。</span><span class="token keyword">val</span> rdd1DataBroadcast<span class="token operator">:</span> Broadcast<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>rdd1Data<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 对另外一个RDD执行map类操作，而不再是join类操作。</span><span class="token keyword">val</span> joinedRdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>map <span class="token punctuation">{</span> tuple <span class="token keyword">=></span>  <span class="token comment" spellcheck="true">// 在算子函数中，通过广播变量，获取到本地Executor中的rdd1数据。</span>  <span class="token keyword">val</span> rdd1Data<span class="token operator">:</span> List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1DataBroadcast<span class="token punctuation">.</span>value  <span class="token comment" spellcheck="true">// 可以将rdd1的数据转换为一个Map，便于后面进行join操作。</span>  <span class="token keyword">val</span> rdd1DataMap<span class="token operator">:</span> Map<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">,</span> Row<span class="token punctuation">]</span> <span class="token operator">=</span> rdd1Data<span class="token punctuation">.</span>toMap  <span class="token comment" spellcheck="true">// 获取当前RDD数据的key以及value。</span>  <span class="token keyword">val</span> key<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>toString  <span class="token keyword">val</span> value<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> tuple<span class="token punctuation">.</span>_2  <span class="token comment" spellcheck="true">// 从rdd1数据Map中，根据key获取到可以join到的数据。</span>  <span class="token keyword">val</span> rdd1Value<span class="token operator">:</span> Row <span class="token operator">=</span> rdd1DataMap<span class="token punctuation">(</span>key<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>  <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">(</span>value<span class="token punctuation">,</span> rdd1Value<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 首先将数据量比较小的RDD的数据， collect 到Driver中来。</span>List<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">>></span> rdd1Data <span class="token operator">=</span> rdd1<span class="token punctuation">.</span> <span class="token function">collect</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 然后使用Spark的广播功能，将小RDD的数据转换成广播变量，这样每个Executor就只有一份RDD的数据。</span><span class="token comment" spellcheck="true">// 可以尽可能节省内存空间，并且减少网络传输性能开销。</span><span class="token keyword">final</span> Broadcast<span class="token operator">&lt;</span>List<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">>>></span> rdd1DataBroadcast <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">broadcast</span><span class="token punctuation">(</span>rdd1Data<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 对另外一个RDD执行map类操作，而不再是join类操作。</span>JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> joinedRdd <span class="token operator">=</span> rdd2<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>String<span class="token operator">></span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// 在算子函数中，通过广播变量，获取到本地Executor中的rdd1数据。</span>                List<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">>></span> rdd1Data <span class="token operator">=</span> rdd1DataBroadcast<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">// 可以将rdd1的数据转换为一个Map，便于后面进行join操作。</span>                Map<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">></span> rdd1DataMap <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">for</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">></span> data <span class="token operator">:</span> rdd1Data<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    rdd1DataMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> data<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>                <span class="token comment" spellcheck="true">// 获取当前RDD数据的key以及value。</span>                String key <span class="token operator">=</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">;</span>                String value <span class="token operator">=</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">// 从rdd1数据Map中，根据key获取到可以join到的数据。</span>                Row rdd1Value <span class="token operator">=</span> rdd1DataMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">></span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> rdd1Value<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="7-6-对key分拆join操作"><a href="#7-6-对key分拆join操作" class="headerlink" title="7.6 对key分拆join操作"></a>7.6 对key分拆join操作</h3><ul><li><p>适用场景：当两个数据量较大的 RDD/Hive 表进行 join 且无法采用将 reduce join 转为 map join 的方法时，若数据倾斜是由一个 RDD/Hive 表中少数几个 key 的数据量过大而另一个表中所有 key 分布较均匀所导致的，此方案较为合适。</p></li><li><p>实现思路：</p></li></ul><ol><li>对含有少数数据量过大的 key 的 RDD，采用 sample 算子抽取样本，统计各 key 数量，找出数据量最大的几个 key。</li><li>从原 RDD 中拆分出这几个 key 对应的数据，形成一个独立 RDD，并为每个 key 添加 n 以内的随机数前缀。不会导致倾斜的大部分 key 形成另一个 RDD。</li><li>对需要 join 的另一个 RDD，过滤出这几个倾斜 key 对应的数据，形成一个独立 RDD。将每条数据扩充为 n 条数据，这些数据依次附加一个 0~n 的前缀。不会导致倾斜的大部分 key 形成另一个 RDD。</li><li>将带有随机前缀的独立 RDD 与另一个扩充 n 倍的独立 RDD 进行 join，将原先相同的 key 分散成 n 份，分配到多个 task 中进行 join。</li><li>另外两个普通 RDD 照常 join。</li><li>最后使用 union 算子合并两次 join 的结果，得到最终 join 结果。</li></ol><ul><li><p>实现原理：针对少数几个导致数据倾斜的 key，将它们分拆成独立 RDD，添加随机前缀，分散到 n 份进行 join。这样，这几个 key 对应的数据不再集中在少数 task 上，而是分散到多个 task 进行 join。</p></li><li><p>优点：针对仅有少数 key 导致的数据倾斜，此方案可以有效地打散 key 进行 join，且仅需针对少数倾斜 key 对应的数据扩充 n 倍，避免占用过多内存。</p></li><li><p>缺点：若导致倾斜的 key 数量特别多，如成千上万个 key 都导致数据倾斜，此方案不适用。</p></li></ul><p><img src="https://images.hnbian.cn/202305051745522.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><ul><li>代码示例</li></ul><pre class=" language-scala"><code class="language-scala"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token keyword">import</span> scala<span class="token punctuation">.</span>Tuple2<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random<span class="token comment" spellcheck="true">// 首先从包含了少数几个导致数据倾斜key的rdd1中，采样10%的样本数据。</span><span class="token keyword">val</span> sampledRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 对样本数据RDD统计出每个key的出现次数，并按出现次数降序排序。</span><span class="token comment" spellcheck="true">// 对降序排序后的数据，取出top 1或者top 100的数据，也就是key最多的前n个数据。</span><span class="token comment" spellcheck="true">// 具体取出多少个数据量最多的key，由大家自己决定，我们这里就取1个作为示范。</span><span class="token keyword">val</span> mappedSampledRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sampledRDD<span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">1L</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token keyword">val</span> countedSampledRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mappedSampledRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 将(key, count)格式的countedSampledRDD转换为(count, key)格式</span><span class="token keyword">val</span> reversedSampledRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> countedSampledRDD<span class="token punctuation">.</span>map <span class="token punctuation">{</span>  <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> count<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>count<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 按照count降序排序，取出导致数据倾斜的最大key</span><span class="token keyword">val</span> skewedUserid<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> reversedSampledRDD<span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span>ascending <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">.</span>_2<span class="token comment" spellcheck="true">// 从rdd1中分拆出导致数据倾斜的key，形成独立的RDD</span><span class="token keyword">val</span> skewedRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>filter <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span> key <span class="token operator">==</span> skewedUserid <span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 从rdd1中分拆出不导致数据倾斜的普通key，形成独立的RDD。</span><span class="token keyword">val</span> commonRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>filter <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">=></span> key <span class="token operator">!=</span> skewedUserid <span class="token punctuation">}</span><span class="token comment" spellcheck="true">// rdd2是那个所有key的分布相对较为均匀的rdd。</span><span class="token comment" spellcheck="true">// 过滤出rdd2中与导致数据倾斜的key对应的数据，分拆成单独的rdd</span><span class="token keyword">val</span> skewedRdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>filter <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">=></span> key <span class="token operator">==</span> skewedUserid <span class="token punctuation">}</span>  <span class="token punctuation">.</span>flatMap <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> row<span class="token punctuation">)</span> <span class="token keyword">=></span>    <span class="token comment" spellcheck="true">// 对每条数据扩容100倍，打上0～100的前缀</span>    <span class="token keyword">for</span> <span class="token punctuation">{</span>      i <span class="token keyword">&lt;-</span> <span class="token number">0</span> until <span class="token number">100</span>    <span class="token punctuation">}</span> <span class="token keyword">yield</span> <span class="token punctuation">(</span>s<span class="token string">"$i_$key"</span><span class="token punctuation">,</span> row<span class="token punctuation">)</span>  <span class="token punctuation">}</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random<span class="token comment" spellcheck="true">// 为rdd1中分拆出来的导致倾斜的key的独立rdd中的每条数据都打上100以内的随机前缀</span><span class="token keyword">val</span> prefixedSkewedRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> skewedRDD<span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span>  <span class="token keyword">val</span> prefix <span class="token operator">=</span> Random<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>s<span class="token string">"${prefix}_$key"</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 将这个rdd1中分拆出来的独立rdd与上面rdd2中分拆出来的独立rdd进行join</span><span class="token keyword">val</span> joinedRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> prefixedSkewedRDD  <span class="token punctuation">.</span>join<span class="token punctuation">(</span>skewedRdd2<span class="token punctuation">)</span>  <span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token punctuation">(</span>value1<span class="token punctuation">,</span> row<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=></span>    <span class="token keyword">val</span> key <span class="token operator">=</span> value1<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong    <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">(</span>value1<span class="token punctuation">,</span> row<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 将rdd1中分拆出来的包含普通key的独立rdd，直接与rdd2进行join</span><span class="token keyword">val</span> joinedRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> commonRDD<span class="token punctuation">.</span>join<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 将倾斜key join后的结果与普通key join后的结果，union起来，得到最终的join结果</span><span class="token keyword">val</span> joinedRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> joinedRDD1<span class="token punctuation">.</span>union<span class="token punctuation">(</span>joinedRDD2<span class="token punctuation">)</span></code></pre><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 首先从包含了少数几个导致数据倾斜key的rdd1中，采样10%的样本数据。</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> sampledRDD <span class="token operator">=</span> rdd1<span class="token punctuation">.</span><span class="token function">sample</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 对样本数据RDD统计出每个key的出现次数，并按出现次数降序排序。</span><span class="token comment" spellcheck="true">// 对降序排序后的数据，取出top 1或者top 100的数据，也就是key最多的前n个数据。</span><span class="token comment" spellcheck="true">// 具体取出多少个数据量最多的key，由大家自己决定，我们这里就取1个作为示范。</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> mappedSampledRDD <span class="token operator">=</span> sampledRDD<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>String<span class="token operator">></span><span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span>tuple<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> 1L<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>             <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> countedSampledRDD <span class="token operator">=</span> mappedSampledRDD<span class="token punctuation">.</span> <span class="token function">reduceByKey</span> <span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">Function2</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Long <span class="token function">call</span><span class="token punctuation">(</span>Long v1<span class="token punctuation">,</span> Long v2<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> reversedSampledRDD <span class="token operator">=</span> countedSampledRDD<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>         <span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>Long<span class="token operator">></span><span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Long<span class="token operator">></span><span class="token punctuation">(</span>tuple<span class="token punctuation">.</span>_2<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">final</span> Long skewedUserid <span class="token operator">=</span> reversedSampledRDD<span class="token punctuation">.</span><span class="token function">sortByKey</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">take</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>_2<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 从rdd1中分拆出导致数据倾斜的key，形成独立的RDD。</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> skewedRDD <span class="token operator">=</span> rdd1<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">Function</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>String<span class="token operator">></span><span class="token punctuation">,</span> Boolean<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Boolean <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> tuple<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>skewedUserid<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 从rdd1中分拆出不导致数据倾斜的普通key，形成独立的RDD。</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> commonRDD <span class="token operator">=</span> rdd1<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">Function</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>String<span class="token operator">></span><span class="token punctuation">,</span> Boolean<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Boolean <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> tuple<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> <span class="token operator">!</span>tuple<span class="token punctuation">.</span>_1<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>skewedUserid<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>         <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// rdd2，就是那个所有key的分布相对较为均匀的rdd。</span><span class="token comment" spellcheck="true">// 这里将rdd2中，前面获取到的key对应的数据，过滤出来，分拆成单独的rdd，并对rdd中的数据使用flatMap算子都扩容100倍。</span><span class="token comment" spellcheck="true">// 对扩容的每条数据，都打上0～100的前缀。</span>JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">></span> skewedRdd2 <span class="token operator">=</span> rdd2<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>         <span class="token keyword">new</span> <span class="token class-name">Function</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>Row<span class="token operator">></span><span class="token punctuation">,</span> Boolean<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Boolean <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">></span> tuple<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                <span class="token keyword">return</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>skewedUserid<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">flatMapToPair</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PairFlatMapFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>Row<span class="token operator">></span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> Row<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Iterable<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> <span class="token function">call</span><span class="token punctuation">(</span>                    Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">></span> tuple<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                Random random <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                List<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> list <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    list<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">></span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>                <span class="token keyword">return</span> list<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 将rdd1中分拆出来的导致倾斜的key的独立rdd，每条数据都打上100以内的随机前缀。</span><span class="token comment" spellcheck="true">// 然后将这个rdd1中分拆出来的独立rdd，与上面rdd2中分拆出来的独立rdd，进行join。</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> joinedRDD1 <span class="token operator">=</span> skewedRDD<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>String<span class="token operator">></span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                Random random <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">int</span> prefix <span class="token operator">=</span> random<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span>prefix <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span>skewedUserid2infoRDD<span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span>Row<span class="token operator">>></span><span class="token punctuation">,</span> Long<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                        <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>                        <span class="token annotation punctuation">@Override</span>                        <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> <span class="token function">call</span><span class="token punctuation">(</span>                            Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> tuple<span class="token punctuation">)</span>                            <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                            <span class="token keyword">long</span> key <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>tuple<span class="token punctuation">.</span>_1<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>                        <span class="token punctuation">}</span>                    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 将rdd1中分拆出来的包含普通key的独立rdd，直接与rdd2进行join。</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> joinedRDD2 <span class="token operator">=</span> commonRDD<span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 将倾斜key join后的结果与普通key join后的结果，uinon起来。</span><span class="token comment" spellcheck="true">// 就是最终的join结果。</span>JavaPairRDD<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> joinedRDD <span class="token operator">=</span> joinedRDD1<span class="token punctuation">.</span><span class="token function">union</span><span class="token punctuation">(</span>joinedRDD2<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="7-7-使用随机前缀和扩容RDD进行join"><a href="#7-7-使用随机前缀和扩容RDD进行join" class="headerlink" title="7.7 使用随机前缀和扩容RDD进行join"></a>7.7 使用随机前缀和扩容RDD进行join</h3><ol><li>适用场景</li></ol><p>此方案适用于在进行 join 操作时，由于 RDD 中存在大量导致数据倾斜的 key，从而无法通过分拆 key 进行优化的情况。</p><ol start="2"><li><p>实现思路</p><ol><li><p>参考对key分拆join操作，首先分析 RDD/Hive 表的数据分布，找到导致数据倾斜的 RDD/Hive 表，如多个 key 对应超过 1 万条数据。</p></li><li><p>为该 RDD 的每条数据添加一个 n 以内的随机前缀。</p></li><li><p>对另一个正常的 RDD 进行扩容，将每条数据扩充为 n 条数据，并分别添加 0~n 的前缀。</p></li><li><p>对两个处理后的 RDD 进行 join。</p></li></ol></li><li><p>实现原理</p></li></ol><p>通过为相同的 key 添加随机前缀，将它们转换为不同的 key，这样可以将处理任务分散到多个 task 中，而不是由一个 task 处理大量相同的 key。与对key分拆join操作不同，这个方案针对有大量倾斜 key 的情况，整个 RDD 需要进行数据扩容，对内存资源要求较高。</p><ol start="4"><li>优点</li></ol><p>适用于处理 join 类型的数据倾斜，效果显著，性能提升明显。</p><ol start="5"><li>缺点</li></ol><p>该方案主要是缓解数据倾斜，并未完全避免。由于需要对整个 RDD 进行扩容，对内存资源要求较高。</p><ol start="6"><li>实践经验</li></ol><p>在一个数据需求开发过程中，发现 join 操作导致数据倾斜。优化前，作业执行时间约为 60 分钟，采用此方案优化后，执行时间缩短至 10 分钟，性能提升了 6 倍。</p><ol start="7"><li>代码示例：</li></ol><pre class=" language-scala"><code class="language-scala"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token keyword">import</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random<span class="token keyword">import</span> scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable<span class="token punctuation">.</span>ListBuffer<span class="token comment" spellcheck="true">// 首先将其中一个 key 分布相对较为均匀的 RDD 膨胀 100 倍</span><span class="token keyword">val</span> expandedRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>flatMap <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> row<span class="token punctuation">)</span> <span class="token keyword">=></span>  <span class="token keyword">val</span> list <span class="token operator">=</span> <span class="token keyword">new</span> ListBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token keyword">&lt;-</span> <span class="token number">0</span> until <span class="token number">100</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>s<span class="token string">"0_$key"</span><span class="token punctuation">,</span> row<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">}</span>  list<span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 其次，将另一个有数据倾斜 key 的 RDD，每条数据都打上 100 以内的随机前缀</span><span class="token keyword">val</span> mappedRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">=></span>  <span class="token keyword">val</span> prefix <span class="token operator">=</span> Random<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>s<span class="token string">"$prefix_$key"</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 将两个处理后的 RDD 进行 join 即可</span><span class="token keyword">val</span> joinedRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Row<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mappedRDD<span class="token punctuation">.</span>join<span class="token punctuation">(</span>expandedRDD<span class="token punctuation">)</span></code></pre><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 首先将其中一个key分布相对较为均匀的RDD膨胀100倍。</span>JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">></span> expandedRDD <span class="token operator">=</span> rdd1<span class="token punctuation">.</span><span class="token function">flatMapToPair</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">PairFlatMapFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>Row<span class="token operator">></span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> Row<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Iterable<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> Row<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                List<span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> list <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    list<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">></span><span class="token punctuation">(</span><span class="token number">0</span> <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>                <span class="token keyword">return</span> list<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 其次，将另一个有数据倾斜key的RDD，每条数据都打上100以内的随机前缀。</span>JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> mappedRDD <span class="token operator">=</span> rdd2<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>        <span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span>String<span class="token operator">></span><span class="token punctuation">,</span> String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1L<span class="token punctuation">;</span>            <span class="token annotation punctuation">@Override</span>            <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>Tuple2<span class="token operator">&lt;</span>Long<span class="token punctuation">,</span> String<span class="token operator">></span> tuple<span class="token punctuation">)</span>                    <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>                Random random <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">int</span> prefix <span class="token operator">=</span> random<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span>prefix <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> tuple<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> tuple<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 将两个处理后的RDD进行join即可。</span>JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Row<span class="token operator">>></span> joinedRDD <span class="token operator">=</span> mappedRDD<span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span>expandedRDD<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>在实践中，处理简单数据倾斜场景时，通常只需使用一种方案就能解决。然而，针对复杂的数据倾斜问题，可能需要将多种方案组合使用。在有多个数据倾斜环节的 Spark 作业中，可以先运用预处理和过滤数据的方法来缓解数据倾斜，接着提升某些 shuffle 操作的并行度以优化性能，最后针对不同的聚合或 join 操作选择合适的优化方案。只有深入理解这些方案的思路和原理，才能根据不同情况灵活运用多种方案，解决数据倾斜问题。</p><ul><li>总结：</li></ul><ol><li>单一方案适用于简单数据倾斜：对于较简单的数据倾斜问题，使用一种方案就能得到有效改善。</li><li>复杂数据倾斜需要方案组合：在面临复杂的数据倾斜场景时，将多种解决方案结合起来使用可能更为有效。</li><li>预处理和过滤数据缓解数据倾斜：通过对数据进行预处理和过滤，可以在一定程度上减轻数据倾斜的影响。</li><li>提升 shuffle 操作并行度优化性能：调整并行度可以优化 shuffle 过程中的性能，减轻数据倾斜的影响。</li><li>针对聚合或 join 操作选择合适方案：根据具体场景，为不同的聚合或 join 操作选择最适合的优化方案。</li><li>理解方案原理以灵活运用：深入了解各种解决方案的原理和思路，以便在实际应用中更加灵活地运用这些方案，针对具体情况进行优化。</li></ol><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-背景介绍&quot;&gt;&lt;a href=&quot;#1-背景介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 背景介绍&quot;&gt;&lt;/a&gt;1. 背景介绍&lt;/h2&gt;&lt;p&gt;数据倾斜是在大数据计算中，经常会面临一个非常棘手的问题。数据倾斜会导致 Spark 作业性能大幅下降，这
      
    
    </summary>
    
    
      <category term="spark" scheme="https://www.hnbian.cn/categories/spark/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="spark" scheme="https://www.hnbian.cn/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Ambari 启动异常 ambari_commons.exceptions.FatalException</title>
    <link href="https://www.hnbian.cn/posts/2a5ba89.html"/>
    <id>https://www.hnbian.cn/posts/2a5ba89.html</id>
    <published>2022-07-26T07:12:49.000Z</published>
    <updated>2023-03-14T15:24:21.122Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>昨天公司机房停电， 没来得及关服务器， 早上到公司发现Ambari环境无法启动了</p><h2 id="异常信息"><a href="#异常信息" class="headerlink" title="异常信息"></a>异常信息</h2><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@node1 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># service ambari-server status</span>Using python  /usr/bin/pythonAmbari-server statusERROR: Could not create <span class="token keyword">.</span> Reason: <span class="token punctuation">[</span>Errno 2<span class="token punctuation">]</span> No such <span class="token function">file</span> or directory: <span class="token string">''</span>Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/usr/sbin/ambari-server.py"</span>, line 37, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    from ambari_server.checkDatabase <span class="token function">import</span> check_database  File <span class="token string">"/usr/lib/ambari-server/lib/ambari_server/checkDatabase.py"</span>, line 26, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    from ambari_server <span class="token function">import</span> serverConfiguration  File <span class="token string">"/usr/lib/ambari-server/lib/ambari_server/serverConfiguration.py"</span>, line 603, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    configDefaults <span class="token operator">=</span> ServerConfigDefaults<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-server/lib/ambari_server/serverConfiguration.py"</span>, line 512, <span class="token keyword">in</span> __init__    super<span class="token punctuation">(</span>ServerConfigDefaultsLinux, self<span class="token punctuation">)</span>.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-server/lib/ambari_server/serverConfiguration.py"</span>, line 396, <span class="token keyword">in</span> __init__    self.check_if_directories_writable<span class="token punctuation">(</span><span class="token punctuation">[</span>self.OUT_DIR, self.PID_DIR<span class="token punctuation">]</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-server/lib/ambari_server/serverConfiguration.py"</span>, line 448, <span class="token keyword">in</span> check_if_directories_writable    raise FatalException<span class="token punctuation">(</span>-1, <span class="token string">"Unable to access {0} directory. Confirm the directory is created and is writable by Ambari Server user account '{1}'"</span>.format<span class="token punctuation">(</span>directory, getpass.getuser<span class="token punctuation">(</span><span class="token punctuation">))</span><span class="token punctuation">)</span>ambari_commons.exceptions.FatalException: <span class="token string">"Fatal exception: Unable to access  directory. Confirm the directory is created and is writable by Ambari Server user account 'root', exit code -1"</span></code></pre><h2 id="异常原因"><a href="#异常原因" class="headerlink" title="异常原因"></a>异常原因</h2><ol><li>先查看 ambari.properties</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@node1 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># find / -name ambari.properties</span>/etc/ambari-server/conf/ambari.properties <span class="token punctuation">[</span>root@node1 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cat /etc/ambari-server/conf/ambari.properties </span><span class="token punctuation">[</span>root@node1 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#</span></code></pre><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ol><li>可以找其他的 ambari.properties 替换到当前文件夹中</li><li>使用 <code>ambari-server setup</code> 重新设置环境</li></ol><p>我这里没有找到 ambari.properties 配置文件， 是使用 <code>ambari-server setup</code> 配置了环境</p><h2 id="重新启动"><a href="#重新启动" class="headerlink" title="重新启动"></a>重新启动</h2><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@node1 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ambari-server status</span>Using python  /usr/bin/pythonAmbari-server statusAmbari Server not running.<span class="token punctuation">[</span>root@node1 conf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ambari-server start</span>Using python  /usr/bin/pythonStarting ambari-serverAmbari Server running with administrator privileges.Organizing resource files at /var/lib/ambari-server/resources<span class="token punctuation">..</span>.Ambari database consistency check started<span class="token punctuation">..</span>.Server PID at: /var/run/ambari-server/ambari-server.pidServer out at: /var/log/ambari-server/ambari-server.outServer log at: /var/log/ambari-server/ambari-server.logWaiting <span class="token keyword">for</span> server start<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>Server started listening on 8080DB configs consistency check found warnings. See /var/log/ambari-server/ambari-server-check-database.log <span class="token keyword">for</span> <span class="token function">more</span> details.Ambari Server <span class="token string">'start'</span> completed successfully.</code></pre><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;昨天公司机房停电， 没来得及关服务器， 早上到公司发现Ambari环境无法启动了&lt;/p&gt;
&lt;h2 id=&quot;异常信息&quot;&gt;&lt;a href=&quot;#异
      
    
    </summary>
    
    
      <category term="ambari" scheme="https://www.hnbian.cn/categories/ambari/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="ambari" scheme="https://www.hnbian.cn/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>Ambari2.7.3 集成 Flume Service</title>
    <link href="https://www.hnbian.cn/posts/ddab1ce.html"/>
    <id>https://www.hnbian.cn/posts/ddab1ce.html</id>
    <published>2022-06-05T03:25:18.000Z</published>
    <updated>2023-05-06T03:34:11.456Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>Ambari 是一个开源的 Apache 项目，用于部署、监控和管理 Hadoop 集群。Ambari 提供了一个易于使用的 Web UI 和 RESTful API 来简化 Hadoop 集群管理。Ambari 2.7.3 是 Ambari 项目的一个版本。</p><p>Flume 是一个分布式、可靠且可用的大数据日志采集、聚合和传输系统。它具有灵活的数据模型，可支持多种数据源和数据存储。Flume 可以将大量的日志数据从不同的来源高效地传输到 Hadoop 分布式文件系统（HDFS）或其他数据存储系统中，以便进行分析和处理。</p><p>但是在 Ambari 2.7.3 中，Flume 组件并未默认集成。这意味着在使用 Ambari 2.7.3 部署和管理 Hadoop 集群时，Flume 不会自动可用。要在 Ambari 2.7.3 中使用 Flume，您需要手动集成该组件。</p><h2 id="2-为什么要集成-Flume"><a href="#2-为什么要集成-Flume" class="headerlink" title="2. 为什么要集成 Flume"></a>2. 为什么要集成 Flume</h2><ol><li>灵活性：自定义集成 Flume 可以让用户根据自己的需求选择使用 Flume，而不是被迫接受 Ambari 默认提供的组件。这提供了更大的灵活性，用户可以根据项目需求和目标选择所需的组件。</li><li>定制化：手动集成 Flume 允许用户在整合过程中进行定制，例如，可以选择特定版本的 Flume，定制 Flume 配置文件，以满足特定的业务需求和场景。</li><li>节省资源：如果您的 Hadoop 集群不需要 Flume 进行日志采集和传输，那么不集成 Flume 可以节省计算资源和存储空间。这样，您可以专注于优化其他重要组件的性能，从而提高整个集群的性能。</li><li>简化部署和管理：通过手动集成 Flume，您可以更好地了解 Flume 的配置和工作原理。这有助于简化 Hadoop 集群的部署和管理，使您能够更有效地解决遇到的问题。</li></ol><p>总之，自定义集成 Flume 组件允许您根据项目需求灵活地部署和管理 Hadoop 集群，提高集群性能并简化集群管理。</p><h2 id="3-下载服务"><a href="#3-下载服务" class="headerlink" title="3. 下载服务"></a>3. 下载服务</h2><p>使用如下github地址，将编译的包，以及将flume添加到ambari-server的web页中的包，克隆到ambari-server所在服务器的一个目录中。</p><pre class=" language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/maikoulin/ambari-flume-service.git</code></pre><h2 id="4-下载-Flume安装包"><a href="#4-下载-Flume安装包" class="headerlink" title="4. 下载 Flume安装包"></a>4. 下载 Flume安装包</h2><p>去官网下载flume的tar包：<a href="https://flume.apache.org/download.html。下个" target="_blank" rel="noopener">https://flume.apache.org/download.html。下个</a> apache-flume-1.9.0-bin.tar.gz 的tar.gz包，或者直接使用如下命令：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">wget</span> https://dlcdn.apache.org/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz</code></pre><h2 id="5-上传-Flume-安装包"><a href="#5-上传-Flume-安装包" class="headerlink" title="5. 上传 Flume 安装包"></a>5. 上传 Flume 安装包</h2><p>将 apache-flume-1.9.0-bin.tar.gz 放到 ambari-flume-service/buildrpm/rpmbuild/SOURCES 这个相对目录下。</p><h2 id="6-编译-ambari-flume-service"><a href="#6-编译-ambari-flume-service" class="headerlink" title="6. 编译 ambari-flume-service"></a>6. 编译 ambari-flume-service</h2><p>ambari-flume-service/buildrpm 目录下执行:</p><pre class=" language-bash"><code class="language-bash">sh buildrpm.sh<span class="token comment" spellcheck="true"># 到此，rpm包编译完成</span></code></pre><h2 id="7-安装-ambari-flume-service"><a href="#7-安装-ambari-flume-service" class="headerlink" title="7. 安装 ambari-flume-service"></a>7. 安装 ambari-flume-service</h2><p>将 flumerpm/ambari-flume-service 相对目录下的Flume 复制到 ambari-server 主机的 /var/lib/ambari-server/resources/stacks/HDP/3.1/services/ 目录下并重启ambari-server:</p><pre class=" language-bash"><code class="language-bash">ambari-server restart<span class="token comment" spellcheck="true"># 到此，ambari的web界面就能识别出来flume了</span></code></pre><h2 id="8-创建-Flume-的本地源"><a href="#8-创建-Flume-的本地源" class="headerlink" title="8. 创建 Flume 的本地源"></a>8. 创建 Flume 的本地源</h2><pre class=" language-bash"><code class="language-bash"><span class="token function">mkdir</span> /var/www/html/flume/<span class="token comment" spellcheck="true"># 创建yum源</span>createrepo /var/www/html/flume/<span class="token comment" spellcheck="true"># 将上面生成的rpm包拷贝到此</span><span class="token function">cp</span> ambari-flume-service/buildrpm/rpmbuild/RPMS/noarch/flume-1.9.0-1.el7.noarch.rpm /var/www/html/flume/</code></pre><h2 id="9-创建repo"><a href="#9-创建repo" class="headerlink" title="9. 创建repo"></a>9. 创建repo</h2><pre class=" language-bash"><code class="language-bash"><span class="token function">cd</span> /etc/yum.repos.d/<span class="token function">cp</span> centos.repo flume.repovim flume.repo <span class="token punctuation">[</span>flume-1.9.0<span class="token punctuation">]</span>name<span class="token operator">=</span>flume-1.9.0baseurl<span class="token operator">=</span>http://hadoop01/flume/gpgcheck<span class="token operator">=</span>0enabled<span class="token operator">=</span>1</code></pre><h2 id="10-复制-repo"><a href="#10-复制-repo" class="headerlink" title="10. 复制 repo"></a>10. 复制 repo</h2><p>将 flume.repo复制到需要安装的子节点上</p><pre class=" language-bash"><code class="language-bash"><span class="token function">scp</span> flume.repohadoop05:/etc/yum.repos.d/</code></pre><h2 id="11-安装-Flume"><a href="#11-安装-Flume" class="headerlink" title="11. 安装 Flume"></a>11. 安装 Flume</h2><p>通过ambariUI安装flume</p><h3 id="11-1-点击-add-service，勾选flume"><a href="#11-1-点击-add-service，勾选flume" class="headerlink" title="11.1 点击 add service，勾选flume"></a>11.1 点击 add service，勾选flume</h3><p><img src="https://images.hnbian.cn/202305061041430.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><h3 id="11-2-分配客户端"><a href="#11-2-分配客户端" class="headerlink" title="11.2 分配客户端"></a>11.2 分配客户端</h3><p><img src="https://images.hnbian.cn/FqwJ1OW-g2vLKFVvP6_81_1LWzH8?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><h3 id="11-3-填写flume-agent配置文件"><a href="#11-3-填写flume-agent配置文件" class="headerlink" title="11.3 填写flume agent配置文件"></a>11.3 填写flume agent配置文件</h3><p><img src="https://images.hnbian.cn/FjAx2NbQQPWgdm7Ge_abZvTa52cZ?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p>可以在这里填写配置，也可以不填，等安装完成再填写。点击next。 </p><h3 id="11-4-预览页面"><a href="#11-4-预览页面" class="headerlink" title="11.4 预览页面"></a>11.4 预览页面</h3><p><img src="https://images.hnbian.cn/FszljSychupUu8yjJETHimRZ9iYS?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><h3 id="11-5-安装成功"><a href="#11-5-安装成功" class="headerlink" title="11.5 安装成功"></a>11.5 安装成功</h3><p><img src="https://images.hnbian.cn/FjCuixNE9EZlecCR9febHYEmK7Bh?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><h3 id="11-6-完成"><a href="#11-6-完成" class="headerlink" title="11.6 完成"></a>11.6 完成</h3><p><img src="https://images.hnbian.cn/FnMXADKfZi3Ck7snuptgW5czofE1?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><h3 id="11-7-填写agent配置文件"><a href="#11-7-填写agent配置文件" class="headerlink" title="11.7 填写agent配置文件"></a>11.7 填写agent配置文件</h3><p><img src="https://images.hnbian.cn/FiuZ_ESsnMvdvWcBvWm1YXhMxkDG?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p>如果刚刚在安装过程过程中没有填写 配置文件，可在此点击 “Configure Agents”，填写配置文件：</p><h2 id="12-测试-1"><a href="#12-测试-1" class="headerlink" title="12. 测试 1"></a>12. 测试 1</h2><p>通过avro方式接受数据，最后通过日志形式输出</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 定义来source、channel和sink</span>logger.sources <span class="token operator">=</span> r1logger.sinks <span class="token operator">=</span> k1logger.channels <span class="token operator">=</span> c1<span class="token comment" spellcheck="true"># 配置source</span><span class="token comment" spellcheck="true"># 来源类型：Avro</span>logger.sources.r1.type <span class="token operator">=</span> Avro <span class="token comment" spellcheck="true"># 绑定的 IP 地址：监听所有 IP 地址</span>logger.sources.r1.bind <span class="token operator">=</span> 0.0.0.0 <span class="token comment" spellcheck="true"># 监听的端口号：9999</span>logger.sources.r1.port <span class="token operator">=</span> 9999<span class="token comment" spellcheck="true"># 配置sink</span><span class="token comment" spellcheck="true"># sink关联的channel</span>logger.sinks.k1.channel<span class="token operator">=</span>c1 <span class="token comment" spellcheck="true"># sink 类型：logger (日志接收器）</span>logger.sinks.k1.type<span class="token operator">=</span>logger <span class="token comment" spellcheck="true"># 配置 Spillable Memory channel</span><span class="token comment" spellcheck="true"># channel类型：可溢出内存channel</span>logger.channels.c1.type<span class="token operator">=</span>SPILLABLEMEMORY <span class="token comment" spellcheck="true"># 检查点目录</span>logger.channels.c1.checkpointDir <span class="token operator">=</span> /data/flume/checkpoint<span class="token comment" spellcheck="true"># 数据目录</span>logger.channels.c1.dataDirs <span class="token operator">=</span> /data/flume logger.sources.r1.channels <span class="token operator">=</span> c1</code></pre><h2 id="13-测试-2"><a href="#13-测试-2" class="headerlink" title="13. 测试 2"></a>13. 测试 2</h2><p>通过avro方式接受数据，输出到kafka</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 定义来源、接收器和通道</span>logger.sources <span class="token operator">=</span> r1logger.sinks <span class="token operator">=</span> k1logger.channels <span class="token operator">=</span> c1<span class="token comment" spellcheck="true"># 配置source</span><span class="token comment" spellcheck="true"># 来源类型：Avro</span>logger.sources.r1.type <span class="token operator">=</span> Avro<span class="token comment" spellcheck="true"># 绑定的 IP 地址：监听所有 IP 地址</span>logger.sources.r1.bind <span class="token operator">=</span> 0.0.0.0 <span class="token comment" spellcheck="true"># 监听的端口号：9999</span>logger.sources.r1.port <span class="token operator">=</span> 9999 <span class="token comment" spellcheck="true"># 配置sink</span><span class="token comment" spellcheck="true"># sink 关联的channel</span>logger.sinks.k1.channel<span class="token operator">=</span>c1<span class="token comment" spellcheck="true"># 接收器类型：KafkaSink</span>logger.sinks.k1.type<span class="token operator">=</span>org.apache.flume.sink.kafka.KafkaSink <span class="token comment" spellcheck="true"># Kafka Broker 列表</span>logger.sinks.k1.brokerList<span class="token operator">=</span>hadoop03:6667,hadoop04:6667,node2:6667 <span class="token comment" spellcheck="true"># Kafka topic：testFlume</span>logger.sinks.k1.topic<span class="token operator">=</span>testFlume<span class="token comment" spellcheck="true"># 序列化类：StringEncoder</span>logger.sinks.k1.serializer.class<span class="token operator">=</span>kafka.serializer.StringEncoder <span class="token comment" spellcheck="true"># 是否在序列化后追加换行符：否</span>logger.sinks.k1.serializer.appendNewline<span class="token operator">=</span>false <span class="token comment" spellcheck="true"># 配置 Spillable Memory 通道 (channel)</span><span class="token comment" spellcheck="true"># 通道类型：可溢出内存通道</span>logger.channels.c1.type<span class="token operator">=</span>SPILLABLEMEMORY <span class="token comment" spellcheck="true"># 检查点目录</span>logger.channels.c1.checkpointDir <span class="token operator">=</span> /data/flume/checkpoint <span class="token comment" spellcheck="true"># 数据目录</span>logger.channels.c1.dataDirs <span class="token operator">=</span> /data/flume logger.sources.r1.channels <span class="token operator">=</span> c1</code></pre><p>保存之后，点击“ACTIONS”&gt;“Restart All”。到此安装完成。</p><h2 id="异常解决"><a href="#异常解决" class="headerlink" title="异常解决"></a>异常解决</h2><h3 id="Failed-to-execute-command-…message-‘Error-Nothing-to-do’"><a href="#Failed-to-execute-command-…message-‘Error-Nothing-to-do’" class="headerlink" title="Failed to execute command …message: ‘Error: Nothing to do’"></a>Failed to execute command …message: ‘Error: Nothing to do’</h3><pre class=" language-bash"><code class="language-bash">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/var/lib/ambari-agent/cache/stacks/HDP/3.1/services/FLUME/package/scripts/flume_handler.py"</span>, line 134, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    FlumeHandler<span class="token punctuation">(</span><span class="token punctuation">)</span>.execute<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/libraries/script/script.py"</span>, line 352, <span class="token keyword">in</span> execute    method<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/var/lib/ambari-agent/cache/stacks/HDP/3.1/services/FLUME/package/scripts/flume_handler.py"</span>, line 53, <span class="token keyword">in</span> <span class="token function">install</span>    self.install_packages<span class="token punctuation">(</span>env<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/libraries/script/script.py"</span>, line 853, <span class="token keyword">in</span> install_packages    retry_count<span class="token operator">=</span>agent_stack_retry_count<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/base.py"</span>, line 166, <span class="token keyword">in</span> __init__    self.env.run<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/environment.py"</span>, line 160, <span class="token keyword">in</span> run    self.run_action<span class="token punctuation">(</span>resource, action<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/environment.py"</span>, line 124, <span class="token keyword">in</span> run_action    provider_action<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/resource_management/core/providers/packaging.py"</span>, line 30, <span class="token keyword">in</span> action_install    self._pkg_manager.install_package<span class="token punctuation">(</span>package_name, self.__create_context<span class="token punctuation">(</span><span class="token punctuation">))</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/ambari_commons/repo_manager/yum_manager.py"</span>, line 219, <span class="token keyword">in</span> install_package    shell.repository_manager_executor<span class="token punctuation">(</span>cmd, self.properties, context<span class="token punctuation">)</span>  File <span class="token string">"/usr/lib/ambari-agent/lib/ambari_commons/shell.py"</span>, line 753, <span class="token keyword">in</span> repository_manager_executor    raise RuntimeError<span class="token punctuation">(</span>message<span class="token punctuation">)</span>RuntimeError: Failed to execute <span class="token function">command</span> <span class="token string">'/usr/bin/yum -y install flume'</span>, exited with code <span class="token string">'1'</span>, message: <span class="token string">'Error: Nothing to do'</span></code></pre><p><strong>解决办法：</strong></p><p>没有配置好 flume 的 yum 源，要把flume.repo复制到需要安装的子节点上，比如：要在 hadoop01、hadoop02 节点安装 flume，则需要把 flume.repo 复制到以上两个节点。</p><h3 id="Package-flume-1-9-0-1-el7-noarch-rpm-is-not-signed"><a href="#Package-flume-1-9-0-1-el7-noarch-rpm-is-not-signed" class="headerlink" title="Package flume-1.9.0-1.el7.noarch.rpm is not signed"></a>Package flume-1.9.0-1.el7.noarch.rpm is not signed</h3><p>解决办法：由于 flume 的 rpm 包时在本地编译的，没有对应的签名，将 flume.repo 中的 gpgcheck 设置为 0 即可。 gpgcheck 表示使用gpg 文件来检查软件包的签名。</p><h3 id="安装了flume的节点spark-shell启动报错："><a href="#安装了flume的节点spark-shell启动报错：" class="headerlink" title="安装了flume的节点spark-shell启动报错："></a>安装了flume的节点spark-shell启动报错：</h3><pre class=" language-bash"><code class="language-bash">hdfs@node2 spark2-client<span class="token punctuation">]</span>$ ./bin/spark-shell Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"/bin/hdp-select"</span>, line 453, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>    listPackages<span class="token punctuation">(</span>getPackages<span class="token punctuation">(</span><span class="token string">"all"</span><span class="token punctuation">))</span>  File <span class="token string">"/bin/hdp-select"</span>, line 271, <span class="token keyword">in</span> listPackages    os.path.basename<span class="token punctuation">(</span>os.path.dirname<span class="token punctuation">(</span>os.readlink<span class="token punctuation">(</span>linkname<span class="token punctuation">))</span><span class="token punctuation">))</span>OSError: <span class="token punctuation">[</span>Errno 22<span class="token punctuation">]</span> Invalid argument: <span class="token string">'/usr/hdp/current/flume-server'</span>ls: cannot access /usr/hdp//hadoop/lib: No such <span class="token function">file</span> or directoryException <span class="token keyword">in</span> thread <span class="token string">"main"</span> java.lang.IllegalStateException: hdp.version is not <span class="token keyword">set</span> <span class="token keyword">while</span> running Spark under HDP, please <span class="token keyword">set</span> through HDP_VERSION <span class="token keyword">in</span> spark-env.sh or add a java-opts <span class="token function">file</span> <span class="token keyword">in</span> conf with -Dhdp.version<span class="token operator">=</span>xxx    at org.apache.spark.launcher.Main.main<span class="token punctuation">(</span>Main.java:118<span class="token punctuation">)</span></code></pre><p><strong>解决办法：</strong></p><p>将 /usr/hdp/current 下的 flume-server 文件夹复制到 /usr/hdp/3.1.5.0-152 下，然后将 /usr/hdp/current 下的 flume-server 文件夹删除，创建软链接过去</p><pre class=" language-bash"><code class="language-bash"><span class="token function">cd</span> /usr/hdp/current<span class="token function">cp</span> -r flume-server <span class="token punctuation">..</span>/3.1.5.0-152/<span class="token function">rm</span> -rf flume-server<span class="token function">ln</span> -s /usr/hdp/3.1.5.0-152/flume-server flume-server</code></pre><h3 id="不显示启动日志"><a href="#不显示启动日志" class="headerlink" title="不显示启动日志"></a>不显示启动日志</h3><p>后续使用发现通过 ambari 启动flume，flume的启动日志（/var/log/flume/${agent_name}.out）不显示</p><p>解决办法：</p><p>在ambari-server所在机器上执行如下命令：</p><pre class=" language-bash"><code class="language-bash">vim /var/lib/ambari-server/resources/stacks/HDP/3.1/services/FLUME/package/scripts/flume.py</code></pre><p>找到 conf-file 所在位置，添加 -Dflume.root.logger=INFO,console</p><p>然后重启 ambari-server，重启flume即可。 </p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 介绍&quot;&gt;&lt;/a&gt;1. 介绍&lt;/h2&gt;&lt;p&gt;Ambari 是一个开源的 Apache 项目，用于部署、监控和管理 Hadoop 集群。Ambari 提供了一个易于使
      
    
    </summary>
    
    
      <category term="ambari" scheme="https://www.hnbian.cn/categories/ambari/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="ambari" scheme="https://www.hnbian.cn/tags/ambari/"/>
    
      <category term="flume" scheme="https://www.hnbian.cn/tags/flume/"/>
    
  </entry>
  
  <entry>
    <title>Spark Submit 提交任务抛出 IllegalAccessError</title>
    <link href="https://www.hnbian.cn/posts/f5835112.html"/>
    <id>https://www.hnbian.cn/posts/f5835112.html</id>
    <published>2022-05-15T10:20:42.000Z</published>
    <updated>2023-03-14T15:24:21.131Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-运行环境"><a href="#1-运行环境" class="headerlink" title="1. 运行环境"></a>1. 运行环境</h2><table><thead><tr><th>组件</th><th>版本</th></tr></thead><tbody><tr><td>Ambari</td><td>2.7.6</td></tr><tr><td>Spark</td><td>2.3.2</td></tr><tr><td>HDFS</td><td>3.1.1</td></tr></tbody></table><h2 id="2-提交任务报错信息如下："><a href="#2-提交任务报错信息如下：" class="headerlink" title="2. 提交任务报错信息如下："></a>2. 提交任务报错信息如下：</h2><ul><li>使用 spark-submit 提交任务时报错信息</li></ul><pre class=" language-bash"><code class="language-bash">java.lang.IllegalAccessError: class org.apache.hadoop.hdfs.web.HftpFileSystem cannot access its superinterface org.apache.hadoop.hdfs.web.TokenAspect<span class="token variable">$TokenManagementDelegator</span></code></pre><h2 id="3-解决办法"><a href="#3-解决办法" class="headerlink" title="3. 解决办法"></a>3. 解决办法</h2><p>在IDEA中导出jar包之前，</p><p>File-&gt;Project Structure-&gt;Artifacts-&gt;xxx.jar-&gt;Output Layout</p><p>将hadoop-hdfs-x.x.x.jar这个文件去除即可</p><p>或在pom.xml 中配置，打包时去除相应的依赖</p><pre class=" language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">"</span></span>         <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>         <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">></span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.example<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>myTest<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0-SNAPSHOT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>hadoop.version</span><span class="token punctuation">></span></span>3.2.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>hadoop.version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-core_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0-preview2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 要排除的依赖 --></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-hdfs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>${hadoop.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-hdfs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>${hadoop.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>${hadoop.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">></span></span></code></pre><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-运行环境&quot;&gt;&lt;a href=&quot;#1-运行环境&quot; class=&quot;headerlink&quot; title=&quot;1. 运行环境&quot;&gt;&lt;/a&gt;1. 运行环境&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;组件&lt;/th&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;/tr&gt;
&lt;/th
      
    
    </summary>
    
    
      <category term="spark" scheme="https://www.hnbian.cn/categories/spark/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="spark" scheme="https://www.hnbian.cn/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>编译GreenPlum源码时遇见的问题及解决方式</title>
    <link href="https://www.hnbian.cn/posts/5a60f667.html"/>
    <id>https://www.hnbian.cn/posts/5a60f667.html</id>
    <published>2022-03-08T09:49:34.000Z</published>
    <updated>2023-03-14T15:24:21.123Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间编译了 greenplum 源码， 过程中遇到了一些问题， 在这里进行一下记录， 希望能够帮助遇见相同问题的小伙伴更快的解决问题。</p><h2 id="Could-not-fetch-URL-https-pypi-python-org-simple-conan"><a href="#Could-not-fetch-URL-https-pypi-python-org-simple-conan" class="headerlink" title="Could not fetch URL https://pypi.python.org/simple/conan/:"></a>Could not fetch URL <a href="https://pypi.python.org/simple/conan/" target="_blank" rel="noopener">https://pypi.python.org/simple/conan/</a>:</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">Could not fetch URL https://pypi.python.org/simple/conan/: There was a problem confirming the ssl certificate: <span class="token punctuation">[</span>SSL: CERTIFICATE_VERIFY_FAILED<span class="token punctuation">]</span> certificate verify failed <span class="token punctuation">(</span>_ssl.c:765<span class="token punctuation">)</span> - skipping</code></pre><ul><li>解决方式</li></ul><p>可以执行如下命令：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 解决 1 </span>pip <span class="token function">install</span> --trusted-host pypi.org --trusted-host files.pythonhosted.org tools<span class="token comment" spellcheck="true"># tools 为你要安装的工具</span>pip <span class="token function">install</span> --trusted-host pypi.org --trusted-host files.pythonhosted.org --upgrade pip<span class="token comment" spellcheck="true"># 如果以上都不解决问题，可是使用 -i 参数指定国内的镜像来进行安装</span>pip <span class="token function">install</span> -i https://pypi.tuna.tsinghua.edu.cn/simple psutil</code></pre><ul><li>如果没有pip，在上面解决问题时会报如下错误：</li></ul><pre><code>Could not fetch URL https://pypi.python.org/simple/pip/: There was a problem confirming the ssl certificate: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:765) - skipping  Could not find a version that satisfies the requirement pip (from versions: )No matching distribution found for pip</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 使用 yum 安装 pip</span><span class="token function">sudo</span> yum -y <span class="token function">install</span> epel-release<span class="token function">sudo</span> yum -y <span class="token function">install</span> python-pip<span class="token comment" spellcheck="true"># 2. 使用 python 安装 pip</span>python get-pip.py --trusted-host pypi.org --trusted-host</code></pre><h2 id="library-‘xslt’-is-required-for-XSLT-support"><a href="#library-‘xslt’-is-required-for-XSLT-support" class="headerlink" title="library ‘xslt’ is required for XSLT support"></a>library ‘xslt’ is required for XSLT support</h2><ul><li>错误信息</li></ul><pre><code>checking for xsltCleanupGlobals in -lxslt... noconfigure: error: library &#39;xslt&#39; is required for XSLT support</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> libxslt libxslt-devel</code></pre><h2 id="could-not-read-symbols-Invalid-operation"><a href="#could-not-read-symbols-Invalid-operation" class="headerlink" title="could not read symbols: Invalid operation"></a>could not read symbols: Invalid operation</h2><pre class=" language-bash"><code class="language-bash">/bin/ld: libpq/SUBSYS.o: undefined reference to symbol <span class="token string">'gss_delete_sec_context@@gssapi_krb5_2_MIT'</span>/bin/ld: note: <span class="token string">'gss_delete_sec_context@@gssapi_krb5_2_MIT'</span> is defined <span class="token keyword">in</span> DSO /lib64/libgssapi_krb5.so.2 so try adding it to the linker <span class="token function">command</span> line/lib64/libgssapi_krb5.so.2: could not <span class="token function">read</span> symbols: Invalid operationcollect2: error: ld returned 1 <span class="token keyword">exit</span> statusmake<span class="token punctuation">[</span>2<span class="token punctuation">]</span>: *** <span class="token punctuation">[</span>postgres<span class="token punctuation">]</span> Error 1make<span class="token punctuation">[</span>2<span class="token punctuation">]</span>: Leaving directory `/home/greenplum/src/backend<span class="token string">'make[1]: *** [all] Error 2make[1]: Leaving directory `/home/greenplum/src'</span>make: *** <span class="token punctuation">[</span>all<span class="token punctuation">]</span> Error 2</code></pre><ul><li>解决方式</li></ul><p>由于我们使用的是CentOS系统, 所以一定要加上/usr/local/lib和/usr/local/lib64的路径到/etc/ld.so.conf文件中，这一步尤为重要，目的是将常用的动态函数库加载到内存中，可以提高函数库的访问效率。另外，如果不配置这一步，在后面编译的过程中会遇到一些奇奇怪怪的缺少引用的错误</p><p>修改后的文件内容类似如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">cat</span> /etc/ld.so.confinclude ld.so.conf.d/*.conf/usr/local/lib/usr/local/lib64<span class="token comment" spellcheck="true"># 修改完成后，运行 ldconfig 命令</span></code></pre><h2 id="could-not-determine-flags-for-linking-embedded-Perl"><a href="#could-not-determine-flags-for-linking-embedded-Perl" class="headerlink" title="could not determine flags for linking embedded Perl"></a>could not determine flags for linking embedded Perl</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> flags to <span class="token function">link</span> embedded Perl<span class="token punctuation">..</span>. Can't <span class="token function">locate</span> ExtUtils/Embed.pm <span class="token keyword">in</span> @INC <span class="token punctuation">(</span>@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .<span class="token punctuation">)</span>.BEGIN failed--compilation aborted.noconfigure: error: could not determine flags <span class="token keyword">for</span> linking embedded Perl.This probably means that ExtUtils::Embed or ExtUtils::MakeMaker is not installed.</code></pre><ul><li>解决办法</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> perl-ExtUtils-Embed -y</code></pre><h2 id="library-‘xml2’-version-gt-2-6-23-is-required-for-XML-support"><a href="#library-‘xml2’-version-gt-2-6-23-is-required-for-XML-support" class="headerlink" title="library ‘xml2’ (version &gt;= 2.6.23) is required for XML support"></a>library ‘xml2’ (version &gt;= 2.6.23) is required for XML support</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> xmlSaveToBuffer <span class="token keyword">in</span> -lxml2<span class="token punctuation">..</span>. noconfigure: error: library <span class="token string">'xml2'</span> <span class="token punctuation">(</span>version <span class="token operator">>=</span> 2.6.23<span class="token punctuation">)</span> is required <span class="token keyword">for</span> XML support</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> libxml2 libxml2-devel -y</code></pre><h2 id="Your-ORCA-version-is-expected-to-be-2-51-XXX"><a href="#Your-ORCA-version-is-expected-to-be-2-51-XXX" class="headerlink" title="Your ORCA version is expected to be 2.51.XXX"></a>Your ORCA version is expected to be 2.51.XXX</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking Checking ORCA version<span class="token punctuation">..</span>. configure: error: Your ORCA version is expected to be 2.51.XXX</code></pre><ul><li>解决方式</li></ul><p>这说明你装的orca的版本是不匹配的，需要安装匹配版本，那么如何在安装前知道需要什么版本，</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 执行如下命令：</span><span class="token function">cd</span> /home/gpdb_src/depends<span class="token function">cat</span> conanfile_orca.txt<span class="token comment" spellcheck="true">#这里在文件中可以看到如下记录：</span><span class="token punctuation">[</span>requires<span class="token punctuation">]</span>orca/v2.51.0@gpdb/stable</code></pre><p>到github上找到对应版本下载安装即可。</p><p>当需要更换版本时，需要清理掉之前已经安装的版本。默认情况下安装在<code>/usr/local/</code>目录下，根据安装的路径</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 执行如下命令删除已经安装的版本</span><span class="token function">rm</span> -rf build/*<span class="token function">rm</span> -rf /usr/local/include/naucrates<span class="token function">rm</span> -rf /usr/local/include/gpdbcost<span class="token function">rm</span> -rf /usr/local/include/gpopt<span class="token function">rm</span> -rf /usr/local/include/gpos<span class="token function">rm</span> -rf /usr/local/lib/libnaucrates.so*<span class="token function">rm</span> -rf /usr/local/lib/libgpdbcost.so*<span class="token function">rm</span> -rf /usr/local/lib/libgpopt.so*<span class="token function">rm</span> -rf /usr/local/lib/libgpos.so*</code></pre><p><strong>注意：</strong></p><p>1、build位于gporca编译目录，其是编译时cmake产生的一些文件</p><p>2、如果重新安装了版本一定要执行ldconfig命令，否则新的版本不会在缓存中更新，会一直报上述错误</p><h2 id="command-‘gcc’-failed-with-exit-status-1"><a href="#command-‘gcc’-failed-with-exit-status-1" class="headerlink" title="command ‘gcc’ failed with exit status 1"></a>command ‘gcc’ failed with exit status 1</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">unable to execute gcc: No such <span class="token function">file</span> or directory    error: <span class="token function">command</span> <span class="token string">'gcc'</span> failed with <span class="token keyword">exit</span> status 1    ----------------------------------------Command <span class="token string">"/usr/bin/python2 -u -c "</span><span class="token function">import</span> setuptools, tokenize<span class="token punctuation">;</span>__file__<span class="token operator">=</span><span class="token string">'/tmp/pip-build-4lu7Y0/psutil/setup.py'</span><span class="token punctuation">;</span>f<span class="token operator">=</span>getattr<span class="token punctuation">(</span>tokenize, <span class="token string">'open'</span>, open<span class="token punctuation">)</span><span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">;</span>code<span class="token operator">=</span>f.read<span class="token punctuation">(</span><span class="token punctuation">)</span>.replace<span class="token punctuation">(</span><span class="token string">'\r\n'</span>, <span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>f.close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>exec<span class="token punctuation">(</span>compile<span class="token punctuation">(</span>code, __file__, <span class="token string">'exec'</span><span class="token punctuation">))</span><span class="token string">" install --record /tmp/pip-YPgXFP-record/install-record.txt --single-version-externally-managed --compile"</span> failed with error code 1 <span class="token keyword">in</span> /tmp/pip-build-4lu7Y0/psutil/</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y gcc</code></pre><h2 id="could-not-find-function-‘gss-init-sec-context’-required-for-GSSAPI"><a href="#could-not-find-function-‘gss-init-sec-context’-required-for-GSSAPI" class="headerlink" title="could not find function ‘gss_init_sec_context’ required for GSSAPI"></a>could not find function ‘gss_init_sec_context’ required for GSSAPI</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> library containing gss_init_sec_context<span class="token punctuation">..</span>. noconfigure: error: could not <span class="token function">find</span> <span class="token keyword">function</span> <span class="token string">'gss_init_sec_context'</span> required <span class="token keyword">for</span> GSSAPI<span class="token comment" spellcheck="true"># 如果使用编译参数：--with-gssapi可能会报该错误信息</span></code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 安装gssapi</span>pip <span class="token function">install</span> gssapi</code></pre><ul><li>安装 gssapi 可能报如下错误：</li></ul><pre class=" language-bash"><code class="language-bash">Complete output from <span class="token function">command</span> python setup.py egg_info:    In distributed package, building from C files<span class="token punctuation">..</span>.    Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:      File <span class="token string">"&lt;string>"</span>, line 1, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>      File <span class="token string">"/tmp/pip-build-CHeKis/gssapi/setup.py"</span>, line 98, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>        raise Exception<span class="token punctuation">(</span><span class="token string">"Could not find main GSSAPI shared library.  Please "</span>    Exception: Could not <span class="token function">find</span> main GSSAPI shared library.  Please try setting GSSAPI_MAIN_LIB yourself or setting ENABLE_SUPPORT_DETECTION to <span class="token string">'false'</span>    ----------------------------------------Command <span class="token string">"python setup.py egg_info"</span> failed with error code 1 <span class="token keyword">in</span> /tmp/pip-build-CHeKis/gssapi/</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y krb5-devel.x86_64</code></pre><h2 id="apr-1-config-is-required-for-gpfdist-unable-to-find-binary"><a href="#apr-1-config-is-required-for-gpfdist-unable-to-find-binary" class="headerlink" title="apr-1-config is required for gpfdist, unable to find binary"></a>apr-1-config is required for gpfdist, unable to find binary</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> apr-1-config<span class="token punctuation">..</span>. noconfigure: error: apr-1-config is required <span class="token keyword">for</span> gpfdist, unable to <span class="token function">find</span> binary</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y apr-devel</code></pre><h2 id="libevent-is-required-for-gpfdist"><a href="#libevent-is-required-for-gpfdist" class="headerlink" title="libevent is required for gpfdist"></a>libevent is required for gpfdist</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> library containing event_add<span class="token punctuation">..</span>. noconfigure: error: libevent is required <span class="token keyword">for</span> gpfdist</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y libevent-devel</code></pre><h2 id="Library-requirements-curl-not-met"><a href="#Library-requirements-curl-not-met" class="headerlink" title="Library requirements (curl) not met."></a>Library requirements (curl) not met.</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> curl-config<span class="token punctuation">..</span>. no*** The curl-config script could not be found. Make sure it is*** <span class="token keyword">in</span> your path, and that curl is properly installed.*** Or see http://curl.haxx.se/configure: error: Library requirements <span class="token punctuation">(</span>curl<span class="token punctuation">)</span> not met.</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y libcurl-devel.x86_64</code></pre><h2 id="header-file-lt-bzlib-h-gt-is-required-for-bzip2-support"><a href="#header-file-lt-bzlib-h-gt-is-required-for-bzip2-support" class="headerlink" title="header file &lt;bzlib.h&gt; is required for bzip2 support"></a>header file &lt;bzlib.h&gt; is required for bzip2 support</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> bzlib.h<span class="token punctuation">..</span>. noconfigure: error: header <span class="token function">file</span> <span class="token operator">&lt;</span>bzlib.h<span class="token operator">></span> is required <span class="token keyword">for</span> <span class="token function">bzip2</span> support</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y bzip2-devel</code></pre><h2 id="psutil-psutil-common-c-9-20-fatal-error-Python-h-No-such-file-or-directory"><a href="#psutil-psutil-common-c-9-20-fatal-error-Python-h-No-such-file-or-directory" class="headerlink" title="psutil/_psutil_common.c:9:20: fatal error: Python.h: No such file or directory"></a>psutil/_psutil_common.c:9:20: fatal error: Python.h: No such file or directory</h2><ul><li>安装psutil时可能报如下错误：</li></ul><pre class=" language-bash"><code class="language-bash">psutil/_psutil_common.c:9:20: fatal error: Python.h: No such <span class="token function">file</span> or directory     <span class="token comment" spellcheck="true">#include &lt;Python.h></span>                        ^    compilation terminated.    error: <span class="token function">command</span> <span class="token string">'gcc'</span> failed with <span class="token keyword">exit</span> status 1    ----------------------------------------Command <span class="token string">"/usr/bin/python2 -u -c "</span><span class="token function">import</span> setuptools, tokenize<span class="token punctuation">;</span>__file__<span class="token operator">=</span><span class="token string">'/tmp/pip-build-3gzCd8/psutil/setup.py'</span><span class="token punctuation">;</span>exec<span class="token punctuation">(</span>compile<span class="token punctuation">(</span>getattr<span class="token punctuation">(</span>tokenize, <span class="token string">'open'</span>, open<span class="token punctuation">)</span><span class="token punctuation">(</span>__file__<span class="token punctuation">)</span>.read<span class="token punctuation">(</span><span class="token punctuation">)</span>.replace<span class="token punctuation">(</span><span class="token string">'\r\n'</span>, <span class="token string">'\n'</span><span class="token punctuation">)</span>, __file__, <span class="token string">'exec'</span><span class="token punctuation">))</span><span class="token string">" install --record /tmp/pip-EAY9ck-record/install-record.txt --single-version-externally-managed --compile"</span> failed with error code 1 <span class="token keyword">in</span> /tmp/pip-build-3gzCd8/psutil/</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y python-devel.x86_64</code></pre><h2 id="Error-256-while-executing-cd-‘-home-gpdb-src-gpd"><a href="#Error-256-while-executing-cd-‘-home-gpdb-src-gpd" class="headerlink" title="Error 256 while executing cd ‘/home/gpdb_src/gpd . .  ."></a>Error 256 while executing cd ‘/home/gpdb_src/gpd . .  .</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">ERROR: orca/v3.21.0@gpdb/stable: Error <span class="token keyword">in</span> build<span class="token punctuation">(</span><span class="token punctuation">)</span> method, line 48        cmake.configure<span class="token punctuation">(</span>defs<span class="token operator">=</span>cmake_defines<span class="token punctuation">)</span>        ConanException: Error 256 <span class="token keyword">while</span> executing <span class="token function">cd</span> <span class="token string">'/home/gpdb_src/gpdb-5.16.0/depends/.conan/data/orca/v3.21.0/gpdb/stable/build/4f7d6d5032b1a188f98e0c149ef6bf91e76af63e'</span> <span class="token operator">&amp;&amp;</span> cmake -G <span class="token string">"Unix Makefiles"</span> -DCMAKE_BUILD_TYPE<span class="token operator">=</span><span class="token string">"Release"</span> -DCONAN_EXPORTED<span class="token operator">=</span><span class="token string">"1"</span> -DCONAN_IN_LOCAL_CACHE<span class="token operator">=</span><span class="token string">"ON"</span> -DCONAN_COMPILER<span class="token operator">=</span><span class="token string">"gcc"</span> -DCONAN_COMPILER_VERSION<span class="token operator">=</span><span class="token string">"4.8"</span> -DCONAN_CXX_FLAGS<span class="token operator">=</span><span class="token string">"-m64"</span> -DCONAN_SHARED_LINKER_FLAGS<span class="token operator">=</span><span class="token string">"-m64"</span> -DCONAN_C_FLAGS<span class="token operator">=</span><span class="token string">"-m64"</span> -DCONAN_LIBCXX<span class="token operator">=</span><span class="token string">"libstdc++"</span> -DBUILD_SHARED_LIBS<span class="token operator">=</span><span class="token string">"ON"</span> -DCMAKE_INSTALL_PREFIX<span class="token operator">=</span><span class="token string">"/home/gpdb_src/gpdb-5.16.0/depends/.conan/data/orca/v3.21.0/gpdb/stable/package/4f7d6d5032b1a188f98e0c149ef6bf91e76af63e"</span> -DCMAKE_INSTALL_BINDIR<span class="token operator">=</span><span class="token string">"bin"</span> -DCMAKE_INSTALL_SBINDIR<span class="token operator">=</span><span class="token string">"bin"</span> -DCMAKE_INSTALL_LIBEXECDIR<span class="token operator">=</span><span class="token string">"bin"</span> -DCMAKE_INSTALL_LIBDIR<span class="token operator">=</span><span class="token string">"lib"</span> -DCMAKE_INSTALL_INCLUDEDIR<span class="token operator">=</span><span class="token string">"include"</span> -DCMAKE_INSTALL_OLDINCLUDEDIR<span class="token operator">=</span><span class="token string">"include"</span> -DCMAKE_INSTALL_DATAROOTDIR<span class="token operator">=</span><span class="token string">"share"</span> -DCMAKE_EXPORT_NO_PACKAGE_REGISTRY<span class="token operator">=</span><span class="token string">"ON"</span> -Wno-dev <span class="token string">'/home/gpdb_src/gpdb-5.16.0/depends/.conan/data/orca/v3.21.0/gpdb/stable/build/4f7d6d5032b1a188f98e0c149ef6bf91e76af63e'</span>make: *** <span class="token punctuation">[</span>orca<span class="token punctuation">]</span> Error 1</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> gcc-c++</code></pre><h2 id="bison’-is-missing-on-your-system"><a href="#bison’-is-missing-on-your-system" class="headerlink" title="`bison’ is missing on your system."></a>`bison’ is missing on your system.</h2><ul><li>错误信息</li></ul><p>该问题可能出现在make阶段</p><pre class=" language-bash"><code class="language-bash">***ERROR: `bison<span class="token string">' is missing on your system. It is needed to create thefile `gram.c'</span><span class="token keyword">.</span> You can either get bison from a GNU mirror siteor download an official distribution of PostgreSQL, <span class="token function">which</span> containspre-packaged bison output.***make<span class="token punctuation">[</span>3<span class="token punctuation">]</span>: *** <span class="token punctuation">[</span>gram.c<span class="token punctuation">]</span> Error 1make<span class="token punctuation">[</span>3<span class="token punctuation">]</span>: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src/backend/parser<span class="token string">'make[2]: *** [parser/gram.h] Error 2make[2]: *** Waiting for unfinished jobs....AWK='</span><span class="token function">gawk</span><span class="token string">' /bin/sh Gen_fmgrtab.sh pg_proc_combined.h.tmpmake[3]: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src/backend/utils'</span>make<span class="token punctuation">[</span>2<span class="token punctuation">]</span>: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src/backend<span class="token string">'make[1]: *** [all] Error 2make[1]: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src'</span>make: *** <span class="token punctuation">[</span>all<span class="token punctuation">]</span> Error 2</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 同样的flex也可能出现类似问题，解决稍微麻烦一点</span>yum <span class="token function">install</span> -y bison.x86_64 bison-devel.x86_64<span class="token comment" spellcheck="true">#之后需要make clean，重新执行安装流程</span></code></pre><h2 id="openssl-hmac-h-No-such-file-or-directory"><a href="#openssl-hmac-h-No-such-file-or-directory" class="headerlink" title="openssl/hmac.h: No such file or directory"></a>openssl/hmac.h: No such file or directory</h2><ul><li>错误信息</li></ul><pre class=" language-bash"><code class="language-bash">In <span class="token function">file</span> included from include/reader.h:4:0,                 from include/gpreader.h:4,                 from src/gpreader.cpp:1:include/s3common_headers.h:8:26: fatal error: openssl/hmac.h: No such <span class="token function">file</span> or directory <span class="token comment" spellcheck="true">#include &lt;openssl/hmac.h></span>                          ^compilation terminated.</code></pre><ul><li>解决方式</li></ul><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y openssl-devel</code></pre><p>参考资料：</p><p><a href="https://www.cnblogs.com/qiannianyuan/p/greenplum_compile.html" target="_blank" rel="noopener">https://www.cnblogs.com/qiannianyuan/p/greenplum_compile.html</a></p><p><a href="https://github.com/greenplum-db/gpdb/tree/5.16.0" target="_blank" rel="noopener">https://github.com/greenplum-db/gpdb/tree/5.16.0</a></p><p><a href="http://blog.csdn.net/luojinbai/article/details/44217551" target="_blank" rel="noopener">http://blog.csdn.net/luojinbai/article/details/44217551</a></p><p><a href="https://www.cnblogs.com/codeblock/p/4730122.html" target="_blank" rel="noopener">https://www.cnblogs.com/codeblock/p/4730122.html</a></p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前段时间编译了 greenplum 源码， 过程中遇到了一些问题， 在这里进行一下记录， 希望能够帮助遇见相同问题的小伙伴更快的解决问题。&lt;/p&gt;
&lt;h2 id=&quot;Could-not-fetch-URL-https-pypi-python-org-simple-conan&quot;
      
    
    </summary>
    
    
      <category term="greenplum" scheme="https://www.hnbian.cn/categories/greenplum/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="greenplum" scheme="https://www.hnbian.cn/tags/greenplum/"/>
    
  </entry>
  
  <entry>
    <title>Spark 使用 Hive元数据遇到的一些问题</title>
    <link href="https://www.hnbian.cn/posts/579b89c7.html"/>
    <id>https://www.hnbian.cn/posts/579b89c7.html</id>
    <published>2022-02-27T03:25:18.000Z</published>
    <updated>2023-04-24T16:39:08.286Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Required-field-‘client-protocol’-is-unset"><a href="#Required-field-‘client-protocol’-is-unset" class="headerlink" title="Required field ‘client_protocol’ is unset!"></a>Required field ‘client_protocol’ is unset!</h2><pre class=" language-bash"><code class="language-bash">beeline 出现 org.apache.thrift.TApplicationException: Required field ‘client_protocol’ is unset<span class="token operator">!</span> Struct:TOpenSessionReq<span class="token punctuation">(</span>client_protocol:null,configuration:set:hiveconf:hive.server2.thrift.resultset.default.fetch.size<span class="token operator">=</span>1000,use:database<span class="token operator">=</span>default<span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre><table><thead><tr><th>原值</th><th>替换值</th></tr></thead><tbody><tr><td>hive/bin 下的 beeline</td><td>spark/bin 下的 beeline</td></tr></tbody></table><h2 id="spark-不使用hive的源数据表的问题"><a href="#spark-不使用hive的源数据表的问题" class="headerlink" title="spark 不使用hive的源数据表的问题"></a>spark 不使用hive的源数据表的问题</h2><p>对 spark2-hive-site-override 做修改</p><table><thead><tr><th>原值</th><th>替换值</th></tr></thead><tbody><tr><td>metastore.catalog.default=spark</td><td>metastore.catalog.default=hive</td></tr></tbody></table><h2 id="Table-is-marked-as-a-managed-table-but-is-not-transactional"><a href="#Table-is-marked-as-a-managed-table-but-is-not-transactional" class="headerlink" title="Table is marked as a managed table but is not transactional."></a>Table is marked as a managed table but is not transactional.</h2><pre class=" language-bash"><code class="language-bash">AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException<span class="token punctuation">(</span>message:Table default.partition_test failed strict managed table checks due to the following reason: Table is marked as a managed table but is not transactional.<span class="token punctuation">)</span></code></pre><p>对hive-site.xml做修改</p><table><thead><tr><th>原值</th><th>替换值</th></tr></thead><tbody><tr><td>hive.strict.managed.tables=true</td><td>hive.strict.managed.tables=false</td></tr></tbody></table><h2 id="file-is-not-owned-by-hive-and-load-data-is-also-not-ran-as-hive"><a href="#file-is-not-owned-by-hive-and-load-data-is-also-not-ran-as-hive" class="headerlink" title="file is not owned by hive and load data is also not ran as hive"></a>file is not owned by hive and load data is also not ran as hive</h2><pre class=" language-bash"><code class="language-bash">org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Load Data failed <span class="token keyword">for</span> hdfs://***:8020/warehouse/tablespace/managed/hive/***/.hive-staging_hive_2019-07-02_18-17-08_028_419193115114639265-1/-ext-10000/part-00000-1f0e8f19-6a12-448f-ba18-a2319711c0aa-c000 as the <span class="token function">file</span> is not owned by hive and load data is also not ran as hive<span class="token punctuation">;</span></code></pre><p>spark hive-site.xml 添加 hive.load.data.owner=spark (具体执行用户)</p><h2 id="AnalysisException-java-lang-NullPointerException-null"><a href="#AnalysisException-java-lang-NullPointerException-null" class="headerlink" title="AnalysisException: java.lang.NullPointerException: null"></a>AnalysisException: java.lang.NullPointerException: null</h2><pre class=" language-bash"><code class="language-bash">org.apache.spark.sql.AnalysisException: java.lang.NullPointerException: null<span class="token punctuation">;</span>at org.apache.spark.sql.hive.HiveExternalCatalog.withClient<span class="token punctuation">(</span>HiveExternalCatalog.scala:106<span class="token punctuation">)</span></code></pre><p>spark sql 不支持 hive 的 OrcInputFormat 格式</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Required-field-‘client-protocol’-is-unset&quot;&gt;&lt;a href=&quot;#Required-field-‘client-protocol’-is-unset&quot; class=&quot;headerlink&quot; title=&quot;Required f
      
    
    </summary>
    
    
      <category term="ambari" scheme="https://www.hnbian.cn/categories/ambari/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="ambari" scheme="https://www.hnbian.cn/tags/ambari/"/>
    
      <category term="spark" scheme="https://www.hnbian.cn/tags/spark/"/>
    
      <category term="hive" scheme="https://www.hnbian.cn/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>ARM 服务器编译部署 GreenPlum 6.9</title>
    <link href="https://www.hnbian.cn/posts/2b892042.html"/>
    <id>https://www.hnbian.cn/posts/2b892042.html</id>
    <published>2022-02-17T09:42:57.000Z</published>
    <updated>2022-06-22T16:03:39.631Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://greenplum.cn/2020/01/14/greenplum-htap/" target="_blank" rel="noopener">Greenplum</a>是一款全球领先的开源大数据平台，为全球各行各业提供具备实时处理、弹性扩容、弹性计算、混合负载、云原生和集成数据分析能力的强大的大数据引擎，目前广泛的应用于包括金融、保险、证券、通信、航空、物流、零售、媒体、政府、医疗、制造、能源等行业。</p><p>目前Greenplum的二进制发行版本只能运行在X86服务器。无论是Greenplum的官方开发商Pivotal公司，还是其他Greenplum发行商，都没有提供Greenplum的ARM发行版。不过，Greenplum是开源软件，我们可以通过编译Greenplum源代码自行构建Greenplum的ARM版本。</p><p>本文将详细讲述如何在ARM服务器上编译并运行开源版<a href="https://github.com/greenplum-db/gpdb" target="_blank" rel="noopener">Greenplum</a>。</p><h2 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h2><h3 id="1-1-arm内核配置yum源"><a href="#1-1-arm内核配置yum源" class="headerlink" title="1.1 arm内核配置yum源"></a>1.1 arm内核配置yum源</h3><p>到目录 /etc/yum.repos.d ，创建/替换下面文件</p><ul><li>CentOS-Base.repo</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localhost yum.repos.d<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cat CentOS-Base.repo</span><span class="token comment" spellcheck="true"># CentOS-Base.repo</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true"># The mirror system uses the connecting IP address of the client and the</span><span class="token comment" spellcheck="true"># update status of each mirror to pick mirrors that are updated to and</span><span class="token comment" spellcheck="true"># geographically close to the client.  You should use this for CentOS updates</span><span class="token comment" spellcheck="true"># unless you are manually picking other mirrors.</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true"># If the mirrorlist= does not work for you, as a fall back you can try the</span><span class="token comment" spellcheck="true"># remarked out baseurl= line instead.</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true">#</span><span class="token punctuation">[</span>base<span class="token punctuation">]</span>name<span class="token operator">=</span>CentOS-<span class="token variable">$releasever</span> - Base<span class="token comment" spellcheck="true">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os</span><span class="token comment" spellcheck="true">#baseurl=http://mirrors.ustc.edu.cn/centos-altarch/$releasever/os/$basearch/</span>baseurl<span class="token operator">=</span>http://mirrors.ustc.edu.cn/centos-altarch/7/os/<span class="token variable">$basearch</span>/gpgcheck<span class="token operator">=</span>0enabled<span class="token operator">=</span>1gpgkey<span class="token operator">=</span>file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7<span class="token comment" spellcheck="true">#       file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-AltArch-Arm32</span><span class="token comment" spellcheck="true">#released updates</span><span class="token punctuation">[</span>updates<span class="token punctuation">]</span>name<span class="token operator">=</span>CentOS-<span class="token variable">$releasever</span> - Updates<span class="token comment" spellcheck="true"># mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates</span><span class="token comment" spellcheck="true">#baseurl=http://mirrors.ustc.edu.cn/centos-altarch/$releasever/updates/$basearch/</span>baseurl<span class="token operator">=</span>http://mirrors.ustc.edu.cn/centos-altarch/7/updates/<span class="token variable">$basearch</span>/gpgcheck<span class="token operator">=</span>0enabled<span class="token operator">=</span>1gpgkey<span class="token operator">=</span>file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7<span class="token comment" spellcheck="true">#       file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-AltArch-Arm32</span><span class="token comment" spellcheck="true">#additional packages that may be useful</span><span class="token punctuation">[</span>extras<span class="token punctuation">]</span>name<span class="token operator">=</span>CentOS-<span class="token variable">$releasever</span> - Extras<span class="token comment" spellcheck="true"># mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras</span><span class="token comment" spellcheck="true">#baseurl=http://mirrors.ustc.edu.cn/centos-altarch/$releasever/extras/$basearch/</span>baseurl<span class="token operator">=</span>http://mirrors.ustc.edu.cn/centos-altarch/7/extras/<span class="token variable">$basearch</span>/gpgcheck<span class="token operator">=</span>0enabled<span class="token operator">=</span>1gpgkey<span class="token operator">=</span>file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7<span class="token comment" spellcheck="true">#       file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-AltArch-Arm32</span><span class="token comment" spellcheck="true">#additional packages that extend functionality of existing packages</span><span class="token punctuation">[</span>centosplus<span class="token punctuation">]</span>name<span class="token operator">=</span>CentOS-<span class="token variable">$releasever</span> - Plus<span class="token comment" spellcheck="true"># mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplus</span><span class="token comment" spellcheck="true">#baseurl=http://mirrors.ustc.edu.cn/centos-altarch/$releasever/centosplus/$basearch/</span>baseurl<span class="token operator">=</span>http://mirrors.ustc.edu.cn/centos-altarch/7/centosplus/<span class="token variable">$basearch</span>/gpgcheck<span class="token operator">=</span>0enabled<span class="token operator">=</span>0gpgkey<span class="token operator">=</span>file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7<span class="token comment" spellcheck="true"># file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-AltArch-Arm32</span></code></pre><ul><li>清空/重建yum 缓存</li></ul><pre class=" language-bash"><code class="language-bash">yum clean allyum makecache</code></pre><h3 id="1-2-关闭防火墙"><a href="#1-2-关闭防火墙" class="headerlink" title="1.2 关闭防火墙"></a>1.2 关闭防火墙</h3><pre class=" language-bash"><code class="language-bash">systemctl stop firewalldsystemctl disable firewalld</code></pre><h3 id="1-3-设置用户使用资源"><a href="#1-3-设置用户使用资源" class="headerlink" title="1.3 设置用户使用资源"></a>1.3 设置用户使用资源</h3><pre class=" language-bash"><code class="language-bash">vim /etc/security/limits.conf<span class="token comment" spellcheck="true"># 可打开的文件描述符的最大数,超过会警告(软限制)</span>* soft nofile 524288<span class="token comment" spellcheck="true"># 可打开的文件描述符的最大数,超过会报错(硬限制)</span>* hard nofile 524288<span class="token comment" spellcheck="true"># 单个用户可用的最大进程数量,超过会警告(软限制)</span>* soft nproc 131072<span class="token comment" spellcheck="true"># 单个用户可用的最大进程数量,超过会报错(硬限制)</span>* hard nproc 131072</code></pre><h3 id="1-4-关闭SELinux"><a href="#1-4-关闭SELinux" class="headerlink" title="1.4 关闭SELinux"></a>1.4 关闭SELinux</h3><pre class=" language-bash"><code class="language-bash">vim /etc/selinux/config<span class="token comment" spellcheck="true"># This file controls the state of SELinux on the system.</span><span class="token comment" spellcheck="true"># SELINUX= can take one of these three values:</span><span class="token comment" spellcheck="true">#     enforcing - SELinux security policy is enforced.</span><span class="token comment" spellcheck="true">#     permissive - SELinux prints warnings instead of enforcing.</span><span class="token comment" spellcheck="true">#     disabled - No SELinux policy is loaded.</span>SELINUX<span class="token operator">=</span>disabled<span class="token comment" spellcheck="true"># SELINUXTYPE= can take one of these two values:</span><span class="token comment" spellcheck="true">#     targeted - Targeted processes are protected,</span><span class="token comment" spellcheck="true">#     mls - Multi Level Security protection.</span>SELINUXTYPE<span class="token operator">=</span>targeted<span class="token comment" spellcheck="true"># 查看 SELINUX 状态</span><span class="token punctuation">[</span>root@localhost ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sestatus</span>SELinux status:   disabled<span class="token comment" spellcheck="true"># 如果状态没有修改则需要重启服务器</span></code></pre><h3 id="1-5-修改内核参数"><a href="#1-5-修改内核参数" class="headerlink" title="1.5 修改内核参数"></a>1.5 修改内核参数</h3><pre class=" language-bash"><code class="language-bash">vim /etc/sysctl.conf<span class="token comment" spellcheck="true"># 新增参数</span><span class="token comment" spellcheck="true"># 用于设置系统范围内共享内存段的最大数量。该参数的默认值是 4096.</span>kernel.shmmni <span class="token operator">=</span> 4096<span class="token comment" spellcheck="true"># 系统任意时刻可以分配的所有共享内存段的总和的最大值(以页为单位)</span>kernel.shmall <span class="token operator">=</span> 4000000000<span class="token comment" spellcheck="true"># 表示设置的信号量</span>kernel.sem <span class="token operator">=</span> 250 512000 100 2048<span class="token comment" spellcheck="true"># 启用SsyRq</span>kernel.sysrq <span class="token operator">=</span> 1<span class="token comment" spellcheck="true"># 设置pid作为文件扩展名</span>kernel.core_uses_pid <span class="token operator">=</span> 1<span class="token comment" spellcheck="true"># 每个消息队列的最大字节限制</span>kernel.msgmnb <span class="token operator">=</span> 65536<span class="token comment" spellcheck="true"># 单个消息的最大size</span>kernel.msgmax <span class="token operator">=</span> 65536<span class="token comment" spellcheck="true"># 整个系统的最大数量的消息队列。</span>kernel.msgmni <span class="token operator">=</span> 2048<span class="token comment" spellcheck="true"># 开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。</span>net.ipv4.tcp_tw_recycle <span class="token operator">=</span> 1<span class="token comment" spellcheck="true"># 定义了处于SYN_RECV的TCP最大连接数</span>net.ipv4.tcp_max_syn_backlog <span class="token operator">=</span> 4096<span class="token comment" spellcheck="true"># ARP响应有关</span>net.ipv4.conf.default.arp_filter <span class="token operator">=</span> 1<span class="token comment" spellcheck="true"># 增加客户端端口可用范围</span>net.ipv4.ip_local_port_range <span class="token operator">=</span> 1025 65535<span class="token comment" spellcheck="true"># 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。这个参数表示该队列的最大值。</span>net.core.netdev_max_backlog <span class="token operator">=</span> 10000<span class="token comment" spellcheck="true"># 接收缓冲区最大值</span>net.core.rmem_max <span class="token operator">=</span> 2097152<span class="token comment" spellcheck="true"># 发送缓冲区最大值</span>net.core.wmem_max <span class="token operator">=</span> 2097152<span class="token comment" spellcheck="true"># 表示内核允许分配超过所有物理内存和交换空间总和的内存。</span>vm.overcommit_memory <span class="token operator">=</span> 2<span class="token comment" spellcheck="true"># 原本参数</span>net.ipv4.tcp_syncookies <span class="token operator">=</span> 1net.ipv4.ip_forward <span class="token operator">=</span> 0<span class="token comment" spellcheck="true"># 重启或刷新配置</span>sysctl -p</code></pre><ul><li>遇见的问题</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localhost rpm<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum localinstall epel-release-latest-7.noarch.rpm</span>上次元数据过期检查：0:42:55 前，执行于 2022年02月15日 星期二 10时42分51秒。错误： 问题: conflicting requests 相互矛盾的请求  - nothing provides redhat-release <span class="token operator">>=</span> 7 needed by epel-release-7-14.noarch  没有提供 redhat-release   7 needed by epel-release-7-14.noarch<span class="token punctuation">(</span>try to add <span class="token string">'--skip-broken'</span> to skip uninstallable packages or <span class="token string">'--nobest'</span> to use not only best candidate packages<span class="token punctuation">)</span>尝试添加“--skip-broken”以跳过可卸载包   或“--nobest”以不仅使用最佳候选包</code></pre><h3 id="1-8-安装编译所需的工具及软件包"><a href="#1-8-安装编译所需的工具及软件包" class="headerlink" title="1.8 安装编译所需的工具及软件包"></a>1.8 安装编译所需的工具及软件包</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. epel-release</span>yum <span class="token function">install</span> https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm<span class="token comment" spellcheck="true"># 或使用下面命令强制安装 </span>rpm -ivh --force --nodeps https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm<span class="token comment" spellcheck="true"># 使用强制安装</span>rpm -ivh --force --nodeps epel-release-latest-7.noarch.rpmyum makecache<span class="token comment" spellcheck="true"># 2. 安装所需编译环境</span>yum groupinstall  <span class="token string">'Development Tools'</span> <span class="token comment" spellcheck="true"># GCC, libtools etc </span><span class="token comment" spellcheck="true"># 3. 安装所需编译环境</span>yum <span class="token function">install</span> curl-devel bzip2-devel python-devel openssl-devel readline-devel perl-ExtUtils-Embed libxml2-devel perl-devel zstd <span class="token function">git</span><span class="token comment" spellcheck="true"># 下面为安装明细与检查</span>yum <span class="token function">install</span> curl-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> python-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> openssl-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> readline-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> libdb-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> bzip2-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> perl-ExtUtils-Embed <span class="token comment" spellcheck="true"># ok </span>yum <span class="token function">install</span> libxml2-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> perl-devel <span class="token comment" spellcheck="true"># ok </span>yum <span class="token function">install</span> zstd <span class="token comment" spellcheck="true"># ok -</span>yum <span class="token function">install</span> <span class="token function">git</span> <span class="token comment" spellcheck="true"># ok </span>yum <span class="token function">install</span> epel-release <span class="token comment" spellcheck="true"># ok </span>yum <span class="token function">install</span> libzstd-devel <span class="token comment" spellcheck="true"># ok</span>yum <span class="token function">install</span> glibc-langpack-tr ok</code></pre><h3 id="1-9-安装python-组件"><a href="#1-9-安装python-组件" class="headerlink" title="1.9 安装python 组件"></a>1.9 安装python 组件</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 3. 下载文件</span><span class="token function">wget</span> https://bootstrap.pypa.io/pip/2.7/get-pip.py<span class="token comment" spellcheck="true"># 4. 使用 Python 安装 pip</span>python get-pip.py<span class="token comment" spellcheck="true"># 5. 使用 pip 安装插件</span>pip <span class="token function">install</span> psutil lockfile paramiko setuptools epydoc conan<span class="token comment" spellcheck="true"># 明细</span>pip <span class="token function">install</span> lockfilepip <span class="token function">install</span> paramikopip <span class="token function">install</span> setuptoolspip <span class="token function">install</span> epydocpip <span class="token function">install</span> conan<span class="token comment" spellcheck="true"># 安装Python组件明细</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>  默认  <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>configobj<span class="token operator">==</span>5.0.6configparser<span class="token operator">==</span>3.5.0b2mysqlclient<span class="token operator">==</span>1.3.12 <span class="token operator">==</span>》 删除pycairo<span class="token operator">==</span>1.19.1 <span class="token operator">==</span>》 删除PyGObject<span class="token operator">==</span>3.36.1python-xlib<span class="token operator">==</span>0.15rc1 <span class="token operator">==</span>》 删除pyxdg<span class="token operator">==</span>0.26six<span class="token operator">==</span>1.15.0<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  psutil  <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>pip          20.3.4psutil       5.9.0setuptools   44.1.1wheel        0.37.1<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  lockfile      <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>lockfile     0.12.2<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  paramiko      <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>bcrypt       3.1.7cffi         1.15.0cryptography 3.3.2enum34       1.1.10ipaddress    1.0.23paramiko     2.10.3pycparser    2.21PyNaCl       1.4.0<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  setuptools    <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>已装<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  epydoc        <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>epydoc       3.0.1<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  conan         <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>Package             Version------------------- -----------bottle              0.12.19certifi             2021.10.8chardet             4.0.0colorama            0.4.4conan               1.47.0contextlib2         0.6.0.post1distro              1.6.0fasteners           0.16.3idna                2.10importlib-resources 3.3.1Jinja2              2.11.3MarkupSafe          1.1.1monotonic           1.6node-semver         0.6.1patch-ng            1.17.4pathlib2            2.3.7.post1pluginbase          1.0.1Pygments            2.5.2PyJWT               1.7.1python-dateutil     2.8.2PyYAML              5.4.1requests            2.27.1scandir             1.10.0singledispatch      3.7.0tqdm                4.64.0typing              3.10.0.0urllib3             1.26.9zipp                1.2.0pip download -d your_offline_packages psutil<span class="token comment" spellcheck="true"># 离线下载安装包</span><span class="token comment" spellcheck="true"># 下载单个离线包 - </span>pip download -d your_offline_packages <span class="token operator">&lt;</span>package_name<span class="token operator">></span><span class="token comment" spellcheck="true"># 批量下载离线包 - </span>pip download -d your_offline_packages -r requirements.txt<span class="token comment" spellcheck="true"># 离线安装</span><span class="token comment" spellcheck="true"># 安装单个离线包 - </span>pip <span class="token function">install</span> --no-index --find-links<span class="token operator">=</span>/your_offline_packages/ package_name<span class="token comment" spellcheck="true"># 批量安装离线包 - </span>pip <span class="token function">install</span> --no-index --find-links<span class="token operator">=</span>/your_offline_packages/ -r requirements.txt</code></pre><h2 id="2-编译Greenplum源代码"><a href="#2-编译Greenplum源代码" class="headerlink" title="2. 编译Greenplum源代码"></a>2. 编译Greenplum源代码</h2><h3 id="2-1-创建-gpadmin-用户"><a href="#2-1-创建-gpadmin-用户" class="headerlink" title="2.1 创建 gpadmin 用户"></a>2.1 创建 gpadmin 用户</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 增加用户组</span><span class="token function">groupadd</span> -g 530 gpadmin<span class="token comment" spellcheck="true"># 增加用户</span><span class="token function">useradd</span> -g 530 -u 530 -m -d /home/gpadmin -s /bin/bash gpadmin<span class="token comment" spellcheck="true"># 对文件夹进行赋权</span><span class="token function">chown</span> -R gpadmin:gpadmin /home/gpadmin/<span class="token comment" spellcheck="true"># 为新用户创建密码</span><span class="token punctuation">[</span>root@localhost ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># passwd gpadmin</span>更改用户 gpadmin 的密码新的 密码： <span class="token punctuation">(</span>gpadmin<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#密码提示太简单，连续输入两次即可。</span>无效的密码： 密码少于 8 个字符重新输入新的 密码：passwd：所有的身份验证令牌已经成功更新</code></pre><h3 id="2-2-下载Greenplum源代码"><a href="#2-2-下载Greenplum源代码" class="headerlink" title="2.2 下载Greenplum源代码"></a>2.2 下载Greenplum源代码</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 切换用 gpadmin 用户</span><span class="token function">su</span> gpadmin<span class="token comment" spellcheck="true"># 下载源码</span><span class="token function">git</span> clone https://github.com/greenplum-db/gpdb<span class="token comment" spellcheck="true"># 进入 gpdb 目录</span><span class="token function">cd</span> gpdb<span class="token comment" spellcheck="true"># 切换版本</span><span class="token function">git</span> checkout 6.9</code></pre><h3 id="2-3-编译安装"><a href="#2-3-编译安装" class="headerlink" title="2.3 编译安装"></a>2.3 编译安装</h3><p>注意编译的时候使用的 Python2 版本, 但要是 2.2 之后的版本</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 编译</span>CFLAGS<span class="token operator">=</span><span class="token string">"-O0 -g3 -ggdb3"</span> \./configure --with-python --with-libxml --enable-debug --enable-cassert \--disable-orca --disable-gpcloud --disable-gpfdist \--disable-gpfdist<span class="token comment" spellcheck="true"># 打印日志</span>checking build system type<span class="token punctuation">..</span>. aarch64-unknown-linux-gnuchecking host system type<span class="token punctuation">..</span>. aarch64-unknown-linux-gnuchecking <span class="token function">which</span> template to use<span class="token punctuation">..</span>. linuxchecking whether to build with 64-bit integer date/time support<span class="token punctuation">..</span>. <span class="token function">yes</span>checking <span class="token keyword">for</span> default port number<span class="token punctuation">..</span>. 5432checking <span class="token keyword">for</span> block size<span class="token punctuation">..</span>. 32kBchecking <span class="token keyword">for</span> segment size<span class="token punctuation">..</span>. 1GBchecking <span class="token keyword">for</span> WAL block size<span class="token punctuation">..</span>. 32kB<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>config.status: linking src/backend/port/tas/dummy.s to src/backend/port/tas.sconfig.status: linking src/backend/port/dynloader/linux.c to src/backend/port/dynloader.cconfig.status: linking src/backend/port/sysv_sema.c to src/backend/port/pg_sema.cconfig.status: linking src/backend/port/sysv_shmem.c to src/backend/port/pg_shmem.cconfig.status: linking src/backend/port/unix_latch.c to src/backend/port/pg_latch.cconfig.status: linking src/backend/port/dynloader/linux.h to src/include/dynloader.hconfig.status: linking src/include/port/linux.h to src/include/pg_config_os.hconfig.status: linking src/makefiles/Makefile.linux to src/Makefile.port<span class="token comment" spellcheck="true"># 2. 编译</span><span class="token function">sudo</span> <span class="token function">make</span><span class="token comment" spellcheck="true"># 打印日志</span>make<span class="token punctuation">[</span>1<span class="token punctuation">]</span>: 进入目录“/home/gpadmin/gpdb/src”<span class="token function">make</span> -C common allmake<span class="token punctuation">[</span>2<span class="token punctuation">]</span>: 进入目录“/home/gpadmin/gpdb/src/common”<span class="token function">make</span> -C <span class="token punctuation">..</span>/backend submake-errcodesmake<span class="token punctuation">[</span>3<span class="token punctuation">]</span>: 进入目录“/home/gpadmin/gpdb/src/backend”<span class="token function">make</span> -C utils errcodes.hmake<span class="token punctuation">[</span>4<span class="token punctuation">]</span>: 进入目录“/home/gpadmin/gpdb/src/backend/utils”<span class="token string">'/usr/bin/perl'</span> ./generate-errcodes.pl <span class="token punctuation">..</span>/<span class="token punctuation">..</span>/<span class="token punctuation">..</span>/src/backend/utils/errcodes.txt <span class="token operator">></span> errcodes.hmake<span class="token punctuation">[</span>4<span class="token punctuation">]</span>: 离开目录“/home/gpadmin/gpdb/src/backend/utils”<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>n -fPIC -shared -o pxf.so src/pxfprotocol.o src/pxfbridge.o src/pxfuriparser.o src/libchurl.o src/pxfutils.o src/pxfheaders.o src/pxffragment.o src/gpdbwritableformatter.o src/pxffilters.o -L<span class="token punctuation">..</span>/<span class="token punctuation">..</span>/src/port -L<span class="token punctuation">..</span>/<span class="token punctuation">..</span>/src/common    -Wl,--as-needed -Wl,-rpath,<span class="token string">'/usr/local/gpdb/lib'</span>,--enable-new-dtags   -lcurlmake<span class="token punctuation">[</span>2<span class="token punctuation">]</span>: 离开目录“/home/gpadmin/gpdb/gpcontrib/pxf”make<span class="token punctuation">[</span>1<span class="token punctuation">]</span>: 离开目录“/home/gpadmin/gpdb/gpcontrib”All of Greenplum Database successfully made. Ready to install.<span class="token comment" spellcheck="true"># 3. 安装</span><span class="token function">sudo</span> <span class="token function">make</span> <span class="token function">install</span><span class="token comment" spellcheck="true"># 打印日志</span>/usr/bin/install -c -m 755  pxf.so <span class="token string">'/usr/local/gpdb/lib/postgresql/pxf.so'</span>/usr/bin/install -c -m 644 pxf.control <span class="token string">'/usr/local/gpdb/share/postgresql/extension/'</span>/usr/bin/install -c -m 644 pxf--1.0.sql <span class="token string">'/usr/local/gpdb/share/postgresql/extension/'</span>make<span class="token punctuation">[</span>2<span class="token punctuation">]</span>: 离开目录“/home/gpadmin/gpdb/gpcontrib/pxf”make<span class="token punctuation">[</span>1<span class="token punctuation">]</span>: 离开目录“/home/gpadmin/gpdb/gpcontrib”Greenplum Database installation complete.</code></pre><ul><li>问题 zstd library not found</li></ul><pre class=" language-bash"><code class="language-bash">configure: error: zstd library not foundIf you have libzstd already installed, see config.log <span class="token keyword">for</span> details on thefailure.  It is possible the compiler isn't looking <span class="token keyword">in</span> the proper directory.Use --without-zstd to disable zstd support.<span class="token comment" spellcheck="true"># 解决办法 -- </span>yum <span class="token function">install</span> epel-releaseyum <span class="token function">install</span> libzstd-devel<span class="token comment" spellcheck="true"># 这是安装时遇见的问题, 已经在前面增加了此软件的安装命令</span></code></pre><ul><li>问题 configure: error: libperl library is required for Perl</li></ul><pre class=" language-bash"><code class="language-bash">checking <span class="token keyword">for</span> libperl<span class="token punctuation">..</span>. noconfigure: error: libperl library is required <span class="token keyword">for</span> Perl<span class="token comment" spellcheck="true"># 解决</span><span class="token function">wget</span> https://rpmfind.net/linux/fedora/linux/development/rawhide/Everything/aarch64/os/Packages/p/perl-devel-5.34.0-485.fc36.aarch64.rpm<span class="token comment" spellcheck="true"># 下载源码</span><span class="token function">wget</span> https://vault.centos.org/8.5.2111/AppStream/Source/SPackages/perl-5.30.1-452.module_el8.4.0+646+45e06e4a.src.rpm<span class="token comment" spellcheck="true"># 编译源码</span>rpmbuild --rebuild --clean perl-5.30.1-452.module_el8.4.0+646+45e06e4a.src.rpm<span class="token comment" spellcheck="true"># 编译失败需要依赖</span>错误：构建依赖失败：    gdbm-devel 被 perl-4:5.30.1-452.ky10.ky10.aarch64 需要    glibc-langpack-tr 被 perl-4:5.30.1-452.ky10.ky10.aarch64 需要    libdb-devel 被 perl-4:5.30.1-452.ky10.ky10.aarch64 需要<span class="token comment" spellcheck="true"># 安装依赖 -- </span>yum <span class="token function">install</span> gdbm-devel <span class="token comment" spellcheck="true"># 安装失败</span>yum <span class="token function">install</span> glibc-langpack-tr <span class="token comment" spellcheck="true"># 找不到</span>yum <span class="token function">install</span> libdb-devel <span class="token comment" spellcheck="true"># 安装成功</span></code></pre><ul><li>问题  bison’ is missing on your system</li></ul><pre class=" language-bash"><code class="language-bash">***ERROR: `bison<span class="token string">' is missing on your system. It is needed to create thefile `gram.c'</span><span class="token keyword">.</span> You can either get bison from a GNU mirror siteor download an official distribution of PostgreSQL, <span class="token function">which</span> containspre-packaged bison output.***make<span class="token punctuation">[</span>3<span class="token punctuation">]</span>: *** <span class="token punctuation">[</span>gram.c<span class="token punctuation">]</span> Error 1make<span class="token punctuation">[</span>3<span class="token punctuation">]</span>: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src/backend/parser<span class="token string">'make[2]: *** [parser/gram.h] Error 2make[2]: *** Waiting for unfinished jobs....AWK='</span><span class="token function">gawk</span><span class="token string">' /bin/sh Gen_fmgrtab.sh pg_proc_combined.h.tmpmake[3]: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src/backend/utils'</span>make<span class="token punctuation">[</span>2<span class="token punctuation">]</span>: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src/backend<span class="token string">'make[1]: *** [all] Error 2make[1]: Leaving directory `/home/gpdb_src/gpdb-5.16.0/src'</span>make: *** <span class="token punctuation">[</span>all<span class="token punctuation">]</span> Error 2<span class="token comment" spellcheck="true"># 解决方式</span>yum <span class="token function">install</span> bison</code></pre><h2 id="3-配置-Greenplum"><a href="#3-配置-Greenplum" class="headerlink" title="3. 配置 Greenplum"></a>3. 配置 Greenplum</h2><h3 id="3-1-设置免密登录"><a href="#3-1-设置免密登录" class="headerlink" title="3.1 设置免密登录"></a>3.1 设置免密登录</h3><p>使用gpadmin登入，配置ssh免密码登录</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 生成秘钥</span><span class="token punctuation">[</span>root@localhost opt<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># su gpadmin</span><span class="token punctuation">[</span>gpadmin@localhost opt<span class="token punctuation">]</span>$ ssh-keygen -t rsaGenerating public/private rsa key pair.Enter <span class="token function">file</span> <span class="token keyword">in</span> <span class="token function">which</span> to save the key <span class="token punctuation">(</span>/home/gpadmin/.ssh/id_rsa<span class="token punctuation">)</span>: <span class="token comment" spellcheck="true">#(回车)</span>Enter passphrase <span class="token punctuation">(</span>empty <span class="token keyword">for</span> no passphrase<span class="token punctuation">)</span>:<span class="token comment" spellcheck="true">#(回车)</span>Enter same passphrase again:Your identification has been saved <span class="token keyword">in</span> /home/gpadmin/.ssh/id_rsa.Your public key has been saved <span class="token keyword">in</span> /home/gpadmin/.ssh/id_rsa.pub.The key fingerprint is:SHA256:TTr5ZrIMSa+VXwFJJiAoUPmYskWTR8DLiFpraX0+7dg gpadmin@localhostThe key's randomart image is:+---<span class="token punctuation">[</span>RSA 2048<span class="token punctuation">]</span>----+<span class="token operator">|</span>ooo*o <span class="token punctuation">..</span>. o      <span class="token operator">|</span><span class="token operator">|</span><span class="token keyword">.</span> B <span class="token punctuation">..</span>   + <span class="token keyword">.</span>     <span class="token operator">|</span><span class="token operator">|</span>.<span class="token operator">=</span> B      +      <span class="token operator">|</span><span class="token operator">|</span>+ B <span class="token keyword">.</span>    <span class="token operator">=</span> <span class="token keyword">.</span>     <span class="token operator">|</span><span class="token operator">|</span>.<span class="token operator">=</span> +  <span class="token keyword">.</span> S <span class="token keyword">.</span> <span class="token keyword">.</span>    <span class="token operator">|</span><span class="token operator">|</span>o <span class="token operator">=</span> <span class="token punctuation">..</span>.o +   <span class="token keyword">.</span>   <span class="token operator">|</span><span class="token operator">|</span> o   oo.<span class="token operator">=</span> + <span class="token keyword">.</span>    <span class="token operator">|</span><span class="token operator">|</span>      oB.* <span class="token keyword">.</span>     <span class="token operator">|</span><span class="token operator">|</span>      ooE <span class="token keyword">.</span>      <span class="token operator">|</span>+----<span class="token punctuation">[</span>SHA256<span class="token punctuation">]</span>-----+<span class="token punctuation">[</span>gpadmin@localhost opt<span class="token punctuation">]</span>$<span class="token punctuation">[</span>gpadmin@localhost opt<span class="token punctuation">]</span>$ <span class="token function">cd</span> ~<span class="token punctuation">[</span>gpadmin@localhost .ssh<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/home/gpadmin/.ssh<span class="token comment" spellcheck="true"># 配置 localhost 免密登录</span><span class="token punctuation">[</span>gpadmin@localhost .ssh<span class="token punctuation">]</span>$ ssh-copy-id localhostgpadmin@localhost password: <span class="token comment" spellcheck="true">#(输入gpadmin用户的密码)</span><span class="token punctuation">..</span>.<span class="token comment" spellcheck="true"># 尝试免密登录 localhost</span><span class="token punctuation">[</span>gpadmin@localhost .ssh<span class="token punctuation">]</span>$ <span class="token function">ssh</span> localhost <span class="token comment" spellcheck="true"># 退出登录</span><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token keyword">exit</span>登出Connection to localhost closed.</code></pre><h3 id="3-2-创建节点列表文件"><a href="#3-2-创建节点列表文件" class="headerlink" title="3.2 创建节点列表文件"></a>3.2 创建节点列表文件</h3><p>在管理节点配置</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>gpadmin@localhost .ssh<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> /home/gpadmin/conf<span class="token punctuation">[</span>gpadmin@localhost .ssh<span class="token punctuation">]</span>$<span class="token punctuation">[</span>gpadmin@localhost .ssh<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/gpadmin/conf<span class="token comment" spellcheck="true">#添加 GreenPlum 集群的所有节点</span><span class="token punctuation">[</span>gpadmin@localhost conf<span class="token punctuation">]</span>$ vim hostlist <span class="token punctuation">[</span>gpadmin@localhost conf<span class="token punctuation">]</span>$ <span class="token function">cat</span> hostlistlocalhost<span class="token comment" spellcheck="true">#添加 GreenPlum 集群的所有segment节点 </span><span class="token punctuation">[</span>gpadmin@localhost conf<span class="token punctuation">]</span>$ vim seg_hosts <span class="token punctuation">[</span>gpadmin@localhost conf<span class="token punctuation">]</span>$ <span class="token function">cat</span> seg_hostslocalhost</code></pre><h3 id="3-3-创建数据存储空间"><a href="#3-3-创建数据存储空间" class="headerlink" title="3.3 创建数据存储空间"></a>3.3 创建数据存储空间</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 在 Master 节点创建元数据目录</span><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> -p /home/gpadmin/data/master<span class="token comment" spellcheck="true"># 创建数据存储目录</span><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> -p /home/gpadmin/data/primary<span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> -p /home/gpadmin/data/mirror</code></pre><h3 id="3-4-配置-bash-profile-环境变量"><a href="#3-4-配置-bash-profile-环境变量" class="headerlink" title="3.4 配置 .bash_profile 环境变量"></a>3.4 配置 .bash_profile 环境变量</h3><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ vim /home/gpadmin/.bash_profile<span class="token comment" spellcheck="true"># 添加下面内容</span><span class="token function">source</span> /usr/local/gpdb/greenplum_path.sh <span class="token comment" spellcheck="true"># 这个路径对应安装 gp 的目录</span><span class="token function">export</span> MASTER_DATA_DIRECTORY<span class="token operator">=</span>/home/gpadmin/data/master/gpseg-1<span class="token function">export</span> PGPORT<span class="token operator">=</span>5432<span class="token function">export</span> PGUSER<span class="token operator">=</span>gpadmin<span class="token function">export</span> PGDATABASE<span class="token operator">=</span>Greenplum<span class="token comment" spellcheck="true"># 将刚刚配置的加到环境变量中</span>PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HOME</span>/.local/bin:<span class="token variable">$HOME</span>/bin:<span class="token variable">$MASTER_DATA_DIRECTORY</span><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">source</span> /home/gpadmin/.bash_profile<span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> <span class="token variable">$GPHOME</span>/usr/local/gpdb</code></pre><h3 id="3-5-初始化配置文件"><a href="#3-5-初始化配置文件" class="headerlink" title="3.5 初始化配置文件"></a>3.5 初始化配置文件</h3><p>配置文件模板为 <code>$GPHOME/docs/cli_help/gpconfigs/gpinitsystem_config</code></p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> /home/gpadmin/gpconfigs<span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/gpadmin/gpconfigs/<span class="token punctuation">[</span>gpadmin@localhost gpconfigs<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/home/gpadmin/gpconfigs<span class="token comment" spellcheck="true"># 创建 节点列表文件 hostfile_gpinitsystem</span><span class="token punctuation">[</span>gpadmin@localhost gpconfigs<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> localhost <span class="token operator">></span> hostfile_gpinitsystem<span class="token comment" spellcheck="true">#将segment节点名称添加到该文件内</span><span class="token punctuation">[</span>gpadmin@localhost gpconfigs<span class="token punctuation">]</span>$ <span class="token function">cat</span> /home/gpadmin/gpconfigs/hostfile_gpinitsystemlocalhost<span class="token comment" spellcheck="true"># 复制配置文件模板</span><span class="token punctuation">[</span>gpadmin@localhost gpconfigs<span class="token punctuation">]</span>$ <span class="token function">cp</span> <span class="token variable">$GPHOME</span>/docs/cli_help/gpconfigs/gpinitsystem_config <span class="token keyword">.</span><span class="token comment" spellcheck="true"># 修改配置</span><span class="token punctuation">[</span>gpadmin@localhost gpconfigs<span class="token punctuation">]</span>$ vim gpinitsystem_config<span class="token comment" spellcheck="true"># 修改以下配置</span><span class="token comment" spellcheck="true">#数据库代号</span>ARRAY_NAME<span class="token operator">=</span><span class="token string">"Greenplum"</span><span class="token comment" spellcheck="true">#segment前缀</span>SEG_PREFIX<span class="token operator">=</span>gpseg<span class="token comment" spellcheck="true">#primary segment 起始的端口号</span>PORT_BASE<span class="token operator">=</span>6000<span class="token comment" spellcheck="true">#指定primary segment的数据目录,网上写的是多个相同目录，多个目录表示一台机器有多个segment</span><span class="token keyword">declare</span> -a DATA_DIRECTORY<span class="token operator">=</span><span class="token punctuation">(</span>/home/gpadmin/data/primary<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#master所在机器的host name # 需要修改</span>MASTER_HOSTNAME<span class="token operator">=</span>localhost<span class="token comment" spellcheck="true">#master的数据目录 # 需要修改</span>MASTER_DIRECTORY<span class="token operator">=</span>/home/gpadmin/data/master<span class="token comment" spellcheck="true">#master的端口</span>MASTER_PORT<span class="token operator">=</span>5432<span class="token comment" spellcheck="true">#指定bash的版本</span>TRUSTED_SHELL<span class="token operator">=</span>/usr/bin/ssh<span class="token comment" spellcheck="true">#将日志写入磁盘的间隔，每个段文件通常 =16MB &lt; 2 * CHECK_POINT_SEGMENTS + 1</span>CHECK_POINT_SEGMENTS<span class="token operator">=</span>8<span class="token comment" spellcheck="true">#字符集</span>ENCODING<span class="token operator">=</span>UNICODE<span class="token comment" spellcheck="true">#mirror segment 起始的端口号</span>MIRROR_PORT_BASE<span class="token operator">=</span>7000<span class="token comment" spellcheck="true"># mirror的数据目录，和主数据一样，一个对一个，多个对多个</span><span class="token keyword">declare</span> -a MIRROR_DATA_DIRECTORY<span class="token operator">=</span><span class="token punctuation">(</span>/home/gpadmin/data/mirror<span class="token punctuation">)</span>DATABASE_NAME<span class="token operator">=</span>GreenplumMACHINE_LIST_FILE<span class="token operator">=</span>/home/gpadmin/gpconfigs/hostfile_gpinitsystem</code></pre><h2 id="4-Greenplum-初始化"><a href="#4-Greenplum-初始化" class="headerlink" title="4. Greenplum 初始化"></a>4. Greenplum 初始化</h2><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>gpadmin@localhost gpconfigs<span class="token punctuation">]</span>$ <span class="token function">cd</span> ~<span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/home/gpadmin<span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ <span class="token function">source</span> /usr/local/gpdb/greenplum_path.sh<span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ gpinitsystem -c gpconfigs/gpinitsystem_config -h gpconfigs/hostfile_gpinitsystem<span class="token punctuation">..</span>.Continue with Greenplum creation Yy<span class="token operator">|</span>Nn <span class="token punctuation">(</span>default<span class="token operator">=</span>N<span class="token punctuation">)</span>: <span class="token comment" spellcheck="true">#(y)</span><span class="token punctuation">..</span>.20200<span class="token punctuation">..</span>. gpstart:localhost:gpadmin-<span class="token punctuation">[</span>INFO<span class="token punctuation">]</span>:-   Successful segment starts                                            <span class="token operator">=</span> 2<span class="token punctuation">..</span>.20200<span class="token punctuation">..</span>. gpinitsystem:localhost:gpadmin-<span class="token punctuation">[</span>INFO<span class="token punctuation">]</span>:-Greenplum Database instance successfully created<span class="token comment" spellcheck="true"># GreenPlum 初始化成功</span></code></pre><ul><li>如果出现问题可以去下面路径查看日志</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">less</span> /home/gpadmin/gpAdminLogs/</code></pre><h2 id="5-连接-GreenPlum-测试"><a href="#5-连接-GreenPlum-测试" class="headerlink" title="5. 连接 GreenPlum 测试"></a>5. 连接 GreenPlum 测试</h2><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 连接GreenPlum</span><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ psql -d postgrespsql <span class="token punctuation">(</span>9.4.24<span class="token punctuation">)</span>Type <span class="token string">"help"</span> <span class="token keyword">for</span> help.postgres<span class="token operator">=</span><span class="token comment" spellcheck="true"># select version();</span>                        version---------------------------------------------------------- PostgreSQL 9.4.24 <span class="token punctuation">(</span>Greenplum Database 6.7.1 build <span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">(</span>1 row<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 查看现有database</span>postgres<span class="token operator">=</span><span class="token comment" spellcheck="true"># \l</span>                               List of databases   Name    <span class="token operator">|</span>  Owner  <span class="token operator">|</span> Encoding <span class="token operator">|</span>  Collate   <span class="token operator">|</span>   Ctype    <span class="token operator">|</span>  Access privileges-----------+---------+----------+------------+------------+--------------------- postgres  <span class="token operator">|</span> gpadmin <span class="token operator">|</span> UTF8     <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> template0 <span class="token operator">|</span> gpadmin <span class="token operator">|</span> UTF8     <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> <span class="token operator">=</span>c/gpadmin         +           <span class="token operator">|</span>         <span class="token operator">|</span>          <span class="token operator">|</span>            <span class="token operator">|</span>            <span class="token operator">|</span> gpadmin<span class="token operator">=</span>CTc/gpadmin template1 <span class="token operator">|</span> gpadmin <span class="token operator">|</span> UTF8     <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> <span class="token operator">=</span>c/gpadmin         +           <span class="token operator">|</span>         <span class="token operator">|</span>          <span class="token operator">|</span>            <span class="token operator">|</span>            <span class="token operator">|</span> gpadmin<span class="token operator">=</span>CTc/gpadmin<span class="token punctuation">(</span>3 rows<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 新建database</span>postgres<span class="token operator">=</span><span class="token comment" spellcheck="true"># create database test;</span>CREATE DATABASE<span class="token comment" spellcheck="true"># 查看 database 是否创建成功</span>postgres<span class="token operator">=</span><span class="token comment" spellcheck="true"># \l</span>                               List of databases   Name    <span class="token operator">|</span>  Owner  <span class="token operator">|</span> Encoding <span class="token operator">|</span>  Collate   <span class="token operator">|</span>   Ctype    <span class="token operator">|</span>  Access privileges-----------+---------+----------+------------+------------+--------------------- postgres  <span class="token operator">|</span> gpadmin <span class="token operator">|</span> UTF8     <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> template0 <span class="token operator">|</span> gpadmin <span class="token operator">|</span> UTF8     <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> <span class="token operator">=</span>c/gpadmin         +           <span class="token operator">|</span>         <span class="token operator">|</span>          <span class="token operator">|</span>            <span class="token operator">|</span>            <span class="token operator">|</span> gpadmin<span class="token operator">=</span>CTc/gpadmin template1 <span class="token operator">|</span> gpadmin <span class="token operator">|</span> UTF8     <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> <span class="token operator">=</span>c/gpadmin         +           <span class="token operator">|</span>         <span class="token operator">|</span>          <span class="token operator">|</span>            <span class="token operator">|</span>            <span class="token operator">|</span> gpadmin<span class="token operator">=</span>CTc/gpadmin <span class="token function">test</span>      <span class="token operator">|</span> gpadmin <span class="token operator">|</span> UTF8     <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span> en_US.utf8 <span class="token operator">|</span><span class="token punctuation">(</span>4 rows<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 退出命令行</span>postgres<span class="token operator">=</span><span class="token comment" spellcheck="true"># \q</span><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$</code></pre><p>命令集参考文档：<a href="https://gpdb.docs.pivotal.io/6-7/ref_guide/sql_commands/sql_ref.html" target="_blank" rel="noopener">https://gpdb.docs.pivotal.io/6-7/ref_guide/sql_commands/sql_ref.html</a></p><h2 id="6-远程登录授权"><a href="#6-远程登录授权" class="headerlink" title="6. 远程登录授权"></a>6. 远程登录授权</h2><ul><li>为 gpadmin 用户创建密码</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ psql -d postgrespsql <span class="token punctuation">(</span>9.4.24<span class="token punctuation">)</span>Type <span class="token string">"help"</span> <span class="token keyword">for</span> help.postgres<span class="token operator">=</span><span class="token comment" spellcheck="true">#</span>postgres<span class="token operator">=</span><span class="token comment" spellcheck="true">#</span>postgres<span class="token operator">=</span><span class="token comment" spellcheck="true"># alter role gpadmin with password '123456';</span>ALTER ROLEpostgres<span class="token operator">=</span><span class="token comment" spellcheck="true">#</span></code></pre><ul><li>修改授权文件</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ vim /home/gpadmin/data/master/gpseg-1/pg_hba.conf<span class="token comment" spellcheck="true">#在末尾追加如下内容</span>host     all         gpadmin         localhost/16   trust<span class="token comment" spellcheck="true"># 重启 GreenPlum</span><span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ gpstop -M fast -a<span class="token punctuation">[</span>gpadmin@localhost ~<span class="token punctuation">]</span>$ gpstart -a</code></pre><ul><li>配置说明</li></ul><table><thead><tr><th>连接方式</th><th>连接的数据库</th><th>连接的用户</th><th>要连接GP的主机IP</th><th>认证方式</th></tr></thead><tbody><tr><td>host</td><td>all</td><td>gpadmin</td><td>localhost/16</td><td>trust</td></tr></tbody></table><h2 id="7-启停命令与日志"><a href="#7-启停命令与日志" class="headerlink" title="7. 启停命令与日志"></a>7. 启停命令与日志</h2><table><thead><tr><th>说明</th><th>命令</th></tr></thead><tbody><tr><td>启动</td><td>gpstart</td></tr><tr><td>关闭</td><td>gpstop</td></tr><tr><td>状态</td><td>gpstate</td></tr><tr><td>日志地址</td><td>/home/gpadmin/gpAdminLogs</td></tr><tr><td>日志地址</td><td>/home/gpadmin/data/mirror/gpseg1/pg_log</td></tr><tr><td>日志地址</td><td>/home/gpadmin/data/primary/gpseg0/pg_log</td></tr></tbody></table><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://greenplum.cn/2020/01/14/greenplum-htap/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Greenplum&lt;/a&gt;是一款全球领先的开源大数据平台，为全球各行各业提供具备实时处理、弹性扩
      
    
    </summary>
    
    
      <category term="greenplum" scheme="https://www.hnbian.cn/categories/greenplum/"/>
    
    
      <category term="greenplum" scheme="https://www.hnbian.cn/tags/greenplum/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse 常见错误码</title>
    <link href="https://www.hnbian.cn/posts/8e38e034.html"/>
    <id>https://www.hnbian.cn/posts/8e38e034.html</id>
    <published>2022-01-20T08:30:37.000Z</published>
    <updated>2023-04-25T14:24:26.501Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>ClickHouse 是一种高性能列式数据库管理系统，专为在线分析处理（OLAP）场景设计。它具有高查询性能、水平可扩展性和实时数据更新等优点，广泛应用于大数据分析领域。在使用 ClickHouse 时，用户可能会遇到各种错误。为了帮助用户更好地理解和解决问题，ClickHouse 提供了一系列错误码。</p><p>ClickHouse 的错误码是一个数字，表示特定类型的错误。每个错误码对应一个描述性的错误消息，以帮助用户快速定位问题。这些错误码涵盖了各种可能的问题，包括语法错误、权限问题、数据类型不匹配、网络问题等。当用户在查询或操作数据库时遇到问题时，ClickHouse 会返回相应的错误码和错误消息。</p><p>要解决 ClickHouse 返回的错误，用户需要根据错误码和错误消息找出问题所在，并采取相应的措施进行修复。有时，解决问题可能需要修改 SQL 语句、调整权限设置、更改数据类型或检查网络设置等。了解 ClickHouse 错误码有助于用户更快地定位问题，提高数据库使用效率。</p><h2 id="2-常见错误码"><a href="#2-常见错误码" class="headerlink" title="2. 常见错误码"></a>2. 常见错误码</h2><table><thead><tr><th>错误码</th><th>原因</th></tr></thead><tbody><tr><td>53</td><td>数据类型不匹配。当用户试图将不兼容的数据类型插入表中或执行类型转换时，会返回此错误码。用户需要确保数据类型与表结构相符。</td></tr><tr><td>62</td><td>语法错误。当用户提交的 SQL 语句存在语法错误时，会返回此错误码。此时，用户需要检查 SQL 语句的语法是否正确。</td></tr><tr><td>164</td><td>权限问题。当用户试图执行需要特定权限的操作（如创建表、删除表等）时，如果没有足够的权限，会返回此错误码。用户需要检查自己的权限设置，或联系管理员进行授权。</td></tr><tr><td>210</td><td>网络问题。当用户与 ClickHouse 服务器之间的网络连接出现问题时，会返回此错误码。用户需要检查网络连接状况和服务器设置。</td></tr></tbody></table><h3 id="2-1-Code-32"><a href="#2-1-Code-32" class="headerlink" title="2.1 Code: 32"></a>2.1 Code: 32</h3><pre class=" language-bash"><code class="language-bash">Clickhouse code 32 DB::Exception: Attempt to <span class="token function">read</span> after eof</code></pre><ul><li>原因：</li></ul><p>错误码 32 对应的错误消息是 “DB::Exception: Attempt to read after eof”。这表明在尝试从文件或流中读取数据时，已经到达了文件末尾（EOF, End of File），但仍然尝试继续读取。这通常是由于查询中的某些操作导致的，例如尝试读取文件中不存在的数据。</p><ul><li>解决：</li></ul><ol><li>检查查询：仔细检查查询，确保正在访问存在的数据。如果查询中的某些操作依赖于文件的特定部分，但该部分不存在，则可能会导致此问题。尝试修改查询以避免读取不存在的数据。</li><li>检查数据文件：检查与查询相关的数据文件，确保它们没有损坏或不完整。如果文件损坏或丢失部分数据，可能需要从备份恢复数据，或者重新生成数据。</li><li>检查表结构：确保表结构与查询中使用的数据类型和列相匹配。如果表结构与查询不匹配，可能会导致读取文件时出现问题。可以使用 <code>DESCRIBE TABLE</code> 语句查看表结构。</li></ol><p>通过检查查询、确保数据文件完整且未损坏以及检查表结构，可以解决错误码 32 相关的问题。这将有助于确保能够顺利地从文件或流中读取数据，从而提高查询性能和可靠性。</p><h3 id="2-2-Code-48"><a href="#2-2-Code-48" class="headerlink" title="2.2 Code: 48"></a>2.2 Code: 48</h3><pre class=" language-bash"><code class="language-bash">Received exception from server <span class="token punctuation">(</span>version 21.1.2.15<span class="token punctuation">)</span>:Code: 48. DB::Exception: Received from localhost:9000, ::1. DB::Exception: Mutations are not supported by storage Distributed.</code></pre><ul><li>原因：</li></ul><p>错误码 48 对应的错误消息是 “DB::Exception: Received from localhost:9000, ::1. DB::Exception: Mutations are not supported by storage Distributed.”。这表示尝试在 ClickHouse 的 Distributed 存储引擎上执行一种不支持的操作（即，Mutation）。Mutation 是一种用于对已存在的数据进行修改的操作，例如 ALTER TABLE … UPDATE 或 ALTER TABLE … DELETE。</p><ul><li>解决：</li></ul><p>需要在 Distributed 表的底层本地表上执行 Mutation 操作，而不是直接在 Distributed 表上进行。Distributed 表本质上是一个代理，它将查询路由到一个或多个底层的本地表。因此，要对 Distributed 表的数据进行修改，需要分别在每个底层本地表上执行相应的 Mutation 操作。</p><p>例如，如果有一个名为 <code>distributed_table</code> 的 Distributed 表，该表分布在名为 <code>local_table</code> 的本地表上，可以执行以下操作：</p><ol><li>在每个本地表上执行 UPDATE 操作：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> local_table <span class="token keyword">ON</span> CLUSTER your_cluster <span class="token keyword">UPDATE</span> column1 <span class="token operator">=</span> value1 <span class="token keyword">WHERE</span> condition<span class="token punctuation">;</span></code></pre><ol start="2"><li>在每个本地表上执行 DELETE 操作：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> local_table <span class="token keyword">ON</span> CLUSTER your_cluster <span class="token keyword">DELETE</span> <span class="token keyword">WHERE</span> condition<span class="token punctuation">;</span></code></pre><p>通过在底层本地表上执行 Mutation 操作，可以解决错误码 48 相关的问题。这将有助于确保能够成功地修改 Distributed 表的数据，从而提高查询性能和可靠性。</p><h3 id="2-3-Code-62"><a href="#2-3-Code-62" class="headerlink" title="2.3 Code: 62"></a>2.3 Code: 62</h3><pre class=" language-bash"><code class="language-bash">ERROR ApplicationMaster: User class threw exception: ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 62, host: 127.0.0.1, port: 8123<span class="token punctuation">;</span> Code: 62, e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::Exception: Syntax error: failed at position 1432 <span class="token punctuation">(</span>end of query<span class="token punctuation">)</span>: <span class="token keyword">.</span> Expected one of: ENGINE, storage definition <span class="token punctuation">(</span>version 20.8.3.18<span class="token punctuation">)</span>ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 62, host: 127.0.0.1, port: 8123<span class="token punctuation">;</span> Code: 62, e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::Exception: Syntax error: failed at position 1432 <span class="token punctuation">(</span>end of query<span class="token punctuation">)</span>: <span class="token keyword">.</span> Expected one of: ENGINE, storage definition <span class="token punctuation">(</span>version 20.8.3.18<span class="token punctuation">)</span></code></pre><ul><li>原因：</li></ul><p>错误码 62 表示遇到了一个语法错误。根据错误消息 “Syntax error: failed at position 1432 (end of query): . Expected one of: ENGINE, storage definition”，在执行 ClickHouse 查询或操作时，遇到了一个语法错误。问题出现在查询的第 1432 个字符位置，可能与存储引擎（ENGINE）或存储定义相关。</p><ul><li>解决： </li></ul><p>请仔细检查 SQL 查询或操作，并找出语法错误。以下是一些建议：</p><ol><li>检查 <code>CREATE TABLE</code> 语句中是否正确定义了存储引擎。在 ClickHouse 中，需要为每个表指定一个存储引擎。例如，对于 MergeTree 存储引擎，需要这样定义：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> table_name<span class="token punctuation">(</span>    column1 String<span class="token punctuation">,</span>    column2 Int32<span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span> <span class="token operator">=</span> MergeTree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">ORDER</span> <span class="token keyword">BY</span> <span class="token punctuation">(</span>column1<span class="token punctuation">,</span> column2<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ol><li>确保 SQL 查询中没有遗漏或错误的括号、逗号或其他符号。这些小错误可能导致语法错误。</li><li>如果正在使用一些高级特性或函数，请确保正确使用它们。参考 ClickHouse 官方文档以获取正确的语法和示例。</li></ol><p>检查并修正 SQL 查询或操作中的语法错误有助于解决错误码 62 相关的问题。正确编写 SQL 查询或操作可以确保 ClickHouse 正常工作，并避免因语法错误导致的问题。</p><h3 id="2-4-Code-62"><a href="#2-4-Code-62" class="headerlink" title="2.4 Code 62"></a>2.4 Code 62</h3><pre class=" language-bash"><code class="language-bash">Max query size exceeded</code></pre><ul><li><p>原因：Select 语句中使用 in 方式查询报错。这是由于查询语句特别大造成的，默认的 max_query_size 最大是256。</p></li><li><p>解决：</p></li></ul><p>打开 /etc/clickhouse-server/users.xml（只配置了一些常用的用户）。max_query_size 这种配置，就需要在 profiles 部分中配置修改。</p><p>注意这里的单位是 bytes(字节), 我这里设置了102410241024=1,073,741,824,就解决问题了。如果是 sql 创建的用户，需要通过 sql 修改配额，修改方式参考 <a href="https://www.cnblogs.com/MrYang-11-GetKnow/p/15896355.html。" target="_blank" rel="noopener">https://www.cnblogs.com/MrYang-11-GetKnow/p/15896355.html。</a></p><h3 id="2-5-Code-117"><a href="#2-5-Code-117" class="headerlink" title="2.5 Code: 117"></a>2.5 Code: 117</h3><pre class=" language-bash"><code class="language-bash">Code: 117, e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::Exception: Unexpected NULL value of not Nullable <span class="token function">type</span> String <span class="token punctuation">(</span>version 20.8.3.18<span class="token punctuation">)</span></code></pre><ul><li>原因：</li></ul><p>错误码 117 对应的错误消息为 “Unexpected NULL value of not Nullable type String”。这表明在执行某个操作时，向一个不允许为空（non-nullable）的 String 类型字段中插入了 NULL 值。ClickHouse 不允许在 non-nullable 字段中存储 NULL 值。</p><ul><li>解决</li></ul><p>检查 SQL 查询或操作，确保不向不允许为空的字段中插入 NULL 值。可以采取以下措施之一：</p><ol><li>确保插入的数据中不包含 NULL 值。在插入数据之前，可以对数据进行清洗，以确保不包含 NULL 值。如果数据源可能包含 NULL 值，可以使用适当的默认值替换它们。</li><li>修改表结构，将 non-nullable 字段更改为 nullable 字段。这将允许字段存储 NULL 值。可以使用 <code>ALTER TABLE</code> 语句更改表结构。但请注意，这可能会影响查询性能和存储空间。</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">MODIFY</span> <span class="token keyword">COLUMN</span> column_name Nullable<span class="token punctuation">(</span>String<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ol><li>使用 <code>coalesce</code> 或 <code>ifNull</code> 函数为可能为空的字段提供默认值。这可以确保在插入数据时，空值将被默认值替换。</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> table_name <span class="token punctuation">(</span>column1<span class="token punctuation">,</span> column2<span class="token punctuation">,</span> non_nullable_column<span class="token punctuation">)</span><span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token string">'value1'</span><span class="token punctuation">,</span> <span class="token string">'value2'</span><span class="token punctuation">,</span> <span class="token keyword">coalesce</span><span class="token punctuation">(</span><span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token string">'default_value'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>通过采取这些措施，应该能够解决错误码 117 相关的问题。确保不向 non-nullable 字段中插入 NULL 值，有助于维护数据库的数据完整性和查询性能。</p><h3 id="2-6-Code-159，read-timeout"><a href="#2-6-Code-159，read-timeout" class="headerlink" title="2.6 Code: 159，read timeout"></a>2.6 Code: 159，read timeout</h3><ul><li>原因：查询超时导致报错。</li><li>解决：执行某些SQL很耗时导致最后报错读超时，这是因为 clickhouse 执行单次 SQ L的默认最大等待时间是30s，如果有比较耗时的SQL， 可以通过将 JdbcURL 的 socket_timeout 参数值设置的大一点来解决这个问题（注意这个参数的时间单位是毫秒，默认是30000）。</li></ul><h3 id="2-7-Code-159"><a href="#2-7-Code-159" class="headerlink" title="2.7 Code: 159"></a>2.7 Code: 159</h3><pre class=" language-bash"><code class="language-bash">Code: 159. DB::Exception: Received from localhost:9000. DB::Exception: Watching task /clickhouse/task_queue/ddl/query-0000000002 is executing longer than distributed_ddl_task_timeout <span class="token punctuation">(</span><span class="token operator">=</span>180<span class="token punctuation">)</span> seconds. There are 3 unfinished hosts <span class="token punctuation">(</span>0 of them are currently active<span class="token punctuation">)</span>, they are going to execute the query <span class="token keyword">in</span> background.</code></pre><ul><li>原因： </li></ul><p>错误码 159 表示遇到了一个分布式 DDL（Data Definition Language）任务超时的问题。根据错误消息，任务执行时间超过了分布式 DDL 任务的超时时间（<code>distributed_ddl_task_timeout</code>），默认值为 180 秒。此时，尚有 3 个未完成的主机（其中 0 个处于活跃状态），它们将在后台继续执行查询。</p><ul><li>解决</li></ul><ol><li>增加分布式 DDL 任务的超时时间：可以通过修改 <code>distributed_ddl_task_timeout</code> 配置参数来增加超时时间。例如，将其设置为 300 秒：</li></ol><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 在 config.xml 文件中 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>distributed_ddl_task_timeout</span><span class="token punctuation">></span></span>300<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>distributed_ddl_task_timeout</span><span class="token punctuation">></span></span></code></pre><p>然后重启 ClickHouse 服务器以使更改生效。这将为分布式 DDL 任务提供更多的执行时间。</p><ol start="2"><li><p>检查未完成主机的状态：由于有 3 个未完成的主机，可能需要检查这些主机的状态。可能有网络问题、资源瓶颈或其他问题导致它们无法在规定时间内完成任务。解决这些问题可以提高分布式 DDL 任务的执行效率。</p></li><li><p>优化 DDL 操作：如果正在执行大型或复杂的 DDL 操作（例如，更改表结构或删除大量数据），可能需要考虑优化这些操作以减少执行时间。例如，可以将大型操作分解为较小的任务，或者优化表结构以提高执行效率。</p></li></ol><p>通过调整超时设置、检查主机状态和优化 DDL 操作，可以解决错误码 159 相关的问题。这将有助于确保分布式 DDL 任务能够在规定时间内完成，提高 ClickHouse 集群的整体性能。</p><h3 id="2-8-Code-168，AST-is-too-big，Maximum-50000"><a href="#2-8-Code-168，AST-is-too-big，Maximum-50000" class="headerlink" title="2.8 Code: 168，AST is too big，Maximum: 50000"></a>2.8 Code: 168，AST is too big，Maximum: 50000</h3><ul><li>原因： </li></ul><p>错误码 168 对应的错误消息是 “AST is too big，Maximum: 50000”。这表明在执行某个查询或操作时，生成的抽象语法树（Abstract Syntax Tree，AST）太大，超过了 ClickHouse 允许的最大限制（默认为 50,000）。</p><blockquote><p>抽象语法树是一种树形数据结构，用于表示源代码的结构。在执行查询或操作时，ClickHouse 首先将 SQL 语句解析为 AST，然后对 AST 进行进一步的分析和处理。如果生成的 AST 过大，可能导致内存消耗过高，影响系统性能。</p></blockquote><ul><li>解决：</li></ul><p>要解决这个问题，需要优化 SQL 查询或操作，以减小生成的 AST 大小。以下是一些建议：</p><ol><li>分解复杂查询：将复杂的查询分解为多个较简单的查询，并逐步执行。这可以减小每个查询生成的 AST 大小，降低内存消耗。</li><li>避免过度嵌套：减少子查询、连接和嵌套函数的使用，以降低 AST 的复杂性。尽可能使用简单的查询结构和表达式。</li><li>优化表结构：优化表结构以减少查询中需要处理的字段数量。这可以降低 AST 大小，并提高查询性能。</li></ol><p>另外，可以尝试增加 ClickHouse 配置中的 <code>max_ast_elements</code> 参数值。但请注意，过高的值可能导致更高的内存消耗和系统性能问题。</p><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 在 config.xml 文件中 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>max_ast_elements</span><span class="token punctuation">></span></span>100000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>max_ast_elements</span><span class="token punctuation">></span></span></code></pre><p>然后重启 ClickHouse 服务器以使更改生效。请谨慎调整此值，以免对系统性能产生负面影响。</p><p>通过优化 SQL 查询或操作、分解复杂查询以及合理调整 ClickHouse 配置，可以解决错误码 168 相关的问题。这将有助于确保 AST 大小在可接受范围内，提高 ClickHouse 的查询性能和稳定性。</p><h3 id="2-9-Code-202"><a href="#2-9-Code-202" class="headerlink" title="2.9 Code: 202"></a>2.9 Code: 202</h3><pre class=" language-bash"><code class="language-bash">ClickHouse exception, code: 202, host: xxxxx, port: 8123<span class="token punctuation">;</span> Code: 202, e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::Exception: Too many simultaneous queries. Maximum: 100</code></pre><ul><li>原因：</li></ul><p>错误码 202 对应的错误消息是 “Too many simultaneous queries. Maximum: 100”。这表明正在尝试在 ClickHouse 中执行过多的并行查询，超过了允许的最大限制（默认为 100）。</p><ul><li>解决：</li></ul><ol><li>限制并发查询：尝试减少应用程序或服务中同时执行的查询数量。可以考虑使用连接池、队列或其他方法来限制并发查询数，避免超过 ClickHouse 允许的最大限制。</li><li>优化查询性能：检查查询，看是否可以进行优化以提高查询性能。执行更快的查询可以减少并发查询数，从而降低对 ClickHouse 的压力。可以考虑使用索引、分区或其他优化方法来提高查询性能。</li><li>调整 ClickHouse 配置：可以尝试增加 ClickHouse 配置中的 <code>max_concurrent_queries</code> 参数值，以允许更多的并发查询。但请注意，过高的值可能导致更高的资源消耗和系统性能问题。</li></ol><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 在 config.xml 文件中 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>max_concurrent_queries</span><span class="token punctuation">></span></span>150<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>max_concurrent_queries</span><span class="token punctuation">></span></span></code></pre><p>然后重启 ClickHouse 服务器以使更改生效。请谨慎调整此值，以免对系统性能产生负面影响。</p><p>通过限制并发查询、优化查询性能以及合理调整 ClickHouse 配置，可以解决错误码 202 相关的问题。这将有助于确保 ClickHouse 能够在可接受的范围内处理并发查询，提高系统的整体性能和稳定性。</p><h3 id="2-10-Code-210"><a href="#2-10-Code-210" class="headerlink" title="2.10 Code: 210"></a>2.10 Code: 210</h3><pre class=" language-bash"><code class="language-bash">Code: 210, e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::NetException: Connection refused: <span class="token punctuation">(</span>10.121.21.33:9000<span class="token punctuation">)</span>, e.what<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::NetException ConnectionPoolWithFailover: Connection failed at try <span class="token punctuation">..</span></code></pre><p>错误码 210 对应的错误消息是 “Connection refused”。这表明在尝试连接到 ClickHouse 服务器（IP 地址为 10.121.21.33，端口为 9000）时，连接被拒绝。这可能是由于网络问题、服务器未启动或服务器配置不正确导致的。</p><p>为了解决这个问题，可以尝试以下方法：</p><ol><li>检查网络连接：确保客户端和 ClickHouse 服务器之间的网络连接正常。可以尝试使用 <code>ping</code> 或 <code>telnet</code> 命令测试网络连接。</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token function">ping</span> 10.121.21.33telnet 10.121.21.33 9000</code></pre><ol start="2"><li>确保 ClickHouse 服务器正在运行：登录到目标服务器（IP 地址为 10.121.21.33），检查 ClickHouse 服务是否正在运行。如果没有运行，需要启动 ClickHouse 服务。</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 对于 Systemd 系统，使用以下命令：</span><span class="token function">sudo</span> systemctl start clickhouse-server<span class="token comment" spellcheck="true"># 对于 SysVinit 系统，使用以下命令：</span><span class="token function">sudo</span> <span class="token function">service</span> clickhouse-server start</code></pre><ol start="3"><li>检查 ClickHouse 配置：确保 ClickHouse 配置文件（通常位于 <code>/etc/clickhouse-server/config.xml</code>）正确配置了监听地址和端口。例如，要确保 ClickHouse 服务器监听所有网络接口，可以将 <code>listen_host</code> 参数设置为 <code>0.0.0.0</code>：</li></ol><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 在 config.xml 文件中 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>listen_host</span><span class="token punctuation">></span></span>0.0.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>listen_host</span><span class="token punctuation">></span></span></code></pre><p>然后重启 ClickHouse 服务器以使更改生效。</p><p>通过检查网络连接、确保 ClickHouse 服务器正在运行以及检查并更新 ClickHouse 配置，可以解决错误码 210 相关的问题。这将有助于确保客户端能够成功连接到 ClickHouse 服务器，从而进行正常的查询和操作。</p><h3 id="2-11-Code-241"><a href="#2-11-Code-241" class="headerlink" title="2.11 Code: 241"></a>2.11 Code: 241</h3><pre class=" language-bash"><code class="language-bash">Code: 241. DB::Exception: Received from localhost:9000. DB::Exception: Memory limit <span class="token punctuation">(</span>for query<span class="token punctuation">)</span> exceeded: would use 9.31 GiB <span class="token punctuation">(</span>attempt to allocate chunk of 4223048 bytes<span class="token punctuation">)</span>, maximum: 9.31 GiB: While executing MergeTreeThread: While executing CreatingSetsTransform.</code></pre><ul><li>原因： </li></ul><p>错误码 241 对应的错误消息是 “Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4223048 bytes), maximum: 9.31 GiB: While executing MergeTreeThread: While executing CreatingSetsTransform”。这表明在执行某个查询时，内存使用量超过了 ClickHouse 允许的最大限制（默认为 9.31 GiB）。</p><ul><li>解决：</li></ul><ol><li>优化查询：检查查询，看是否可以进行优化以降低内存使用量。可以考虑减少查询中的子查询、连接和嵌套函数，以降低内存消耗。此外，通过选择合适的表结构和索引，还可以提高查询性能。</li><li>分解复杂查询：将复杂的查询分解为多个较简单的查询，并逐步执行。这可以降低每个查询的内存消耗，从而降低对 ClickHouse 的压力。</li><li>调整 ClickHouse 配置：可以尝试增加 ClickHouse 配置中的 <code>max_memory_usage</code> 参数值，以允许使用更多内存。但请注意，过高的值可能导致更高的资源消耗和系统性能问题。</li></ol><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 在 config.xml 文件中 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>max_memory_usage</span><span class="token punctuation">></span></span>16106127360<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>max_memory_usage</span><span class="token punctuation">></span></span></code></pre><p>上面的例子将最大内存使用限制提高到 15 GiB。然后重启 ClickHouse 服务器以使更改生效。请谨慎调整此值，以免对系统性能产生负面影响。</p><p>通过优化查询、分解复杂查询以及合理调整 ClickHouse 配置，可以解决错误码 241 相关的问题。这将有助于确保内存使用量在可接受范围内，提高 ClickHouse 的查询性能和稳定性。</p><h3 id="2-12-Code-252"><a href="#2-12-Code-252" class="headerlink" title="2.12 Code: 252"></a>2.12 Code: 252</h3><pre class=" language-bash"><code class="language-bash">ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 252, host: xxxx, port: 8123<span class="token punctuation">;</span> Code: 252, e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::Exception: Too many parts <span class="token punctuation">(</span>308<span class="token punctuation">)</span>. Merges are processing significantly slower than inserts. <span class="token punctuation">(</span>version 20.8.3.18<span class="token punctuation">)</span></code></pre><ul><li>原因： </li></ul><p>这个错误表示 ClickHouse 中的表分区有太多的数据部分（parts），导致合并操作（merges）处理速度远低于插入操作（inserts）。错误消息是 “ClickHouse exception, code: 252, e.displayText() = DB::Exception: Too many parts (308). Merges are processing significantly slower than inserts.”。</p><ul><li>解决：</li></ul><ol><li>优化表的分区策略：检查的表分区策略，看是否可以进行优化以减少数据部分的数量。合理的分区策略可以确保数据更有效地存储在表中，从而提高合并操作的性能。</li><li>调整合并操作的设置：可以调整 ClickHouse 配置文件中与合并操作相关的参数，以提高合并操作的性能。例如，可以调整 <code>background_pool_size</code> 和 <code>background_schedule_pool_size</code> 参数，以便 ClickHouse 使用更多的线程来执行合并操作。</li></ol><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 在 config.xml 文件中 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>background_pool_size</span><span class="token punctuation">></span></span>16<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>background_pool_size</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>background_schedule_pool_size</span><span class="token punctuation">></span></span>16<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>background_schedule_pool_size</span><span class="token punctuation">></span></span></code></pre><p>完成更改后，重启 ClickHouse 服务器以使更改生效。</p><ol start="3"><li>手动触发合并操作：可以尝试手动触发合并操作，以减少表中的数据部分。使用 <code>OPTIMIZE TABLE</code> 语句可以手动触发合并操作：</li></ol><pre class=" language-xml"><code class="language-xml">OPTIMIZE TABLE your_table_name FINAL;</code></pre><p>这将尝试将表中的所有数据部分合并为一个部分。请注意，此操作可能会消耗大量资源并影响查询性能，因此谨慎使用。</p><p>通过优化表的分区策略、调整合并操作的设置以及手动触发合并操作，可以解决错误码 252 相关的问题。这将有助于确保表中的数据部分数量保持在合理范围内，从而提高合并操作和查询性能。</p><h3 id="2-13-Code-252"><a href="#2-13-Code-252" class="headerlink" title="2.13 Code: 252"></a>2.13 Code: 252</h3><pre class=" language-bash"><code class="language-bash">Code: 252, e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> DB::Exception: Too many partitions ,<span class="token keyword">for</span> single INSERT block <span class="token punctuation">(</span>more than 100<span class="token punctuation">)</span>.</code></pre><ul><li>原因：</li></ul><p>错误码 252 对应的错误消息是 “DB::Exception: Too many partitions for single INSERT block (more than 100)”。这表示尝试执行的 INSERT 操作涉及到过多的分区（超过 100 个），导致 ClickHouse 拒绝执行该操作。ClickHouse 限制了单个 INSERT 块中涉及的分区数量，以防止由于插入数据导致的性能问题。</p><ul><li>解决：</li></ul><ol><li>拆分 INSERT 操作：将涉及大量分区的 INSERT 操作拆分为多个较小的操作。每个操作应仅涉及较少的分区，以确保它们在 ClickHouse 中能够成功执行。例如，可以将数据分批插入，每次插入涉及的分区数量不超过 100。</li><li>优化分区策略：检查的表分区策略，看是否可以进行优化以减少 INSERT 操作涉及的分区数量。合理的分区策略可以确保数据在表中更有效地存储，从而提高插入操作的性能。</li><li>调整插入的数据量：如果可能，请尝试减少单个 INSERT 操作中插入的数据量。这样可以降低插入操作涉及的分区数量，从而提高插入操作的成功率。</li></ol><p>通过拆分 INSERT 操作、优化分区策略以及调整插入的数据量，可以解决错误码 252 相关的问题。这将有助于确保能够顺利地向 ClickHouse 表中插入数据，从而提高查询性能和可靠性。</p><h3 id="2-14-Code-253"><a href="#2-14-Code-253" class="headerlink" title="2.14 Code: 253"></a>2.14 Code: 253</h3><pre class=" language-bash"><code class="language-bash">Code: 253, Replica /clickhouse/tables/XXX/XXX/replicas/dba07 already exists</code></pre><ul><li>原因：</li></ul><p>错误码 253 对应的错误消息是 “Replica /clickhouse/tables/XXX/XXX/replicas/dba07 already exists”。这意味着尝试创建一个已经存在的副本（Replica）。在 ClickHouse 的 ReplicatedMergeTree 引擎中，副本用于在多个服务器之间同步数据，以提供冗余和故障转移。每个副本都必须具有唯一的名称。</p><ul><li>解决：</li></ul><ol><li>检查副本名称：确保在创建副本时使用了正确且唯一的名称。如果已经存在具有相同名称的副本，请为新副本选择不同的名称。例如，如果当前尝试创建的副本名称为 <code>dba07</code>，则可以尝试使用 <code>dba08</code> 或其他唯一名称。</li><li>删除现有副本：如果确实需要创建一个具有相同名称的副本，可以先删除现有副本。然而，请注意，在删除副本之前，确保它不再需要，以防止数据丢失。要删除副本，可以使用 <code>DROP TABLE</code> 语句：</li></ol><pre class=" language-xml"><code class="language-xml">DROP TABLE your_table_name ON CLUSTER your_cluster_name;</code></pre><p>然后，可以使用 <code>CREATE TABLE</code> 语句创建新的副本。</p><p>通过检查副本名称以及在需要时删除现有副本，可以解决错误码 253 相关的问题。这将有助于确保能够成功地创建和管理 ClickHouse 中的副本，从而提高数据同步和故障转移能力。</p><h3 id="2-15-Code-253"><a href="#2-15-Code-253" class="headerlink" title="2.15 Code: 253"></a>2.15 Code: 253</h3><pre class=" language-bash"><code class="language-bash">Code: 253, Exception: Replica /clickhouse/tables/<span class="token punctuation">[</span><span class="token punctuation">..</span>.<span class="token punctuation">]</span> already exists <span class="token punctuation">(</span>version 21.8.10.19 Docker<span class="token punctuation">)</span></code></pre><ul><li>原因：</li></ul><p>错误码 253 对应的错误消息是 “Exception: Replica /clickhouse/tables/[…] already exists (version 21.8.10.19 Docker)”。这表示尝试创建一个已经存在的副本。在 ClickHouse 的 ReplicatedMergeTree 引擎中，副本用于在多个服务器之间同步数据，以提供冗余和故障转移。每个副本都必须具有唯一的名称。</p><ul><li>解决：</li></ul><ol><li>检查副本名称：确保在创建副本时使用了正确且唯一的名称。如果已经存在具有相同名称的副本，请为新副本选择不同的名称。例如，如果当前尝试创建的副本名称为 <code>replica01</code>，则可以尝试使用 <code>replica02</code> 或其他唯一名称。</li><li>删除现有副本：如果确实需要创建一个具有相同名称的副本，可以先删除现有副本。然而，请注意，在删除副本之前，确保它不再需要，以防止数据丢失。要删除副本，可以使用 <code>DROP TABLE</code> 语句：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> your_table_name <span class="token keyword">ON</span> CLUSTER your_cluster_name<span class="token punctuation">;</span></code></pre><p>然后，可以使用 <code>CREATE TABLE</code> 语句创建新的副本。</p><p>通过检查副本名称以及在需要时删除现有副本，可以解决错误码 253 相关的问题。这将有助于确保能够成功地创建和管理 ClickHouse 中的副本，从而提高数据同步和故障转移能力。</p><h3 id="2-16-Code-253"><a href="#2-16-Code-253" class="headerlink" title="2.16 Code: 253"></a>2.16 Code: 253</h3><pre class=" language-bash"><code class="language-bash">Code: 253, Exception: Replica /clickhouse/tables/<span class="token punctuation">[</span><span class="token punctuation">..</span>.<span class="token punctuation">]</span> already exists <span class="token punctuation">(</span>version 21.8.10.19 Docker<span class="token punctuation">)</span></code></pre><ul><li>原因：</li></ul><p>错误码 253 对应的错误消息是 “Exception: Replica /clickhouse/tables/[…] already exists (version 21.8.10.19 Docker)”。这表示尝试创建一个已经存在的副本。在 ClickHouse 的 ReplicatedMergeTree 引擎中，副本用于在多个服务器之间同步数据，以提供冗余和故障转移。每个副本都必须具有唯一的名称。</p><ul><li>解决：</li></ul><ol><li>检查副本名称：确保在创建副本时使用了正确且唯一的名称。如果已经存在具有相同名称的副本，请为新副本选择不同的名称。例如，如果当前尝试创建的副本名称为 <code>replica01</code>，则可以尝试使用 <code>replica02</code> 或其他唯一名称。</li><li>删除现有副本：如果确实需要创建一个具有相同名称的副本，可以先删除现有副本。然而，请注意，在删除副本之前，确保它不再需要，以防止数据丢失。要删除副本，可以使用 <code>DROP TABLE</code> 语句：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> your_table_name <span class="token keyword">ON</span> CLUSTER your_cluster_name<span class="token punctuation">;</span></code></pre><p>然后，可以使用 <code>CREATE TABLE</code> 语句创建新的副本。</p><p>通过检查副本名称以及在需要时删除现有副本，可以解决错误码 253 相关的问题。这将有助于确保能够成功地创建和管理 ClickHouse 中的副本，从而提高数据同步和故障转移能力。</p><h3 id="2-17-Code-359"><a href="#2-17-Code-359" class="headerlink" title="2.17 Code: 359"></a>2.17 Code: 359</h3><pre class=" language-bash"><code class="language-bash">Code: 359,e.displayText<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">=</span>DB::Exception: Table or Partition <span class="token keyword">in</span> xxx was not dropped.Reason:1. Size <span class="token punctuation">(</span>158.40 GB<span class="token punctuation">)</span> is greater than max_<span class="token punctuation">[</span>table/partition<span class="token punctuation">]</span>_size_to_drop <span class="token punctuation">(</span>50.00 GB<span class="token punctuation">)</span>2. File <span class="token string">'/data/clickhouse/clickhouse-server/flags/force_drop_table'</span> intended to force DROP doesn't exist</code></pre><ul><li>原因： </li></ul><p>错误码 359 对应的错误消息是 “DB::Exception: Table or Partition in xxx was not dropped. Reason: \1. Size (158.40 GB) is greater than max_[table/partition]_size_to_drop (50.00 GB) \2. File ‘/data/clickhouse/clickhouse-server/flags/force_drop_table’ intended to force DROP doesn’t exist”。这表示尝试删除一个表或分区，但由于其大小（158.40 GB）超过了允许删除的最大表或分区大小（50.00 GB），因此未能成功删除。</p><ul><li>解决：</li></ul><ol><li>增加 max_table_size_to_drop 或 max_partition_size_to_drop 的值：可以通过修改 ClickHouse 配置文件（通常为 /etc/clickhouse-server/config.xml）中的 max_table_size_to_drop 或 max_partition_size_to_drop 参数来增加允许删除的最大表或分区大小。例如，可以将其设置为 200 GB 或更高。请注意，在修改配置文件后，需要重启 ClickHouse 服务器以使更改生效。</li><li>强制删除表或分区：如果确实需要删除较大的表或分区，可以通过创建一个名为 ‘force_drop_table’ 的文件来强制删除它。此文件应位于 ‘/data/clickhouse/clickhouse-server/flags/‘ 目录中。可以使用以下命令创建该文件：</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token function">touch</span> /data/clickhouse/clickhouse-server/flags/force_drop_table</code></pre><p>然后，再次尝试删除表或分区。请注意，在完成删除操作后，建议删除 ‘force_drop_table’ 文件，以免误删其他表或分区。</p><p>通过增加允许删除的最大表或分区大小，或者强制删除表或分区，可以解决错误码 359 相关的问题。这将有助于确保能够有效地管理 ClickHouse 中的表和分区，从而提高数据库性能和可靠性。</p><h3 id="2-18-Code-516"><a href="#2-18-Code-516" class="headerlink" title="2.18 Code: 516"></a>2.18 Code: 516</h3><pre class=" language-bash"><code class="language-bash">Code: 516. DB::Exception: Received from localhost:9000. DB::Exception: Received from chi-repl-05-replicated-0-0:9000. DB::Exception: default: Authentication failed: password is incorrect or there is no user with such name.</code></pre><ul><li>原因：</li></ul><p>错误码 516 对应的错误消息是 “DB::Exception: Received from localhost:9000. DB::Exception: Received from chi-repl-05-replicated-0-0:9000. DB::Exception: default: Authentication failed: password is incorrect or there is no user with such name.”。这表示尝试连接到 ClickHouse 服务器时遇到了身份验证问题。可能的原因是提供的密码不正确，或者不存在具有所提供名称的用户。</p><ul><li>解决：</li></ul><ol><li>检查用户名和密码：确保在尝试连接到 ClickHouse 服务器时使用了正确的用户名和密码。如果不确定用户名和密码，请查看 ClickHouse 配置文件（通常为 <code>/etc/clickhouse-server/users.xml</code>），在该文件中，可以找到用户的详细信息和加密后的密码。</li><li>重置用户密码：如果无法找到正确的密码，可以重置用户密码。要做到这一点，打开 ClickHouse 配置文件（通常为 <code>/etc/clickhouse-server/users.xml</code>），找到要重置密码的用户，并将其 <code>&lt;password&gt;</code> 标签替换为新的加密密码。要生成加密密码，可以使用 <code>clickhouse-client</code> 命令行工具：</li></ol><pre class=" language-bash"><code class="language-bash">clickhouse-client --password <span class="token string">'your_new_password'</span></code></pre><p>运行此命令后，它将提示输入当前密码，然后生成加密后的新密码。将此加密密码复制并粘贴到 <code>users.xml</code> 文件中的相应用户的 <code>&lt;password&gt;</code> 标签中。完成更改后，请确保保存文件并重启 ClickHouse 服务器以使更改生效。</p><p>通过检查用户名和密码以及在需要时重置用户密码，可以解决错误码 516 相关的问题。这将确保能够成功连接到 ClickHouse 服务器，从而进行查询和数据操作。</p><h3 id="2-19-Code-1000"><a href="#2-19-Code-1000" class="headerlink" title="2.19 Code: 1000"></a>2.19 Code: 1000</h3><pre class=" language-bash"><code class="language-bash">db::exception: no interserver io endpoint named…<span class="token comment" spellcheck="true"># 复制副本数据时报错导致无法同步数据，直接在err.log日志文件看到的报错是：auto </span>DB::StorageReplicatedMergeTree::processQueueEntry<span class="token punctuation">(</span>ReplicatedMergeTreeQueue::SelectedEntryPtr<span class="token punctuation">)</span>::<span class="token punctuation">(</span>anonymous class<span class="token punctuation">)</span>::operator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>DB::StorageReplicatedMergeTree::LogEntryPtr <span class="token operator">&amp;</span><span class="token punctuation">)</span> const: Poco::Exception. Code: 1000, e.code<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> 111, Connection refused</code></pre><ul><li>原因：</li></ul><p>这个错误表明在 ClickHouse 分布式副本之间进行数据同步时遇到了问题。错误消息 “DB::Exception: No interserver IO endpoint named” 和 “Poco::Exception. Code: 1000, e.code() = 111, Connection refused” 表示在尝试将数据从一个副本传输到另一个副本时，连接被拒绝。</p><ul><li>解决：</li></ul><ol><li>检查 ClickHouse 集群中所有节点的网络连接：确保所有节点之间的网络连接正常。可以使用 <code>ping</code> 命令检查网络连接。</li><li>检查 ClickHouse 配置文件：确保所有节点的 ClickHouse 配置文件（通常位于 <code>/etc/clickhouse-server/config.xml</code>）中的 <code>interserver_http_host</code> 和 <code>interserver_http_port</code> 参数正确配置。这两个参数定义了节点间数据传输所使用的地址和端口。</li></ol><p>例如：</p><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 在 config.xml 文件中 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>interserver_http_host</span><span class="token punctuation">></span></span>your_server_ip_or_hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>interserver_http_host</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>interserver_http_port</span><span class="token punctuation">></span></span>9009<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>interserver_http_port</span><span class="token punctuation">></span></span></code></pre><p>请确保所有节点都使用相同的端口，并将 <code>interserver_http_host</code> 设置为每个节点的 IP 地址或主机名。完成更改后，重启 ClickHouse 服务器以使更改生效。</p><ol start="3"><li><p>检查防火墙和安全组规则：确保所有节点上的防火墙和安全组规则允许节点之间的数据传输。可能需要打开 <code>interserver_http_port</code>（默认为 9009）之间的通信。</p></li><li><p>确保所有 ClickHouse 节点正在运行：登录到每个节点，检查 ClickHouse 服务是否正在运行。如果没有运行，需要启动 ClickHouse 服务。</p></li></ol><p>通过检查网络连接、确保 ClickHouse 配置正确以及检查并更新防火墙和安全组规则，可以解决这个问题。这将有助于确保 ClickHouse 集群中的副本能够顺利同步数据，从而提高分布式查询的性能和可靠性。</p><h3 id="2-20-Code-1002"><a href="#2-20-Code-1002" class="headerlink" title="2.20 Code:1002"></a>2.20 Code:1002</h3><pre class=" language-bash"><code class="language-bash">ERROR <span class="token punctuation">[</span>main<span class="token punctuation">]</span> execute clickhouse Query Errorru.yandex.clickhouse.except.ClickHouseUnknownException: ClickHouse exception, code: 1002, host: xxxx, port: 8123<span class="token punctuation">;</span> xxxx:8123 failed to respond</code></pre><ul><li>原因</li></ul><p>此错误表示在尝试执行 ClickHouse 查询时遇到了问题。错误消息为 “ClickHouse exception, code: 1002, host: xxxx, port: 8123; xxxx:8123 failed to respond”。这意味着连接到 ClickHouse 服务器的过程中出现了问题，服务器没有响应。</p><ul><li>解决</li></ul><ol><li>检查 ClickHouse 服务器是否正在运行：确保的 ClickHouse 服务器已启动并正在运行。可以使用以下命令检查 ClickHouse 服务器的状态：</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl status clickhouse-server</code></pre><p>如果服务器未运行，请使用以下命令启动它：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start clickhouse-server</code></pre><ol start="2"><li><p>检查网络连接：确保的客户端和 ClickHouse 服务器之间的网络连接没有问题。请检查防火墙设置以确保 8123 端口未被阻止。此外，请检查服务器的 IP 地址和端口号是否正确。</p></li><li><p>检查 ClickHouse 配置：查看 ClickHouse 配置文件（通常为 <code>/etc/clickhouse-server/config.xml</code>），以确保其中的设置正确。特别是，确保 <code>&lt;listen_host&gt;</code> 和 <code>&lt;listen_port&gt;</code> 设置正确。如果需要对配置文件进行任何更改，请保存更改并重新启动 ClickHouse 服务器以使更改生效。</p></li></ol><p>通过检查服务器状态、网络连接以及 ClickHouse 配置，可以解决与错误码 1002 相关的问题。这将确保能够成功连接到 ClickHouse 服务器并执行查询。</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 介绍&quot;&gt;&lt;/a&gt;1. 介绍&lt;/h2&gt;&lt;p&gt;ClickHouse 是一种高性能列式数据库管理系统，专为在线分析处理（OLAP）场景设计。它具有高查询性能、水平可扩展
      
    
    </summary>
    
    
      <category term="clickhouse" scheme="https://www.hnbian.cn/categories/clickhouse/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="olap" scheme="https://www.hnbian.cn/tags/olap/"/>
    
      <category term="clickhouse" scheme="https://www.hnbian.cn/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse 数据备份与恢复</title>
    <link href="https://www.hnbian.cn/posts/3f394133.html"/>
    <id>https://www.hnbian.cn/posts/3f394133.html</id>
    <published>2022-01-03T09:35:56.000Z</published>
    <updated>2023-05-12T07:31:28.821Z</updated>
    
    <content type="html"><![CDATA[<p>官网：<a href="https://clickhouse.tech/docs/en/operations/backup/" target="_blank" rel="noopener">https://clickhouse.tech/docs/en/operations/backup/</a></p><h2 id="1-手动备份与恢复数据"><a href="#1-手动备份与恢复数据" class="headerlink" title="1. 手动备份与恢复数据"></a>1. 手动备份与恢复数据</h2><p> ClickHouse 允许使用 ALTER TABLE … FREEZE PARTITION … 查询以创建表分区的本地副本。 这是利用硬链接(hardlink)到 /var/lib/clickhouse/shadow/ 文件夹中实现的，所以它通常不会 因为旧数据而占用额外的磁盘空间。 创建的文件副本不由 ClickHouse 服务器处理，所以不 需要任何额外的外部系统就有一个简单的备份。防止硬件问题，最好将它们远程复制到另一 个位置，然后删除本地副本。</p><h3 id="1-1-创建备份路径"><a href="#1-1-创建备份路径" class="headerlink" title="1.1 创建备份路径"></a>1.1 创建备份路径</h3><p>创建用于存放备份数据的目录 shadow</p><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">mkdir</span> -p /var/lib/clickhouse/shadow/<span class="token comment" spellcheck="true"># 如果目录存在，先清空目录下的数据</span></code></pre><h3 id="1-2-执行备份命令"><a href="#1-2-执行备份命令" class="headerlink" title="1.2 执行备份命令"></a>1.2 执行备份命令</h3><pre class=" language-bash"><code class="language-bash"><span class="token keyword">echo</span> -n <span class="token string">'alter table t_order_mt freeze'</span> <span class="token operator">|</span> clickhouse-client</code></pre><h3 id="1-3-将备份数据保存到其他路径"><a href="#1-3-将备份数据保存到其他路径" class="headerlink" title="1.3 将备份数据保存到其他路径"></a>1.3 将备份数据保存到其他路径</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#创建备份存储路径</span><span class="token function">sudo</span> <span class="token function">mkdir</span> -p /var/lib/clickhouse/backup/<span class="token comment" spellcheck="true">#拷贝数据到备份路径</span><span class="token function">sudo</span> <span class="token function">cp</span> -r /var/lib/clickhouse/shadow//var/lib/clickhouse/backup/my-backup-name<span class="token comment" spellcheck="true">#为下次备份准备，删除 shadow 下的数据</span><span class="token function">sudo</span> <span class="token function">rm</span> -rf /var/lib/clickhouse/shadow/*</code></pre><h3 id="恢复数据"><a href="#恢复数据" class="headerlink" title="恢复数据"></a>恢复数据</h3><ul><li>模拟删除备份过的表</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">' drop table t_order_mt '</span> <span class="token operator">|</span> clickhouse-client</code></pre><ul><li>重新创建表</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">cat</span> events.sql <span class="token operator">|</span> clickhouse-client</code></pre><ul><li>将备份复制到 detached 目录</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">cp</span> -rl backup/my-backup-name/1/store/cb1/cb176503-cd88-4ea8-8b17-6503cd888ea8/*data/default/t_order_mt/detached/</code></pre><p>ClickHouse 使用文件系统硬链接来实现即时备份，而不会导致 ClickHouse 服务停机（或 锁定）。这些硬链接可以进一步用于有效的备份存储。在支持硬链接的文件系统（例如本地 文件系统或 NFS）上，将 cp 与-l 标志一起使用（或将 rsync 与–hard-links 和–numeric-ids 标志 一起使用）以避免复制数据。</p><ul><li>执行 attach</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">'alter table t_order_mt attach partition 20220101'</span> <span class="token operator">|</span> clickhouse-client</code></pre><ul><li>查看数据</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">'select count() from t_order_mt'</span> <span class="token operator">|</span> clickhouse-client</code></pre><h2 id="2-使用-clickhouse-backup"><a href="#2-使用-clickhouse-backup" class="headerlink" title="2. 使用 clickhouse-backup"></a>2. 使用 clickhouse-backup</h2><p>上面的过程，我们可以使用 Clickhouse 的备份工具 clickhouse-backup 帮我们自动化实现。 </p><p>工具地址：<a href="https://github.com/AlexAkulov/clickhouse-backup/" target="_blank" rel="noopener">https://github.com/AlexAkulov/clickhouse-backup/</a></p><h3 id="2-1-部署clickhouse-backup"><a href="#2-1-部署clickhouse-backup" class="headerlink" title="2.1 部署clickhouse-backup"></a>2.1 部署clickhouse-backup</h3><h4 id="2-1-1-上传并安装"><a href="#2-1-1-上传并安装" class="headerlink" title="2.1.1 上传并安装"></a>2.1.1 上传并安装</h4><p>将 clickhouse-backup-1.0.0-1.x86_64.rpm 上传至/opt/software/目录下，安装：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> rpm -ivh clickhouse-backup-1.0.0-1.x86_64.rpm</code></pre><h4 id="2-1-2-配置文件"><a href="#2-1-2-配置文件" class="headerlink" title="2.1.2 配置文件"></a>2.1.2 配置文件</h4><pre class=" language-bash"><code class="language-bash"><span class="token function">cat</span> /etc/clickhouse-backup/config.yml</code></pre><h3 id="2-2-使用clickhouse-backup-备份数据"><a href="#2-2-使用clickhouse-backup-备份数据" class="headerlink" title="2.2 使用clickhouse-backup 备份数据"></a>2.2 使用clickhouse-backup 备份数据</h3><ul><li>查看可用命令</li></ul><pre class=" language-bash"><code class="language-bash">clickhouse-backup <span class="token function">help</span></code></pre><ul><li>显示要备份的表</li></ul><pre class=" language-bash"><code class="language-bash">clickhouse-backup tables</code></pre><ul><li>创建备份</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> clickhouse-backup create</code></pre><ul><li>查看现有的本地备份</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> clickhouse-backup list</code></pre><p>备份存储在中/var/lib/clickhouse/backup/BACKUPNAME。备份名称默认为时间戳，但是 可以选择使用–name 标志指定备份名称。备份包含两个目录：一个“metadata”目录，其中包 含重新创建架构所需的 DDL SQL 语句；以及一个“shadow”目录，其中包含作为 ALTER TABLE … FREEZE 操作结果的数据。</p><h3 id="2-3-使用clickhouse-backup-恢复数据"><a href="#2-3-使用clickhouse-backup-恢复数据" class="headerlink" title="2.3 使用clickhouse-backup 恢复数据"></a>2.3 使用clickhouse-backup 恢复数据</h3><ul><li>模拟删除备份过的表</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">'drop table t_order_rmt'</span> <span class="token operator">|</span> clickhouse-client</code></pre><ul><li>从备份还原</li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> clickhouse-backup restore 2022-01-01T23-14-50</code></pre><p>–schema 参数：只还原表结构。</p><p>–data 参数：只还原数据。</p><p>–table 参数：备份（或还原）特定表。也可以使用一个正则表达式，例如，针对特定的 数据库：–table=dbname.*。</p><h2 id="其他说明"><a href="#其他说明" class="headerlink" title="其他说明"></a>其他说明</h2><p>（1）API 文档：https : //github.com/AlexAkulov/clickhouse-backup#api </p><p>（2）注意事项：切勿更改文件夹/var/lib/clickhouse/backup 的权限，可能会导致数据损坏。 </p><p>（3）远程备份</p><p>较新版本才支持，需要设置 config 里的 s3 相关配置 </p><p>➢ 上传到远程存储：sudo clickhouse-backup upload xxxx </p><p>➢ 从远程存储下载：sudo clickhouse-backup download xxxx </p><p>➢ 保存周期： backups_to_keep_local，本地保存周期，单位天 backups_to_keep_remote，远程存储保存周期，单位天 0 均表示不删除</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;官网：&lt;a href=&quot;https://clickhouse.tech/docs/en/operations/backup/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://clickhouse.tech/docs/en/operations
      
    
    </summary>
    
    
      <category term="clickhouse" scheme="https://www.hnbian.cn/categories/clickhouse/"/>
    
    
      <category term="olap" scheme="https://www.hnbian.cn/tags/olap/"/>
    
      <category term="clickhouse" scheme="https://www.hnbian.cn/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>Hive 数据倾斜问题定位以及排查</title>
    <link href="https://www.hnbian.cn/posts/d47af904.html"/>
    <id>https://www.hnbian.cn/posts/d47af904.html</id>
    <published>2021-12-18T09:53:10.000Z</published>
    <updated>2023-05-04T09:36:01.916Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1. 背景介绍"></a>1. 背景介绍</h2><p>多数介绍数据倾斜的文章都是以大篇幅的理论为主，并没有给出具体的数据倾斜案例。当工作中遇到了倾斜问题，这些理论很难直接应用，导致我们面对倾斜时还是不知所措。</p><p>今天我们不扯大篇理论，直接以例子来实践，排查是否出现了数据倾斜，具体是哪段代码导致的倾斜，怎么解决这段代码的倾斜。</p><p>当执行过程中任务卡在 99%，大概率是出现了数据倾斜，但是通常我们的 SQL 很大，需要判断出是哪段代码导致的倾斜，才能利于我们解决倾斜。通过下面这个非常简单的例子来看下<strong>如何定位产生数据倾斜的代码</strong>。</p><h2 id="2-表结构描述"><a href="#2-表结构描述" class="headerlink" title="2. 表结构描述"></a>2. 表结构描述</h2><p>先来了解下这些表（表的字段非常多，此处仅列出我们需要的字段）中我们需要用的字段及数据量：</p><ul><li><strong>第一张表</strong>：user_info （用户信息表，用户粒度），数据量：1.02 亿，大小：13.9G，所占空间：41.7G（HDFS三副本）</li></ul><table><thead><tr><th align="center">字段名</th><th align="center">字段含义</th><th align="center">字段描述</th></tr></thead><tbody><tr><td align="center">userkey</td><td align="center">用户 key</td><td align="center">用户标识</td></tr><tr><td align="center">idno</td><td align="center">用户的身份证号</td><td align="center">用户实名认证时获取</td></tr><tr><td align="center">phone</td><td align="center">用户的手机号</td><td align="center">用户注册时的手机号</td></tr><tr><td align="center">name</td><td align="center">用户的姓名</td><td align="center">用户的姓名</td></tr></tbody></table><ul><li><strong>第二张表</strong>：user_active （用户活跃表，用户粒度），数据量：1.1 亿</li></ul><table><thead><tr><th align="center">字段名</th><th align="center">字段含义</th><th align="center">字段描述</th></tr></thead><tbody><tr><td align="center">userkey</td><td align="center">用户 key</td><td align="center">用户没有注册会分配一个 key</td></tr><tr><td align="center">user_active_at</td><td align="center">用户的最后活跃日期</td><td align="center">从埋点日志表中获取用户的最后活跃日期</td></tr></tbody></table><ul><li><strong>第三张表</strong>：user_intend（用户意向表，此处只取近六个月的数据，用户粒度），数据量：800 万</li></ul><table><thead><tr><th align="center">字段名</th><th align="center">字段含义</th><th align="center">字段描述</th></tr></thead><tbody><tr><td align="center">phone</td><td align="center">用户的手机号</td><td align="center">有意向的用户必须是手机号注册的用户</td></tr><tr><td align="center">intend_commodity</td><td align="center">用户意向次数最多的商品</td><td align="center">客户对某件商品意向次数最多</td></tr><tr><td align="center">intend_rank</td><td align="center">用户意向等级</td><td align="center">用户的购买意愿等级，级数越高，意向越大</td></tr></tbody></table><ul><li><strong>第四张表</strong>：user_order（用户订单表，此处只取近六个月的订单数据，用户粒度），数据量：640 万</li></ul><table><thead><tr><th align="center">字段名</th><th align="center">字段含义</th><th align="center">字段描述</th></tr></thead><tbody><tr><td align="center">idno</td><td align="center">用户的身份证号</td><td align="center">下订单的用户都是实名认证的</td></tr><tr><td align="center">order_num</td><td align="center">用户的订单次数</td><td align="center">用户近六个月下单次数</td></tr><tr><td align="center">order_amount</td><td align="center">用户的订单总金额</td><td align="center">用户近六个月下单总金额</td></tr></tbody></table><h2 id="3-需求"><a href="#3-需求" class="headerlink" title="3. 需求"></a>3. 需求</h2><p>需求非常简单，就是将以上四张表关联组成一张大宽表，大宽表中包含用户的基本信息，活跃情况，购买意向及此用户下订单情况。</p><h2 id="4-代码"><a href="#4-代码" class="headerlink" title="4. 代码"></a>4. 代码</h2><p>根据以上需求，我们以 user_info 表为基础表，将其余表关联为一个宽表，代码如下：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span>  <span class="token number">a</span><span class="token punctuation">.</span>userkey<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>idno<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>phone<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>name<span class="token punctuation">,</span>  <span class="token number">b</span><span class="token punctuation">.</span>user_active_at<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_commodity<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_rank<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_num<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_amount<span class="token keyword">from</span> user_info <span class="token number">a</span><span class="token keyword">left</span> <span class="token keyword">join</span> user_active <span class="token number">b</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>userkey <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>userkey<span class="token keyword">left</span> <span class="token keyword">join</span> user_intend <span class="token number">c</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>phone <span class="token operator">=</span> <span class="token number">c</span><span class="token punctuation">.</span>phone<span class="token keyword">left</span> <span class="token keyword">join</span> user_order <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>idno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>idno<span class="token punctuation">;</span></code></pre><p>执行上述语句，在执行到某个 job 时任务卡在 99%，如下图所示：</p><p><img src="https://images.hnbian.cn/202305041206290.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p>这时我们就应该考虑出现数据倾斜了。其实还有一种情况可能是数据倾斜，就是任务超时被杀掉，Reduce 处理的数据量巨大，在做 full gc 的时候，stop the world。导致响应超时，<strong>超出默认的 600 秒</strong>，任务被杀掉。报错信息一般如下：</p><pre class=" language-bash"><code class="language-bash">AttemptID:attempt_1624419433039_1569885_r_000000 Timed outafter 600 secs Container killed by the ApplicationMaster. Container killed onrequest. Exit code is 143 Container exited with a non-zero <span class="token keyword">exit</span> code 143</code></pre><h2 id="5-倾斜问题排查"><a href="#5-倾斜问题排查" class="headerlink" title="5. 倾斜问题排查"></a>5. 倾斜问题排查</h2><p>数据倾斜大多数都是大 key 问题导致的。如何判断是大 key 导致的问题，可以通过下面方法：</p><h3 id="5-1-通过时间判断"><a href="#5-1-通过时间判断" class="headerlink" title="5.1 通过时间判断"></a>5.1 通过时间判断</h3><p>如果某个 reduce 的时间比其他 reduce 时间长的多，如下图，大部分 task 在 1 分钟之内完成，只有 r_000000 这个 task 执行 20 多分钟了还没完成。</p><p><img src="https://images.hnbian.cn/202305041207748.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p><strong>注意</strong>：要排除两种情况：</p><ol><li>如果每个 reduce 执行时间差不多，都特别长，不一定是数据倾斜导致的，可能是 reduce 设置过少导致的。</li><li>有时候，某个 task 执行的节点可能有问题，导致任务跑的特别慢。这个时候，mapreduce 的推测执行，会重启一个任务。如果新的任务在很短时间内能完成，通常则是由于 task 执行节点问题导致的个别 task 慢。但是如果推测执行后的 task 执行任务也特别慢，那更说明该 task 可能会有倾斜问题。</li></ol><h3 id="5-2-通过任务-Counter-判断"><a href="#5-2-通过任务-Counter-判断" class="headerlink" title="5.2 通过任务 Counter 判断"></a>5.2 通过任务 Counter 判断</h3><p>Counter 会记录整个 job 以及每个 task 的统计信息。counter 的 url 一般类似：</p><pre class=" language-bash"><code class="language-bash">http://node1:8088/proxy/application_1624419433039_1569885/mapreduce/singletaskcounter/task_1624419433039_1569885_r_000000/org.apache.hadoop.mapreduce.FileSystemCounter</code></pre><p>通过输入记录数，普通的 task counter 如下，输入的记录数是 13 亿多:</p><p><img src="https://images.hnbian.cn/202305041416396.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p><img src="https://images.hnbian.cn/202305041416260.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p>而 task=000000 的 counter 如下，其输入记录数是 230 多亿。是其他任务的 100 多倍：</p><p><img src="https://images.hnbian.cn/202305041416823.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><h3 id="5-3-确定任务卡住的-stage"><a href="#5-3-确定任务卡住的-stage" class="headerlink" title="5.3 确定任务卡住的 stage"></a>5.3 确定任务卡住的 stage</h3><p>通过 jobname 确定 stage：</p><p><strong>一般 Hive 默认的 jobname 名称会带上 stage 阶段，如下通过 jobname 看到任务卡住的为 Stage-4：</strong></p><p><img src="https://images.hnbian.cn/202305041417787.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><ul><li><p>如果 jobname 是自定义的，那可能没法通过 jobname 判断 stage。需要借助于任务日志：</p><p>找到执行特别慢的那个 task，然后 Ctrl+F 搜索 “CommonJoinOperator: JOIN struct” 。Hive 在 join 的时候，会把 join 的 key 打印到日志中。如下：</p></li></ul><p><img src="https://images.hnbian.cn/202305041418935.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p>上图中的关键信息是：<strong>struct&lt;_col0:string, _col1:string, _col3:string&gt;</strong></p><p>这时候，需要参考该 SQL 的执行计划。通过参考执行计划，可以断定该阶段为 Stage-4 阶段：</p><p><img src="https://images.hnbian.cn/202305041419354.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><h3 id="5-4-确定-SQL-执行代码"><a href="#5-4-确定-SQL-执行代码" class="headerlink" title="5.4 确定 SQL 执行代码"></a>5.4 确定 SQL 执行代码</h3><p>确定了执行阶段，即 stage。通过执行计划，则可以判断出是执行哪段代码时出现了倾斜。还是从此图，这个 stage 中进行连接操作的表别名是 d：</p><p><img src="https://images.hnbian.cn/202305041419288.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p>就可以推测出是在执行下面红框中代码时出现了数据倾斜，因为这行的表的别名是 d：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span>  <span class="token number">a</span><span class="token punctuation">.</span>userkey<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>idno<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>phone<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>name<span class="token punctuation">,</span>  <span class="token number">b</span><span class="token punctuation">.</span>user_active_at<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_commodity<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_rank<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_num<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_amount<span class="token keyword">from</span> user_info <span class="token number">a</span><span class="token keyword">left</span> <span class="token keyword">join</span> user_active <span class="token number">b</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>userkey <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>userkey<span class="token keyword">left</span> <span class="token keyword">join</span> user_intend <span class="token number">c</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>phone <span class="token operator">=</span> <span class="token number">c</span><span class="token punctuation">.</span>phone<span class="token keyword">left</span> <span class="token keyword">join</span> user_order <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>idno <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>idno<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">-- 根据前面的信息可以推测出，数据清下是因为这个别名为 d 的表</span></code></pre><h2 id="6-数据倾斜原因"><a href="#6-数据倾斜原因" class="headerlink" title="6. 数据倾斜原因"></a>6. 数据倾斜原因</h2><p>我们知道了哪段代码引起的数据倾斜，就针对这段代码查看倾斜原因，看下这段代码的表中数据是否有异常。</p><p>本文的示例数据中 user_info 和 user_order 通过身份证号关联，检查发现 user_info 表中身份证号为空的有 7000 多万，原因就是这 7000 多万数据都分配到一个 reduce 去执行，导致数据倾斜。</p><h2 id="7-解决倾斜方法"><a href="#7-解决倾斜方法" class="headerlink" title="7. 解决倾斜方法"></a>7. 解决倾斜方法</h2><h3 id="7-1-针对当前原因解决"><a href="#7-1-针对当前原因解决" class="headerlink" title="7.1 针对当前原因解决"></a>7.1 针对当前原因解决</h3><ol><li>可以先把身份证号为空的去除之后再关联，最后按照 userkey 连接，因为 userkey 全部都是有值的：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">with</span> t1 <span class="token keyword">as</span><span class="token punctuation">(</span><span class="token keyword">select</span>  u<span class="token punctuation">.</span>userkey<span class="token punctuation">,</span>  o<span class="token punctuation">.</span><span class="token operator">*</span><span class="token keyword">from</span> user_info u<span class="token keyword">left</span> <span class="token keyword">join</span> user_order o<span class="token keyword">on</span> u<span class="token punctuation">.</span>idno <span class="token operator">=</span> o<span class="token punctuation">.</span>idno<span class="token keyword">where</span> u<span class="token punctuation">.</span>idno <span class="token operator">is</span> <span class="token operator">not</span> <span class="token boolean">null</span><span class="token comment" spellcheck="true">--是可以把where条件写在后面的，hive会进行谓词下推，先执行where条件在执行 left join</span><span class="token punctuation">)</span><span class="token keyword">select</span>  <span class="token number">a</span><span class="token punctuation">.</span>userkey<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>idno<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>phone<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>name<span class="token punctuation">,</span>  <span class="token number">b</span><span class="token punctuation">.</span>user_active_at<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_commodity<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_rank<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_num<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_amount<span class="token keyword">from</span> user_info <span class="token number">a</span><span class="token keyword">left</span> <span class="token keyword">join</span> user_active <span class="token number">b</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>userkey <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>userkey<span class="token keyword">left</span> <span class="token keyword">join</span> user_intend <span class="token number">c</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>phone <span class="token operator">=</span> <span class="token number">c</span><span class="token punctuation">.</span>phone<span class="token keyword">left</span> <span class="token keyword">join</span> t1 <span class="token number">d</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>userkey <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>userkey<span class="token punctuation">;</span></code></pre><ol start="2"><li>也可以这样，给身份证为空的数据赋个随机值，但是要注意随机值不能和表中的身份证号有重复：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span>  <span class="token number">a</span><span class="token punctuation">.</span>userkey<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>idno<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>phone<span class="token punctuation">,</span>  <span class="token number">a</span><span class="token punctuation">.</span>name<span class="token punctuation">,</span>  <span class="token number">b</span><span class="token punctuation">.</span>user_active_at<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_commodity<span class="token punctuation">,</span>  <span class="token number">c</span><span class="token punctuation">.</span>intend_rank<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_num<span class="token punctuation">,</span>  <span class="token number">d</span><span class="token punctuation">.</span>order_amount<span class="token keyword">from</span> user_info <span class="token number">a</span><span class="token keyword">left</span> <span class="token keyword">join</span> user_active <span class="token number">b</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>userkey <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>userkey<span class="token keyword">left</span> <span class="token keyword">join</span> user_intend <span class="token number">c</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>phone <span class="token operator">=</span> <span class="token number">c</span><span class="token punctuation">.</span>phone<span class="token keyword">left</span> <span class="token keyword">join</span> user_order <span class="token number">d</span> <span class="token keyword">on</span> nvl<span class="token punctuation">(</span><span class="token number">a</span><span class="token punctuation">.</span>idno<span class="token punctuation">,</span>concat<span class="token punctuation">(</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'idnumber'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">d</span><span class="token punctuation">.</span>idno<span class="token punctuation">;</span></code></pre><h3 id="7-2-过滤掉脏数据"><a href="#7-2-过滤掉脏数据" class="headerlink" title="7.2 过滤掉脏数据"></a>7.2 过滤掉脏数据</h3><p>如果大 key 是无意义的脏数据，直接过滤掉。本场景中大 key 有实际意义，不能直接过滤掉。</p><h3 id="7-3-数据预处理"><a href="#7-3-数据预处理" class="headerlink" title="7.3 数据预处理"></a>7.3 数据预处理</h3><p>数据做一下预处理（如上面例子，对 null 值赋一个随机值），尽量保证 join 的时候，同一个 key 对应的记录不要有太多。</p><h3 id="7-4-增加-reduce-个数"><a href="#7-4-增加-reduce-个数" class="headerlink" title="7.4 增加 reduce 个数"></a>7.4 增加 reduce 个数</h3><p>如果数据中出现了多个大 key，增加 reduce 个数，可以让这些大 key 落到同一个 reduce 的概率小很多。</p><p>配置 reduce 个数：<code>set mapred.reduce.tasks = 15;</code></p><h3 id="7-5-转换为-mapjoin"><a href="#7-5-转换为-mapjoin" class="headerlink" title="7.5 转换为 mapjoin"></a>7.5 转换为 mapjoin</h3><p>如果两个表 join 的时候，一个表为小表，可以用 mapjoin 做。</p><p>配置 mapjoin：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 是否开启自动mapjoin，默认是true</span><span class="token keyword">set</span> hive.auto.convert.join <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true"># mapjoin的表size大小</span><span class="token keyword">set</span> hive.mapjoin.smalltable.filesize<span class="token operator">=</span>100000000<span class="token punctuation">;</span></code></pre><h3 id="7-6-启用倾斜连接优化"><a href="#7-6-启用倾斜连接优化" class="headerlink" title="7.6 启用倾斜连接优化"></a>7.6 启用倾斜连接优化</h3><p>hive 中可以设置 <code>hive.optimize.skewjoin</code> 将一个 join sql 分为两个 job。</p><p>同时可以设置下 <code>hive.skewjoin.key</code>，此参数表示 join 连接的 key 的行数超过指定的行数，就认为该键是偏斜连接键，就对 join 启用倾斜连接优化。默认 key 的行数是 100000。</p><p>配置倾斜连接优化：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 启用倾斜连接优化</span><span class="token keyword">set</span> hive.optimize.skewjoin<span class="token operator">=</span>true<span class="token punctuation">;</span> <span class="token comment" spellcheck="true"># 超过20万行就认为该键是偏斜连接键</span><span class="token keyword">set</span> hive.skewjoin.key<span class="token operator">=</span>200000<span class="token punctuation">;</span> </code></pre><h3 id="7-7-调整内存设置"><a href="#7-7-调整内存设置" class="headerlink" title="7.7 调整内存设置"></a>7.7 调整内存设置</h3><p>适用于那些由于内存超限任务被 kill 掉的场景。通过加大内存起码能让任务跑起来，不至于被杀掉。该参数不一定会明显降低任务执行时间。</p><p>配置内存：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 设置reduce内存大小</span><span class="token keyword">set</span> mapreduce.reduce.memory.mb<span class="token operator">=</span>5120<span class="token punctuation">;</span> <span class="token keyword">set</span> mapreduce.reduce.java.opts<span class="token operator">=</span>-Xmx5000m -XX:MaxPermSize<span class="token operator">=</span>128m<span class="token punctuation">;</span></code></pre><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-背景介绍&quot;&gt;&lt;a href=&quot;#1-背景介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 背景介绍&quot;&gt;&lt;/a&gt;1. 背景介绍&lt;/h2&gt;&lt;p&gt;多数介绍数据倾斜的文章都是以大篇幅的理论为主，并没有给出具体的数据倾斜案例。当工作中遇到了倾斜问题，这些
      
    
    </summary>
    
    
      <category term="hive" scheme="https://www.hnbian.cn/categories/hive/"/>
    
    
      <category term="hive" scheme="https://www.hnbian.cn/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse 使用中遇见的异常</title>
    <link href="https://www.hnbian.cn/posts/5960127a.html"/>
    <id>https://www.hnbian.cn/posts/5960127a.html</id>
    <published>2021-12-07T08:30:37.000Z</published>
    <updated>2023-04-25T14:22:00.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Array-String-cannot-be-inside-Nullable-type"><a href="#1-Array-String-cannot-be-inside-Nullable-type" class="headerlink" title="1. Array(String) cannot be inside Nullable type"></a>1. Array(String) cannot be inside Nullable type</h2><pre class=" language-bash"><code class="language-bash">DB::Exception: Nested <span class="token function">type</span> Array<span class="token punctuation">(</span>String<span class="token punctuation">)</span> cannot be inside Nullable <span class="token function">type</span> <span class="token punctuation">(</span>version 20.4.6.53 <span class="token punctuation">(</span>official build<span class="token punctuation">))</span></code></pre><p>提示信息表示 ClickHouse 不支持将 Array 类型嵌套在 Nullable 类型中。在 ClickHouse 中，Array 类型的元素本身可以为 Nullable 类型，但不能将整个 Array 作为 Nullable 类型。要解决这个问题，请检查你的表结构和查询，确保没有将 Array 类型作为 Nullable 类型的一部分。</p><p>例如，如果你的表结构如下所示：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> example<span class="token punctuation">(</span>    id Int32<span class="token punctuation">,</span>    names Nullable<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>String<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span> <span class="token operator">=</span> MergeTree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">ORDER</span> <span class="token keyword">BY</span> id<span class="token punctuation">;</span></code></pre><p>这将会导致上述错误。正确的做法是将 Array 类型的元素设置为 Nullable 类型，如下所示：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> example<span class="token punctuation">(</span>    id Int32<span class="token punctuation">,</span>    names Array<span class="token punctuation">(</span>Nullable<span class="token punctuation">(</span>String<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span> <span class="token operator">=</span> MergeTree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">ORDER</span> <span class="token keyword">BY</span> id<span class="token punctuation">;</span></code></pre><p>或者将对应的数据转成String。如下：</p><pre class=" language-sql"><code class="language-sql">使用cast强转一下字段类型就行：<span class="token keyword">select</span> splitByString<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span>cast<span class="token punctuation">(</span>col <span class="token keyword">as</span> String<span class="token punctuation">)</span><span class="token punctuation">)</span> col <span class="token keyword">from</span> test</code></pre><h2 id="2-Cannot-convert-NULL-value-to-non-Nullable-type"><a href="#2-Cannot-convert-NULL-value-to-non-Nullable-type" class="headerlink" title="2. Cannot convert NULL value to non-Nullable type"></a>2. Cannot convert NULL value to non-Nullable type</h2><pre class=" language-bash"><code class="language-bash">DB::Exception: Cannot convert NULL value to non-Nullable type: <span class="token keyword">while</span> converting <span class="token function">source</span> column second_channel to destination column second_channel <span class="token punctuation">(</span>version 20.4.6.53 <span class="token punctuation">(</span>official build<span class="token punctuation">))</span></code></pre><p>在执行查询时，ClickHouse 遇到了一个无法将 NULL 值转换为非 Nullable 类型的问题。这通常是由于源数据中的 NULL 值无法直接存储到目标表的非 Nullable 类型列中。</p><p>要解决这个问题，你可以采取以下方法之一：</p><ol><li>修改目标表结构，将对应的列更改为 Nullable 类型。例如，如果你的表结构如下所示：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> example<span class="token punctuation">(</span>    id Int32<span class="token punctuation">,</span>    second_channel String<span class="token punctuation">)</span> <span class="token keyword">ENGINE</span> <span class="token operator">=</span> MergeTree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">ORDER</span> <span class="token keyword">BY</span> id<span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 修改为： </span><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> example<span class="token punctuation">(</span>    id Int32<span class="token punctuation">,</span>    second_channel Nullable<span class="token punctuation">(</span>String<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span> <span class="token operator">=</span> MergeTree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">ORDER</span> <span class="token keyword">BY</span> id<span class="token punctuation">;</span></code></pre><ol start="2"><li>在查询中处理 NULL 值，将其替换为默认值。例如，如果你的查询类似于以下内容：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> example <span class="token punctuation">(</span>id<span class="token punctuation">,</span> second_channel<span class="token punctuation">)</span><span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> second_channel<span class="token keyword">FROM</span> source_table<span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 可以使用 ifNull 或 coalesce 函数处理 NULL 值：</span><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> example <span class="token punctuation">(</span>id<span class="token punctuation">,</span> second_channel<span class="token punctuation">)</span><span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> ifNull<span class="token punctuation">(</span>second_channel<span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token keyword">FROM</span> source_table<span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 或 </span><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> example <span class="token punctuation">(</span>id<span class="token punctuation">,</span> second_channel<span class="token punctuation">)</span><span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> <span class="token keyword">coalesce</span><span class="token punctuation">(</span>second_channel<span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token keyword">FROM</span> source_table<span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 在插入数据时将所有 NULL 值替换为一个空字符串。根据需要替换为其他合适的默认值。</span></code></pre><h2 id="3-Memory-limit-total-exceeded"><a href="#3-Memory-limit-total-exceeded" class="headerlink" title="3. Memory limit (total) exceeded"></a>3. Memory limit (total) exceeded</h2><pre class=" language-bash"><code class="language-bash">DB::Exception: Memory limit <span class="token punctuation">(</span>total<span class="token punctuation">)</span> exceeded: would use 113.20 GiB <span class="token punctuation">(</span>attempt to allocate chunk of 134200512 bytes<span class="token punctuation">)</span>, maximum: 113.14 GiB: While executing CreatingSetsTransform. <span class="token punctuation">(</span>version 20.4.6.53 <span class="token punctuation">(</span>official build<span class="token punctuation">))</span></code></pre><p>这个错误表示在执行查询时，ClickHouse 遇到了一个内存限制问题。服务器尝试使用超过最大允许内存的内存，导致异常。在这种情况下，尝试分配了 134,200,512 字节的内存，但最大允许值为 113.14 GiB。</p><p>要解决这个问题，可以采取以下方法之一：</p><ol><li>调整 ClickHouse 服务器配置以增加内存限制。可以在 <code>config.xml</code> 文件中找到 <code>max_memory_usage</code> 参数，并增加其值。例如：</li></ol><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>yandex</span><span class="token punctuation">></span></span>    ...    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>profiles</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>default</span><span class="token punctuation">></span></span>            ...            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>max_memory_usage</span><span class="token punctuation">></span></span>130000000000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>max_memory_usage</span><span class="token punctuation">></span></span>            ...        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>default</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>profiles</span><span class="token punctuation">></span></span>    ...<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>yandex</span><span class="token punctuation">></span></span></code></pre><p>上面的配置将最大内存使用限制设置为 130 GB。请确保的服务器有足够的内存来支持这个更改。</p><ol><li>优化查询以减少内存使用。这可能包括减少查询中的数据量、使用更少的 JOIN 操作、减少聚合操作或使用更精确的数据类型。例如，可以尝试在查询中添加更多的过滤条件以减少处理的数据量。</li><li>如果可能的话，尝试将查询拆分为多个较小的查询。这可以通过将数据拆分为多个表或表分区来实现，然后执行针对这些较小表或分区的单独查询。这将有助于降低单个查询的内存需求。</li><li>在适当的情况下，还可以考虑将数据预先聚合或使用材化视图。这将使查询更加高效，并减少内存需求。</li></ol><p>通过采用上述方法之一，应该能够解决因内存限制而导致的异常。请注意，在调整内存限制时确保不要超过服务器可用的物理内存，以免导致其他问题。</p><h2 id="4-Table-columns-structure-in-ZooKeeper-is-different"><a href="#4-Table-columns-structure-in-ZooKeeper-is-different" class="headerlink" title="4. Table columns structure in ZooKeeper is different"></a>4. Table columns structure in ZooKeeper is different</h2><pre class=" language-bash"><code class="language-bash">DB::Exception: Table columns structure <span class="token keyword">in</span> ZooKeeper is different from local table structure <span class="token punctuation">(</span>version 20.12.3.3 <span class="token punctuation">(</span>official build<span class="token punctuation">))</span></code></pre><p>此异常表示在 ClickHouse 分布式表中，ZooKeeper 中的表结构与本地表结构不一致。这可能是由于表结构在集群中的不同节点上发生了变化，但这些更改尚未同步到所有节点。</p><p>要解决这个问题，可以采取以下步骤：</p><ol><li>首先，检查集群中的所有节点，确保它们都在运行相同版本的 ClickHouse。不同版本的 ClickHouse 可能会导致表结构不一致的问题。</li><li>确定哪个节点的表结构是最新的或正确的。然后，将正确的表结构从该节点导出为 SQL 文件。可以使用 <code>SHOW CREATE TABLE</code> 查询来获取表结构：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SHOW</span> <span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> your_table_name<span class="token punctuation">;</span></code></pre><ol start="2"><li>使用上一步中导出的 SQL 文件，在集群中的其他节点上更新表结构。这可以通过在其他节点上运行 <code>ALTER TABLE</code> 查询来实现。如果有任何新增的列，请使用 <code>ADD COLUMN</code> 子句；如果有任何更改的列，请使用 <code>MODIFY COLUMN</code> 子句。例如：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> your_table_name    <span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> new_column_name Column_Type<span class="token punctuation">,</span>    <span class="token keyword">MODIFY</span> <span class="token keyword">COLUMN</span> existing_column_name New_Column_Type<span class="token punctuation">;</span></code></pre><ol start="3"><li>在集群中的所有节点上运行 <code>SYSTEM SYNC REPLICA your_table_name;</code> 命令，以确保所有节点与 ZooKeeper 同步。例如：</li></ol><pre class=" language-sql"><code class="language-sql">SYSTEM SYNC REPLICA your_table_name<span class="token punctuation">;</span></code></pre><ol start="4"><li>请确保所有节点上的表结构现在都是一致的，可以使用 <code>SHOW CREATE TABLE</code> 查询在每个节点上检查表结构。</li></ol><h2 id="5-Too-many-parts-300"><a href="#5-Too-many-parts-300" class="headerlink" title="5. Too many parts (300)."></a>5. Too many parts (300).</h2><pre class=" language-bash"><code class="language-bash">Too many parts <span class="token punctuation">(</span>300<span class="token punctuation">)</span>. Merges are processing significantly slower than inserts<span class="token punctuation">..</span>.</code></pre><p>这个异常表明 ClickHouse 表中的写入数量过多，导致合并操作比插入操作慢很多。这种情况可能会导致性能下降和磁盘空间占用过高。要解决这个问题，可以尝试以下方法：</p><ol><li><p><strong>调整表分区策略</strong>：根据业务需求和数据访问模式，对表进行适当的分区。合理的分区策略可以减少每个分区内的部分数量，从而提高合并的速度。</p></li><li><p><strong>调整表的索引粒度</strong>：索引粒度越小，每个部分的行数越多，合并操作就越快。但是，较小的索引粒度可能会导致查询性能下降。可以通过更改表设置 <code>index_granularity</code> 来调整索引粒度。</p></li><li><p><strong>优化插入操作</strong>：尽量将数据批量插入，而不是逐条插入。批量插入可以减少生成的部分数量，从而减轻合并操作的压力。</p></li><li><p><strong>手动触发合并操作</strong>：可以手动触发某些分区的合并操作，以减少部分数量。使用 <code>OPTIMIZE TABLE</code> 查询来合并指定分区：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">OPTIMIZE</span> <span class="token keyword">TABLE</span> your_table_name <span class="token keyword">PARTITION</span> partition_id<span class="token punctuation">;</span></code></pre></li><li><p><strong>检查磁盘性能</strong>：如果磁盘性能较差，合并操作可能会受到影响。检查磁盘性能，并确保为 ClickHouse 配置了足够的 IOPS。</p></li><li><p><strong>检查系统资源</strong>：确保 ClickHouse 服务器具有足够的 CPU、内存和磁盘空间来处理合并操作。如果资源不足，可能需要升级硬件配置或优化 ClickHouse 配置。</p></li><li><p><strong>调整 ClickHouse 配置</strong>：可以尝试调整 ClickHouse 配置中与合并相关的参数，例如 <code>max_bytes_to_merge_at_min_space_in_pool</code> 和 <code>background_pool_size</code>。这些参数可以影响合并操作的速度和资源占用。</p></li></ol><h2 id="6-Connection-reset-by-peer-while-reading"><a href="#6-Connection-reset-by-peer-while-reading" class="headerlink" title="6. Connection reset by peer, while reading"></a>6. Connection reset by peer, while reading</h2><pre class=" language-bash"><code class="language-bash">DB::NetException: Connection reset by peer, <span class="token keyword">while</span> reading from socket xxx<span class="token comment" spellcheck="true"># clickhouse-server进程自己挂掉</span></code></pre><p><code>DB::NetException: Connection reset by peer</code> 这个异常通常表示 ClickHouse 在尝试从远程服务器读取数据时，远程服务器关闭了连接。以下是一些建议的解决方法：</p><ol><li><p><strong>检查网络连接</strong>：确保 ClickHouse 服务器与远程服务器之间的网络连接稳定且没有阻塞。可以尝试使用 <code>ping</code> 或 <code>traceroute</code> 命令来检查网络连接。</p></li><li><p><strong>检查远程服务器状态</strong>：确保远程服务器正在运行，且 ClickHouse 服务正常。可以通过查看服务器的日志或监控工具来检查服务器状态。</p></li><li><p><strong>调整 ClickHouse 超时设置</strong>：如果确定网络连接和远程服务器状态正常，可以尝试调整 ClickHouse 的超时设置。例如，可以增加 <code>receive_timeout</code> 和 <code>send_timeout</code> 参数的值。在 ClickHouse 配置文件中，可以设置这些参数：</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>receive_timeout</span><span class="token punctuation">></span></span>300<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>receive_timeout</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>send_timeout</span><span class="token punctuation">></span></span>300<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>send_timeout</span><span class="token punctuation">></span></span></code></pre><p>请注意，需要根据具体情况调整超时值。</p></li><li><p><strong>检查并发查询限制</strong>：确保没有达到 ClickHouse 的并发查询限制。如果并发查询过多，可能导致服务器资源耗尽并关闭连接。可以通过调整 <code>max_concurrent_queries</code> 参数来设置并发查询的最大限制。例如，在 ClickHouse 配置文件中：</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>max_concurrent_queries</span><span class="token punctuation">></span></span>100<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>max_concurrent_queries</span><span class="token punctuation">></span></span></code></pre><p>根据硬件和性能需求调整这个值。</p></li><li><p><strong>查看 ClickHouse 日志</strong>：查看 ClickHouse 服务器的日志，以获取有关异常的更多详细信息。日志文件通常位于 <code>/var/log/clickhouse-server/</code> 目录中。</p></li></ol><h2 id="7-follower从leader同步文件时超时"><a href="#7-follower从leader同步文件时超时" class="headerlink" title="7. follower从leader同步文件时超时"></a>7. follower从leader同步文件时超时</h2><pre class=" language-bash"><code class="language-bash">zookeeper的snapshot文件太大，follower从leader同步文件时超时</code></pre><p>原因：clickhouse对zookeeper的依赖非常的重，表的元数据信息，每个数据块的信息，每次插入的时候，数据同步的时候，都需要和zookeeper进行交互，存储的数据非常的多。</p><p>ZooKeeper 的 snapshot 文件过大可能导致从属节点（follower）在与领导节点（leader）同步时超时。要解决这个问题，可以尝试以下方法：</p><ol><li><p><strong>调整 ZooKeeper 配置</strong>：修改 ZooKeeper 配置文件（通常位于 <code>/etc/zookeeper/conf/zoo.cfg</code>），增加以下配置项，以延长同步超时时间：</p><pre><code>makefileCopy codesyncLimit=10</code></pre><p><code>syncLimit</code> 的值以 tickTime（默认为 2000 毫秒）为单位。将 <code>syncLimit</code> 增加到一个较大的值可以为从属节点提供更多的时间来同步 snapshot。</p><p>修改配置后，重启 ZooKeeper 服务：</p><pre><code>Copy codesudo systemctl restart zookeeper</code></pre></li><li><p><strong>减小 snapshot 大小</strong>：通过删除不必要的数据或将数据移动到其他 ZooKeeper 集群，减小 snapshot 文件的大小。</p></li><li><p><strong>定期清理 ZooKeeper</strong>：ZooKeeper 提供了一个名为 <code>autopurge</code> 的功能，可以定期清理旧的事务日志和 snapshot。在 ZooKeeper 配置文件中启用它，并设置合适的清理间隔：</p><pre><code>Copy codeautopurge.snapRetainCount=3autopurge.purgeInterval=1</code></pre><p>这里的配置表示保留最近的 3 个 snapshot，每隔 1 天执行一次自动清理。</p><p>启用 <code>autopurge</code> 之后，重启 ZooKeeper 服务。</p></li><li><p><strong>手动清理旧的 snapshot</strong>：如果仍然遇到问题，可以手动删除旧的 snapshot。这些文件通常位于 <code>/var/lib/zookeeper/version-2/</code> 目录中。在删除任何文件之前，请确保备份这些文件以防止数据丢失。</p></li></ol><h2 id="8-”read-only-mode”，插入失败"><a href="#8-”read-only-mode”，插入失败" class="headerlink" title="8. ”read only mode”，插入失败"></a>8. ”read only mode”，插入失败</h2><pre class=" language-bash"><code class="language-bash">分布式clickhouse表处于”read only mode”，插入失败</code></pre><p>在 ClickHouse 分布式表处于 “read-only mode” 时插入数据会失败。这种情况通常是由于某些配置问题或资源限制导致的。要解决此问题，请按照以下步骤进行操作：</p><ol><li><p><strong>检查本地表</strong>：分布式表实际上是一个虚拟表，它将数据插入到底层的本地表。确保本地表的状态正常，没有任何损坏或错误。可以使用 <code>OPTIMIZE TABLE</code> 和 <code>ALTER TABLE ... DETACH PARTITION</code>、<code>ATTACH PARTITION</code> 等命令来修复潜在的问题。</p></li><li><p><strong>检查磁盘空间</strong>：确保 ClickHouse 服务器上有足够的磁盘空间。磁盘空间不足可能导致表处于只读模式。可以通过清理旧的日志文件、备份和不再需要的数据来释放磁盘空间。</p></li><li><p><strong>查看 ClickHouse 配置</strong>：检查 ClickHouse 配置文件（通常位于 <code>/etc/clickhouse-server/config.xml</code>），确保没有任何错误或错误的设置。特别是检查 <code>&lt;readonly&gt;</code> 配置项，确保它的值设置为 0。</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>readonly</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>readonly</span><span class="token punctuation">></span></span></code></pre></li><li><p><strong>检查 ZooKeeper 配置</strong>：分布式表依赖于 ZooKeeper 服务。确保 ZooKeeper 服务配置正确，并且 ClickHouse 服务器可以访问它。检查 ClickHouse 配置文件中的 <code>&lt;zookeeper&gt;</code> 部分，确保所有设置正确。</p></li><li><p><strong>重启 ClickHouse 服务</strong>：在检查并解决潜在问题后，尝试重启 ClickHouse 服务。</p><pre><code>sudo systemctl restart clickhouse-server</code></pre></li><li><p><strong>查看 ClickHouse 日志</strong>：查看 ClickHouse 服务器的日志，以获取有关异常的更多详细信息。日志文件通常位于 <code>/var/log/clickhouse-server/</code> 目录中。</p></li></ol><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-Array-String-cannot-be-inside-Nullable-type&quot;&gt;&lt;a href=&quot;#1-Array-String-cannot-be-inside-Nullable-type&quot; class=&quot;headerlink&quot; title=&quot;1.
      
    
    </summary>
    
    
      <category term="clickhouse" scheme="https://www.hnbian.cn/categories/clickhouse/"/>
    
    
      <category term="exception" scheme="https://www.hnbian.cn/tags/exception/"/>
    
      <category term="olap" scheme="https://www.hnbian.cn/tags/olap/"/>
    
      <category term="clickhouse" scheme="https://www.hnbian.cn/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>关于 HDFS 中小文件的处理方式</title>
    <link href="https://www.hnbian.cn/posts/cbaf5de7.html"/>
    <id>https://www.hnbian.cn/posts/cbaf5de7.html</id>
    <published>2021-11-14T03:10:01.000Z</published>
    <updated>2023-05-29T07:12:21.750Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>在Hadoop应用过程中，处理小文件问题是一项常见的挑战。由于HDFS主要针对大型数据集（M字节以上）设计，大量小文件的出现可能导致Namenode内存使用效率下降、RPC调用速度减慢、block扫描处理速度降低，从而影响整个应用层的性能。本文旨在阐明小文件存储问题的定义，并探讨解决小文件问题的方法和策略。</p><h2 id="2-什么是小文件"><a href="#2-什么是小文件" class="headerlink" title="2. 什么是小文件"></a>2. 什么是小文件</h2><p>小文件是指比 HDFS 默认的 block 大小（默认配置为 128MB）明显小的文件。需要注意的是，在 HDFS 上有一些小文件是不可避免的。这些文件如库 jars、XML 配置文件、临时暂存文件等。但当小文件变的大量，以至于集群中小文件成为主流，此时就需要对小文件进行治理，治理的目标是让文件大小尽可能接近 HDFS block 大小，或HDFS block 大小的倍数。</p><p>Hadoop 的存储层和应用层的设计并不是为了在大量小文件的情况下高效运行。在说到这个问题的意义之前，我们先来回顾一下 HDFS 是如何存储文件的。</p><p>在 HDFS 中数据和元数据是独立的实体。文件被分割成 block，这些 block 被存储在 DataNode 的本地文件系统中，并在整个集群中复制。HDFS 命名空间树和相关的元数据作为对象保存在 NameNode 的内存中（会持久化到磁盘上），每个对象一般占用大约 150 个字节。</p><p>下面的两个方案说明了小文件的问题。</p><ul><li>方案 1（1 个 192M 的大文件）</li></ul><p><img src="https://images.hnbian.cn/202305012353981.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="方案一"></p><p>其中 inode（索引节点）是文件系统中的一个重要概念，用于存储关于文件或目录的元数据。在HDFS（Hadoop分布式文件系统）中，每个文件都有一个对应的inode。一个文件的inode包含了关于该文件的一些重要信息，如文件大小、权限、创建时间、修改时间、所有者等。</p><p>当我们在文件系统中创建、修改或访问一个文件时，操作系统会使用inode来查找和管理这个文件。在HDFS中，1个文件的inode表示的是该文件所对应的inode，用于存储和管理文件的元数据。</p><ul><li>方案 2（192 个小文件，每个 1M 的小文件）。</li></ul><p><img src="https://images.hnbian.cn/202305020007152.png?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt></p><p>从上面的图示中可以看到， 同样是 192M 的文件，一个大文件与一堆小文件相比，在 Namenode 堆上需要的内存相差 100 倍以上。</p><h2 id="3-对存储层的影响"><a href="#3-对存储层的影响" class="headerlink" title="3. 对存储层的影响"></a>3. 对存储层的影响</h2><p>当 NameNode 重启时，它必须将文件系统元数据从本地磁盘加载到内存中。这意味着，如果 NameNode 的元数据很大，重启速度会非常慢。NameNode 还必须跟踪集群上的 block 位置的变化，太多的小文件也会导致 NameNode 在 DataNode 耗尽磁盘上的数据空间之前，就先耗尽内存中的元数据空间。DataNode 还会通过网络向 NameNode 报告块的变化；更多的 block 意味着要通过网络发送更多的元数据变更。</p><p>更多的文件意味着更多的读取请求需要请求 NameNode，这可能最终会堵塞 NameNode 的容量，增加 RPC 队列和处理延迟，进而导致性能和响应能力下降。按照经验，RPC 工作负载接近 40K~50K 的 RPCs/s 是比较高的。</p><h2 id="4-对应用层的影响"><a href="#4-对应用层的影响" class="headerlink" title="4. 对应用层的影响"></a>4. 对应用层的影响</h2><p>一般来说，在通过 Impala 这样的 Ad HOC SQL 引擎或 MapReduce 或 Spark 这样的应用框架运行计算时，拥有大量的小文件会产生更多的磁盘请求。</p><h3 id="4-1-MapReduce-Spark"><a href="#4-1-MapReduce-Spark" class="headerlink" title="4.1 MapReduce / Spark"></a>4.1 MapReduce / Spark</h3><p>在 Hadoop 中，block 是可以进行计算的最细粒度的数据单位。因此，它影响着一个应用的吞吐量。在 MapReduce 中，每读取一个 block 都需要 1 个 Map Container。因此，小文件会降低性能，增加应用开销，因为每个任务都需要自己的 JVM 进程。</p><p>对于 Spark 来说，小文件也是类似的，在 Spark 中，每个“map”相当于 Spark 任务在执行器中每次读取和处理一个分区。每个分区默认情况下是一个 block。这意味着，如果你有很多小文件，每个文件都在不同的分区中读取，这将导致大量的任务开销。</p><p>另外，MapReduce 作业也会创建空间文件，如_SUCCESS 和 _FAILURE，用于标记 MapReduce 任务的 finish 状态。这些文件仍然会在 Namenode 中注册为一个 inode item，如前文所述，每个 使用 150 个字节。清除这些文件的一个简单有效的方法是使用下面的 HDFS 命令：</p><pre class=" language-bash"><code class="language-bash">hdfs dfs -ls -R <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'<span class="token variable">$1</span> !~ /^d/ &amp;&amp; <span class="token variable">$5</span> == "0" { print <span class="token variable">$8</span> }'</span> <span class="token operator">|</span> <span class="token function">xargs</span> -n100 hdfs dfs –rm</code></pre><p>命令说明：</p><p><code>hdfs dfs -ls -R</code>：这个命令用于递归地列出HDFS中的所有文件和目录，包括子目录下的文件。<code>-ls</code>表示列出文件和目录的信息，<code>-R</code>表示递归地进行操作。</p><p><code>|</code>：这是管道操作符，用于将上一个命令的输出作为下一个命令的输入。</p><p><code>awk &#39;$1 !~ /^d/ &amp;&amp; $5 == &quot;0&quot; { print $8 }&#39;</code>：这个命令使用Awk工具对<code>hdfs dfs -ls -R</code>的输出进行处理。它通过匹配条件来筛选出不是目录（即文件）且文件大小为0的行，并提取第8个字段（即文件路径）进行输出。</p><p><code>|</code>：再次使用管道操作符将上一个命令的输出作为下一个命令的输入。</p><p><code>xargs -n100 hdfs dfs –rm</code>：这个命令使用xargs工具将前面命令的输出作为参数，并对每100个文件执行<code>hdfs dfs -rm</code>命令，即删除这些文件。</p><p><code>xargs -n100</code>：指定每次传递给下一个命令的参数数量为100。</p><p><code>hdfs dfs -rm</code>：删除HDFS中指定的文件。</p><p>这个命令的功能是在HDFS中递归地列出所有文件，并找到文件大小为0的文件。然后，通过批量处理的方式，每次删除100个大小为0的文件。这个命令对于清理HDFS中的空文件非常有用。</p><p>注意：</p><ol><li><p>这个命令将把这些文件移动到.Trash 位置（HDFS 回收站开启的情况下），一旦 Trash 清理策略生效，这些文件也将随之删除。</p></li><li><p>如果有应用程序对这些文件有依赖性，删除这些文件可能会导致应用程序失败。</p></li></ol><h2 id="5-小文件是如何产生的"><a href="#5-小文件是如何产生的" class="headerlink" title="5. 小文件是如何产生的"></a>5. 小文件是如何产生的</h2><h3 id="5-1-流式数据处理"><a href="#5-1-流式数据处理" class="headerlink" title="5.1 流式数据处理"></a>5.1 流式数据处理</h3><p>spark streaming/flink 等流式计算框架或者 bacth 的数据计算，最终可能会一段时间内产生大量的小文件。对于流式数据的近乎实时的要求，小的 timewindow（每隔几分钟或几个小时）数量较小，就会生产很多小文件。</p><h3 id="5-2-拥有大量-map-reduce-的任务"><a href="#5-2-拥有大量-map-reduce-的任务" class="headerlink" title="5.2 拥有大量 map/reduce 的任务"></a>5.2 拥有大量 map/reduce 的任务</h3><p>MapReduce 任务，如果有大量的 map 和 reduce task，在 HDFS 上生成的文件基本上与 map 数量（对于 Map-Only 作业）或 reduce 数量（对于 MapReduce 作业）成正比。大量的 reducer 没有足够的数据被写到 HDFS 上，会把结果集稀释成很小的文件，因为每个 reducer 只写一个文件。按照同样的思路，数据倾斜也会产生类似的效果，即大部分数据被路由到一个或几个 reduce，让其他的 reduce 写的数据很少，导致文件变小。</p><h3 id="5-3-过度分区表"><a href="#5-3-过度分区表" class="headerlink" title="5.3 过度分区表"></a>5.3 过度分区表</h3><p>过度分区表是指每个分区的数据量很小（&lt;256 MB）的 Hive 表。Hive Metastore Server (HMS) API 调用开销会随着表拥有的分区数量而增加。这反过来会导致性能下降。在这种情况下，应该考虑表的分区设计并减少分区粒度。 </p><h3 id="5-4-Spark-过度并行化"><a href="#5-4-Spark-过度并行化" class="headerlink" title="5.4 Spark 过度并行化"></a>5.4 Spark 过度并行化</h3><p>在 Spark 作业中，根据写任务中提到的分区数量，每个分区会写一个新文件。这类似于 MapReduce 框架中的每个 reduce 任务都会创建一个新文件。Spark 分区越多，写入的文件就越多。控制分区的数量来减少小文件的生成。</p><h3 id="5-5-文件格式和压缩"><a href="#5-5-文件格式和压缩" class="headerlink" title="5.5 文件格式和压缩"></a>5.5 文件格式和压缩</h3><p>出于小文件治理的目的，我们更推荐使用非 TexFile 的序列化存储方法。</p><h2 id="6-如何识别出小文件"><a href="#6-如何识别出小文件" class="headerlink" title="6. 如何识别出小文件"></a>6. 如何识别出小文件</h2><h3 id="6-1-fsImage"><a href="#6-1-fsImage" class="headerlink" title="6.1 fsImage"></a>6.1 fsImage</h3><p>因为 NameNode 存储了所有与文件相关的元数据，所以它将整个命名空间保存在内存中，而 fsimage 是 NameNode 的本地本机文件系统中的持久化记录。因此，我们可以通过分析 fsimage 来找出文件的元信息。</p><ul><li>fsimage 中可用的字段有：</li></ul><table><thead><tr><th>字段名</th><th>描述</th></tr></thead><tbody><tr><td>Path</td><td>文件或目录在文件系统中的位置</td></tr><tr><td>Replication</td><td>文件在HDFS中的副本数量</td></tr><tr><td>ModificationTime</td><td>文件或目录的最后修改时间</td></tr><tr><td>AccessTime</td><td>文件或目录的最后访问时间</td></tr><tr><td>PreferredBlockSize</td><td>文件在HDFS中的数据块的大小</td></tr><tr><td>BlocksCount</td><td>文件所包含的数据块数量</td></tr><tr><td>FileSize</td><td>文件的大小</td></tr><tr><td>NSQUOTA</td><td>目录中文件和目录的最大数量限制</td></tr><tr><td>DSQUOTA</td><td>目录中文件和目录的总大小限制</td></tr><tr><td>Permission</td><td>文件或目录的访问权限</td></tr><tr><td>UserName</td><td>文件或目录的所有者用户名</td></tr><tr><td>GroupName</td><td>文件或目录所属的用户组名</td></tr></tbody></table><p>通常可以采用以下方法来解析 fsimage</p><p>拷贝 Namenode 数据目录下的 fsimage 文件到其他目录，然后执行：</p><pre class=" language-bash"><code class="language-bash">hdfs oiv -p Delimited -delimiter <span class="token string">"|"</span> -t /tmp/tmpdir/ -i fsimage_copy -o fsimage.out</code></pre><p>这个命令是HDFS中的 “oiv” 命令，用于从 fsimage 文件中提取元数据信息并以指定的格式进行输出。下面是对该命令的解释：</p><ul><li><code>hdfs oiv</code>: 这是用于运行HDFS Offline Image Viewer（离线镜像查看器）的HDFS命令。</li><li><code>-p Delimited</code>: 这是 -oiv 命令的一个选项，指定输出格式为分隔符分隔的格式，以便将元数据字段以自定义的分隔符进行分隔。</li><li><code>-delimiter &quot;|&quot;</code>: 这是指定分隔符的参数，该示例中使用竖线（|）作为分隔符。</li><li><code>-t /tmp/tmpdir/</code>: 这是指定临时目录的参数，用于存储临时文件。</li><li><code>-i fsimage_copy</code>: 这是指定输入的fsimage文件的参数，即要处理的fsimage文件的路径和名称。</li><li><code>-o fsimage.out</code>: 这是指定输出文件的参数，即处理后的元数据将写入的输出文件的路径和名称。</li></ul><p>综合起来，这个命令的作用是从指定的fsimage文件中提取元数据信息，并将元数据以分隔符分隔的格式输出到指定的输出文件中（使用竖线作为分隔符）。输出文件的路径和名称是”fsimage.out”，临时文件将存储在”/tmp/tmpdir/“目录中。</p><p>请注意，此命令需要在Hadoop集群的环境中运行，并且需要适当的权限才能访问和处理HDFS的元数据。</p><p>更多关于 hdfs oiv 命令的使用，可以查看 useage。</p><h3 id="6-2-fsck"><a href="#6-2-fsck" class="headerlink" title="6.2 fsck"></a>6.2 fsck</h3><p>使用 fsck 命令扫描当前的 HDFS 目录并保存扫描后的信息可以查看当前 HDFS 中的小文件</p><pre class=" language-bash"><code class="language-bash">hdfs <span class="token function">fsck</span> / -files -blocks -locations <span class="token operator">></span> fsck_output.txt</code></pre><p> <code>/</code> 是要扫描的HDFS目录的路径，这里使用根目录 <code>/</code> 作为示例，您可以根据实际情况替换为其他目录路径。<br><code>-files</code> 参数用于打印文件的详细信息。<br><code>-blocks</code> 参数用于打印数据块的详细信息。<br><code>-locations</code> 参数用于打印数据块的位置信息。<br><code>fsck_output.txt</code> 是保存扫描结果的输出文件名，您可以根据需要自定义输出文件的路径和名称。</p><p>执行完命令后，<code>fsck</code>命令将扫描指定的HDFS目录，并将扫描结果保存到指定的输出文件中。</p><p>可以使用文本编辑器或命令行查看保存的输出文件来检查扫描后的信息。</p><p>请注意，执行<code>fsck</code>命令需要适当的权限来访问和扫描HDFS目录。此外，<code>fsck</code>命令可能会执行较长时间，具体取决于HDFS集群的规模和文件系统的大小。在大型集群中，考虑生产环境的稳定性，不建议使用 fsck 命令，因为它会带来额外的开销。</p><h2 id="7-如何处理小文件"><a href="#7-如何处理小文件" class="headerlink" title="7. 如何处理小文件"></a>7. 如何处理小文件</h2><h3 id="7-1-流式写入"><a href="#7-1-流式写入" class="headerlink" title="7.1 流式写入"></a>7.1 流式写入</h3><p>调整流式写入的时间窗口是一个不错的选择，如果业务对实时性要求很高，那么可以根据数据类型（非结构化 vs 结构化）、append/update 频率和数据使用模式（随机读取 vs 聚合），HBase 和 Kudu 是存储层的更好选择。对于已经存在的小文件，也可以设置定期的 Job 对这些文件进行压缩、合并，以减少文件量和文件数量。</p><h3 id="7-2-过度分区表"><a href="#7-2-过度分区表" class="headerlink" title="7.2 过度分区表"></a>7.2 过度分区表</h3><p>在决定分区的粒度时，要考虑到每个分区的数据量。为有大文件的分区做计划（用 Parquet 的话，约 256MB 或更大），即使这意味着有较少的粒度分区，例如每月而不是每天的分区。对于数据量小的表（几百 MB），可以考虑创建一个非分区表。</p><h3 id="7-3-Spark-过度并行化"><a href="#7-3-Spark-过度并行化" class="headerlink" title="7.3 Spark 过度并行化"></a>7.3 Spark 过度并行化</h3><p>在 Spark 中向 HDFS 写入数据时，在向磁盘写入数据前要重新分区或聚合分区。这些语句中定义的分区数量将决定输出文件的数量。强烈建议检查 Spark 作业的输出，并验证创建的文件数量和实现的吞吐量。</p><h3 id="7-4-使用merge-命令压缩"><a href="#7-4-使用merge-命令压缩" class="headerlink" title="7.4 使用merge 命令压缩"></a>7.4 使用merge 命令压缩</h3><p>hadoop 本身提供 merge 命令，当然用户也可以自行编写工具实现。</p><p>Hadoop提供的<code>merge</code>命令用于合并多个小文件为一个或多个更大的文件。这对于减少小文件数量和提高文件系统性能非常有用。下面是对<code>merge</code>命令的介绍：</p><pre class=" language-bash"><code class="language-bash">hadoop fs -getmerge <span class="token operator">&lt;</span>src<span class="token operator">></span> <span class="token operator">&lt;</span>localdst<span class="token operator">></span> <span class="token punctuation">[</span>addnl<span class="token punctuation">]</span></code></pre><p>参数说明：</p><ul><li><code>&lt;src&gt;</code>：指定要合并的源目录或文件的路径。它可以是HDFS中的目录或文件。</li><li><code>&lt;localdst&gt;</code>：指定合并后的文件的本地目标路径，即保存合并后文件的本地文件系统路径。</li><li><code>[addnl]</code>：可选参数，当指定该参数时，将追加源文件名作为每个合并后的文件的一部分，以在合并后的文件中保留原始文件的边界。</li></ul><p>注意事项：</p><ul><li><code>&lt;src&gt;</code>参数可以指定一个目录，此时会递归地合并目录下的所有文件。</li><li><code>&lt;src&gt;</code>参数也可以指定多个文件，以空格分隔，这样可以将这些文件合并成一个更大的文件。</li><li>如果<code>&lt;localdst&gt;</code>指定的本地文件已存在，将会覆盖该文件。</li></ul><p>使用示例：</p><ol><li>合并HDFS中的多个文件到本地文件：</li></ol><pre class=" language-bash"><code class="language-bash">hadoop fs -getmerge /user/hadoop/input /home/user/mergedfile</code></pre><p>上述命令将HDFS中<code>/user/hadoop/input</code>目录下的所有文件合并为一个文件，并保存到本地文件系统的<code>/home/user/mergedfile</code>路径下。</p><ol start="2"><li>合并HDFS目录下的多个文件到本地文件，并保留源文件名：</li></ol><pre class=" language-bash"><code class="language-bash">hadoop fs -getmerge /user/hadoop/input /home/user/mergedfile <span class="token boolean">true</span></code></pre><p>该命令将目录<code>/user/hadoop/input</code>下的所有文件合并为一个文件，并在合并后的文件中保留源文件的边界。</p><p>使用<code>merge</code>命令可以方便地将多个小文件合并成一个更大的文件，有助于提高Hadoop文件系统的性能和效率。</p><h3 id="7-5-使用-Hive-对数据进行压缩"><a href="#7-5-使用-Hive-对数据进行压缩" class="headerlink" title="7.5 使用 Hive 对数据进行压缩"></a>7.5 使用 Hive 对数据进行压缩</h3><p>如果你有一个现有的 Hive 表有大量的小文件，那么可以通过以下设置来重写这个表（parquet 格式）。关于 Hive 压缩可以查阅其他文档获取更详细的信息。</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 启用对输出结果进行压缩。当查询产生输出结果时，将使用压缩算法对结果进行压缩，以减少存储空间。</span><span class="token keyword">set</span> hive.exec.compress.output<span class="token operator">=</span>true<span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 设置Parquet文件的压缩算法为Snappy。Parquet是一种列式存储格式，该参数指定使用Snappy算法对Parquet文件进行压缩。</span><span class="token keyword">set</span> parquet.compression<span class="token operator">=</span>snappy<span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 启用Map端文件合并。当执行Hive查询时，Map任务在输出文件到HDFS时，会尝试将多个小文件合并成更大的文件，以减少存储和IO开销。</span><span class="token keyword">set</span> hive.merge.mapfiles<span class="token operator">=</span>true<span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 启用MapReduce端文件合并。类似于上一个参数，但这个参数控制在MapReduce任务的输出阶段进行文件合并。</span><span class="token keyword">set</span> hive.merge.mapredfiles<span class="token operator">=</span>true<span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 设置合并小文件的平均大小。当启用文件合并时，Hive将尝试合并小于该大小的文件。在这个例子中，平均大小为128MB。</span><span class="token keyword">set</span> hive.merge.smallfiles.avgsize<span class="token operator">=</span>134217728<span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 设置每个任务执行合并操作的最大数据大小。当合并操作发生时，Hive将尝试合并小于该大小的文件。</span><span class="token keyword">set</span> hive.merge.size.per.task <span class="token operator">=</span> 268435456<span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 启用动态分区排序优化。当对分区表进行查询时，启用此参数可以提高性能，通过对查询结果进行排序来优化分区读取。</span><span class="token keyword">set</span> hive.optiming.sort.dynamic.partition <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 设置Parquet文件的块大小。Parquet文件由多个块组成，该参数指定每个块的大小。在这个例子中，块大小为256MB。</span><span class="token keyword">set</span> parquet.blocksize<span class="token operator">=</span> 268435456<span class="token punctuation">;</span><span class="token comment" spellcheck="true"># 设置HDFS文件系统的块大小。HDFS将数据划分为多个块进行存储，该参数指定每个块的大小。在这个例子中，块大小为256MB。</span><span class="token keyword">set</span> dfs.block.size<span class="token operator">=</span>268435456<span class="token punctuation">;</span></code></pre><p>关于 Hive 配置属性的详细信息可以在 Apache Hive 官方页面上找到，这里再提供一些重新数据的方法。</p><p>CREATE TABLE AS SELECT（CTAS）对于一个非分区表会比较方便。</p><p>你也可以先运行 CREATE TABLE LIKE (CTL)来复制一个表结构，然后使用 INSERT OVERWRITE SELECT 语句将数据从源表加载数据到目标表。</p><p>注意：如果在没有定义静态分区名的情况下插入数据，需要在 Hive 中启用非严格的动态分区模式，可以通过设置</p><pre class=" language-bash"><code class="language-bash"><span class="token keyword">set</span> hive.exec.dynamic.partition.mode<span class="token operator">=</span>non-strict<span class="token comment" spellcheck="true"># 用于设置动态分区模式的行为。动态分区是指在将数据加载到分区表时，根据数据中的某个列的值自动创建分区。</span></code></pre><p>分区列必须是选择语句中的最后一列，这样动态分区才能在这种情况下工作。此外，也可以直接使用 mapred.reduce.tasks 设置来配置 reduce 的数量。创建的文件数量将等于使用的减速器数量。设置一个最佳的减速器值取决于写入的数据量。</p><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>提前规避要好于事后补救，在任务开发以及表设计的前期尽可能考虑小文件问题尤为重要，因为事后修改任务或者修改表带来业务失败的概率会大得多。此外，小文件治理也是一个长期的过程，对于一个生产集群，定期的进行小文件治理是必要的。</p><p>数据资产中心将小文件数量或比例转化成指数关联到库，表，目录上。用户可以根据库，表，目录等信息发现小文件产生的任务，对小文件的产生进行追本溯源，然后通过调整任务参数等手段从源头进行治理。</p><p>追本溯源可以从源头切断小文件的产生，但是这个是比较理想化的情况，现实中存在很多场景无法在源头进行调整。网易数据资产中心也提供了定期触发的小文件合并策略，在策略识别到小文件过多的表或者目录上进行小文件合并。对于已经产生了很多小文件的表或目录提供主动合并的手段将小文件进行合并。</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 介绍&quot;&gt;&lt;/a&gt;1. 介绍&lt;/h2&gt;&lt;p&gt;在Hadoop应用过程中，处理小文件问题是一项常见的挑战。由于HDFS主要针对大型数据集（M字节以上）设计，大量小文件的
      
    
    </summary>
    
    
      <category term="hdfs" scheme="https://www.hnbian.cn/categories/hdfs/"/>
    
    
      <category term="hdfs" scheme="https://www.hnbian.cn/tags/hdfs/"/>
    
      <category term="hadoop" scheme="https://www.hnbian.cn/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Atlas web UI 使用介绍</title>
    <link href="https://www.hnbian.cn/posts/e581a712.html"/>
    <id>https://www.hnbian.cn/posts/e581a712.html</id>
    <published>2021-10-25T03:25:18.000Z</published>
    <updated>2023-07-19T15:15:18.903Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-导入hive元数据"><a href="#1-导入hive元数据" class="headerlink" title="1. 导入hive元数据"></a>1. 导入hive元数据</h2><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hnode3 hook-bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># pwd</span>/usr/hdp/current/atlas-server/hook-bin<span class="token punctuation">[</span>root@hnode3 hook-bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>总用量 16-rwxr-xr-x. 1 atlas hadoop 4180 12月  6 2018 import-hbase.sh-rwxr-xr-x. 1 atlas hadoop 4101 12月  6 2018 import-hive.shroot@hnode3 hook-bin<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sh import-hive.sh</span>Using Hive configuration directory <span class="token punctuation">[</span>/etc/hive/conf<span class="token punctuation">]</span>Log <span class="token function">file</span> <span class="token keyword">for</span> <span class="token function">import</span> is /usr/hdp/current/atlas-server/logs/import-hive.logSLF4J: Class path contains multiple SLF4J bindings.<span class="token punctuation">..</span>.Enter username <span class="token keyword">for</span> atlas :- admin <span class="token comment" spellcheck="true"># atlas 登录账号 admin</span>Enter password <span class="token keyword">for</span> atlas :- <span class="token comment" spellcheck="true"># atlas 登录密码</span><span class="token punctuation">..</span>.<span class="token punctuation">..</span>.<span class="token punctuation">..</span>.<span class="token punctuation">..</span>.  HiveMetaStoreBridge - Successfully imported 45 tables from database sysHive Meta Data imported successfully<span class="token operator">!</span><span class="token operator">!</span><span class="token operator">!</span> <span class="token comment" spellcheck="true"># 导入成功</span></code></pre><h2 id="2-搜索"><a href="#2-搜索" class="headerlink" title="2. 搜索"></a>2. 搜索</h2><h3 id="2-1-基本搜索"><a href="#2-1-基本搜索" class="headerlink" title="2.1 基本搜索"></a>2.1 基本搜索</h3><p><img src="https://images.hnbian.cn/FkeCqVqzrabndzyeErw-R68ErOrE?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="基本搜索"></p><h3 id="2-2-进阶搜索"><a href="#2-2-进阶搜索" class="headerlink" title="2.2 进阶搜索"></a>2.2 进阶搜索</h3><p><img src="https://images.hnbian.cn/FuO-RYBKAePPfFzjDW_HwFWTZ8J9?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="进阶搜索"></p><h2 id="3-分类"><a href="#3-分类" class="headerlink" title="3. 分类"></a>3. 分类</h2><p><img src="https://images.hnbian.cn/FsMp5Eoa1rG4YIBVxDzRjBTdS3hU?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="水平展示分类"></p><p><img src="https://images.hnbian.cn/FnqcUm37mNkXZiV1Jn6wZPzwZzln?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="属性展示分类"></p><h3 id="3-1-新建分类"><a href="#3-1-新建分类" class="headerlink" title="3.1 新建分类"></a>3.1 新建分类</h3><p><img src="https://images.hnbian.cn/FvWHwTksqxGdWzcBcRzSwaBYADQS?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="新建分类"></p><h3 id="3-2-分类的搜所与删除"><a href="#3-2-分类的搜所与删除" class="headerlink" title="3.2 分类的搜所与删除"></a>3.2 分类的搜所与删除</h3><p><img src="https://images.hnbian.cn/FoemAmOYeBSfXhcGKBNnnaqFTe55?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="分类的删除与搜所"></p><h2 id="4-术语表"><a href="#4-术语表" class="headerlink" title="4. 术语表"></a>4. 术语表</h2><h3 id="4-1-创建术语表"><a href="#4-1-创建术语表" class="headerlink" title="4.1 创建术语表"></a>4.1 创建术语表</h3><p><img src="https://images.hnbian.cn/Ft08zXHhJ3qpq85Fw7nF6JPuMvCI?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="新建术语表"></p><h3 id="4-2-创建术语"><a href="#4-2-创建术语" class="headerlink" title="4.2 创建术语"></a>4.2 创建术语</h3><p><img src="https://images.hnbian.cn/FnS3JtGaumZ1dLDCPPmRxorolkuj?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建术语"></p><p><img src="https://images.hnbian.cn/FnMABpmq9dK9RvWqFGg6Ul_vIp6R?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建术语"></p><h3 id="4-3-创建种类"><a href="#4-3-创建种类" class="headerlink" title="4.3 创建种类"></a>4.3 创建种类</h3><p><img src="https://images.hnbian.cn/FpnlLXPwruSaDhfyUdOCpWJERQ4F?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建种类"></p><h3 id="4-4-为术语添加种类"><a href="#4-4-为术语添加种类" class="headerlink" title="4.4 为术语添加种类"></a>4.4 为术语添加种类</h3><p>为术语添加的种类只能在同一个术语表下，其他术语表下的种类在添加时是看不到的。<br><img src="https://images.hnbian.cn/FqWY0SJZNXaIaci4SZPXlVaPTYO3?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="为术语添加种类"></p><h2 id="5-hive-相关实体介绍"><a href="#5-hive-相关实体介绍" class="headerlink" title="5. hive 相关实体介绍"></a>5. hive 相关实体介绍</h2><h3 id="5-1-hive-数据库实体"><a href="#5-1-hive-数据库实体" class="headerlink" title="5.1 hive 数据库实体"></a>5.1 hive 数据库实体</h3><h4 id="5-1-1-数据库实体概览"><a href="#5-1-1-数据库实体概览" class="headerlink" title="5.1.1 数据库实体概览"></a>5.1.1 数据库实体概览</h4><p><img src="https://images.hnbian.cn/FppaZ3hnzaAjz4tdaI_Sys4SFwlN?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 数据库实体概览"></p><h4 id="5-1-2-数据库实体关系"><a href="#5-1-2-数据库实体关系" class="headerlink" title="5.1.2 数据库实体关系"></a>5.1.2 数据库实体关系</h4><p><img src="https://images.hnbian.cn/Fj2WSe5OcKkQbAvnMEy2iQdSNxs4?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 数据库实体关系1"><br><img src="https://images.hnbian.cn/FqRqJvPg_zTDaaVxdgGMuR3VirI_?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 数据库实体关系2"></p><h4 id="5-1-3-数据库实体分类"><a href="#5-1-3-数据库实体分类" class="headerlink" title="5.1.3 数据库实体分类"></a>5.1.3 数据库实体分类</h4><p><img src="https://images.hnbian.cn/Fn3zItVxy7_oNdRReS_ChnsHxugf?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 数据库实体分类"></p><h4 id="5-1-4-数据库实体审计"><a href="#5-1-4-数据库实体审计" class="headerlink" title="5.1.4 数据库实体审计"></a>5.1.4 数据库实体审计</h4><p><img src="https://images.hnbian.cn/FuM9qQxZZzxfqA6yaKiNd9yNjPxk?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 数据库实体审计"></p><h4 id="5-1-5-数据库实体数据表"><a href="#5-1-5-数据库实体数据表" class="headerlink" title="5.1.5 数据库实体数据表"></a>5.1.5 数据库实体数据表</h4><p><img src="https://images.hnbian.cn/FgPNL-worNCoHs1i2ZCbVSxiBImy?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 数据库实体数据表"></p><h3 id="5-2-hive-表实体"><a href="#5-2-hive-表实体" class="headerlink" title="5.2 hive 表实体"></a>5.2 hive 表实体</h3><h4 id="5-2-1-hive-表实体概览"><a href="#5-2-1-hive-表实体概览" class="headerlink" title="5.2.1 hive 表实体概览"></a>5.2.1 hive 表实体概览</h4><p><img src="https://images.hnbian.cn/FjXURb-NX_ZR6Jja7x73yZWuyQxm?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 表实体概览"></p><h4 id="5-2-2-hive-表实体血缘关系"><a href="#5-2-2-hive-表实体血缘关系" class="headerlink" title="5.2.2 hive 表实体血缘关系"></a>5.2.2 hive 表实体血缘关系</h4><p><img src="https://images.hnbian.cn/FhThEwvrDxdGvv3snHn95g7198FD?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 表实体血缘关系"></p><h4 id="5-2-3-hive-表实体关系"><a href="#5-2-3-hive-表实体关系" class="headerlink" title="5.2.3 hive 表实体关系"></a>5.2.3 hive 表实体关系</h4><p><img src="https://images.hnbian.cn/Fv2ZLus2QA31pLgF4iHMz8Kb_3_C?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 表实体关系"></p><h4 id="5-2-4-hive-表实体分类"><a href="#5-2-4-hive-表实体分类" class="headerlink" title="5.2.4 hive 表实体分类"></a>5.2.4 hive 表实体分类</h4><p><img src="https://images.hnbian.cn/FukjNBJlH-Y3xLWVJPfzir4GP8Fa?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 表实体分类"></p><h4 id="5-2-5-hive-表实体审计"><a href="#5-2-5-hive-表实体审计" class="headerlink" title="5.2.5 hive 表实体审计"></a>5.2.5 hive 表实体审计</h4><p><img src="https://images.hnbian.cn/FspRccTgY0aOfmgHIL5mzXDWeBsw?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 表实体审计"></p><h4 id="5-2-6-hive-表实体表结构"><a href="#5-2-6-hive-表实体表结构" class="headerlink" title="5.2.6 hive 表实体表结构"></a>5.2.6 hive 表实体表结构</h4><p><img src="https://images.hnbian.cn/Frt0NYN02uIl1Hp2rEuNWcJ0Qpe7?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 表实体表结构"></p><h3 id="5-3-hive-列实体"><a href="#5-3-hive-列实体" class="headerlink" title="5.3 hive 列实体"></a>5.3 hive 列实体</h3><h4 id="5-3-1-hive-列实体属性"><a href="#5-3-1-hive-列实体属性" class="headerlink" title="5.3.1 hive 列实体属性"></a>5.3.1 hive 列实体属性</h4><h4 id="5-3-2-hive-列实体关系"><a href="#5-3-2-hive-列实体关系" class="headerlink" title="5.3.2 hive 列实体关系"></a>5.3.2 hive 列实体关系</h4><h4 id="5-3-3-hive-列实体血缘"><a href="#5-3-3-hive-列实体血缘" class="headerlink" title="5.3.3 hive 列实体血缘"></a>5.3.3 hive 列实体血缘</h4><h4 id="5-3-4-hive-列实体分类"><a href="#5-3-4-hive-列实体分类" class="headerlink" title="5.3.4 hive 列实体分类"></a>5.3.4 hive 列实体分类</h4><h4 id="5-3-5-hive-列实体审计"><a href="#5-3-5-hive-列实体审计" class="headerlink" title="5.3.5 hive 列实体审计"></a>5.3.5 hive 列实体审计</h4><h3 id="5-4-hive-存储描述实体"><a href="#5-4-hive-存储描述实体" class="headerlink" title="5.4 hive 存储描述实体"></a>5.4 hive 存储描述实体</h3><h4 id="5-4-1-hive-存储描述实体属性"><a href="#5-4-1-hive-存储描述实体属性" class="headerlink" title="5.4.1 hive 存储描述实体属性"></a>5.4.1 hive 存储描述实体属性</h4><p><img src="https://images.hnbian.cn/Fg_v4Can0JYXenz46oMdtW38Jnw3?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 存储描述实体属性"></p><h4 id="5-4-2-hive-存储描述实体关系"><a href="#5-4-2-hive-存储描述实体关系" class="headerlink" title="5.4.2 hive 存储描述实体关系"></a>5.4.2 hive 存储描述实体关系</h4><p><img src="https://images.hnbian.cn/Fjrm-rq5a7LLzn2Fe6J12Yh_7eFJ?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 存储描述实体关系"></p><h4 id="5-4-3-hive-存储描述实体分类"><a href="#5-4-3-hive-存储描述实体分类" class="headerlink" title="5.4.3 hive 存储描述实体分类"></a>5.4.3 hive 存储描述实体分类</h4><p><img src="https://images.hnbian.cn/FlcaSUIBK1CAC1SDFI8f0xPuEl_E?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 存储描述实体分类"></p><h4 id="5-4-4-hive-存储描述实体审计"><a href="#5-4-4-hive-存储描述实体审计" class="headerlink" title="5.4.4 hive 存储描述实体审计"></a>5.4.4 hive 存储描述实体审计</h4><p><img src="https://images.hnbian.cn/FlhU6R_oY4kiOivhKZz26O0_MxQI?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 存储描述实体审计"></p><h4 id="5-5-hive-过程实体"><a href="#5-5-hive-过程实体" class="headerlink" title="5.5 hive 过程实体"></a>5.5 hive 过程实体</h4><h5 id="5-5-1-hive-过程实体属性"><a href="#5-5-1-hive-过程实体属性" class="headerlink" title="5.5.1 hive 过程实体属性"></a>5.5.1 hive 过程实体属性</h5><p><img src="https://images.hnbian.cn/FgBOyXKkxaEQAYsJm8tyIotfM4Bi?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 过程实体属性"></p><h5 id="5-5-2-hive-过程实体关系"><a href="#5-5-2-hive-过程实体关系" class="headerlink" title="5.5.2 hive 过程实体关系"></a>5.5.2 hive 过程实体关系</h5><p><img src="https://images.hnbian.cn/FiDxPlRbQcAxh7apsD3K2Okb_Md8?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 过程实体关系"></p><h5 id="5-5-3-hive-过程实体血缘"><a href="#5-5-3-hive-过程实体血缘" class="headerlink" title="5.5.3 hive 过程实体血缘"></a>5.5.3 hive 过程实体血缘</h5><p><img src="https://images.hnbian.cn/FmPUhrU6i5E1kcoh5syUA3XNRGZH?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 过程实体血缘"></p><h5 id="5-5-4-hive-过程实体分类"><a href="#5-5-4-hive-过程实体分类" class="headerlink" title="5.5.4 hive 过程实体分类"></a>5.5.4 hive 过程实体分类</h5><p><img src="https://images.hnbian.cn/FqAWyhTS85oLWXsG9sijYKjG4v47?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 过程实体分类"></p><h5 id="5-5-5-hive-过程实体审计"><a href="#5-5-5-hive-过程实体审计" class="headerlink" title="5.5.5 hive 过程实体审计"></a>5.5.5 hive 过程实体审计</h5><p><img src="https://images.hnbian.cn/FlAioY0bglZl8nTADNICOF2MPbNU?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="hive 过程实体审计"></p><h2 id="6-创建HBase-相关实体"><a href="#6-创建HBase-相关实体" class="headerlink" title="6. 创建HBase 相关实体"></a>6. 创建HBase 相关实体</h2><p><strong>在创建实体时，一些关联的实体都需要根据限定名去查找。</strong></p><p><img src="https://images.hnbian.cn/FuCwk4KMApy_5pcOM5XBFoQtScOo?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建实体"></p><h3 id="6-1-创建HBase-namespace实体"><a href="#6-1-创建HBase-namespace实体" class="headerlink" title="6.1 创建HBase namespace实体"></a>6.1 创建HBase namespace实体</h3><p><img src="https://images.hnbian.cn/FpYfZcDPJGdeKRk6eftZQcOhTVxH?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建HBase namespace实体"></p><h3 id="6-2-创建HBase-table实体"><a href="#6-2-创建HBase-table实体" class="headerlink" title="6.2 创建HBase table实体"></a>6.2 创建HBase table实体</h3><p><img src="https://images.hnbian.cn/FvFDwZMKDEvkDXl1pMOInLrpjMEW?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建HBase table实体"></p><h3 id="6-3-创建HBase-column-family实体"><a href="#6-3-创建HBase-column-family实体" class="headerlink" title="6.3 创建HBase column family实体"></a>6.3 创建HBase column family实体</h3><p><img src="https://images.hnbian.cn/FlmxfjM31OmmRZoVjzxe-2a7QiSf?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建HBase column family实体"></p><h3 id="6-4-创建HBase-column实体"><a href="#6-4-创建HBase-column实体" class="headerlink" title="6.4 创建HBase column实体"></a>6.4 创建HBase column实体</h3><p><img src="https://images.hnbian.cn/Fje8CGSyQPXMoxDuREtV8gKSnioh?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="创建HBase column实体"></p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-导入hive元数据&quot;&gt;&lt;a href=&quot;#1-导入hive元数据&quot; class=&quot;headerlink&quot; title=&quot;1. 导入hive元数据&quot;&gt;&lt;/a&gt;1. 导入hive元数据&lt;/h2&gt;&lt;pre class=&quot; language-bash&quot;&gt;&lt;code c
      
    
    </summary>
    
    
      <category term="ambari" scheme="https://www.hnbian.cn/categories/ambari/"/>
    
    
      <category term="atlas" scheme="https://www.hnbian.cn/tags/atlas/"/>
    
  </entry>
  
  <entry>
    <title>Atlas 架构与组件介绍</title>
    <link href="https://www.hnbian.cn/posts/1b46dd17.html"/>
    <id>https://www.hnbian.cn/posts/1b46dd17.html</id>
    <published>2021-10-24T08:15:51.000Z</published>
    <updated>2023-07-19T15:15:18.902Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Atlas-概述"><a href="#1-Atlas-概述" class="headerlink" title="1. Atlas 概述"></a>1. Atlas 概述</h2><p><a href="http://atlas.apache.org/" target="_blank" rel="noopener">Apache Atlas</a> 是Hadoop社区为解决Hadoop生态系统的元数据治理问题而产生的开源项目，它为Hadoop集群提供了包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理在内的元数据治理核心能力。用以构建其数据资源目录，对这些资产进行分类和管理，并为数据分析师和数据治理团队提供围绕这些数据资产的协作的功能。</p><p>Atlas 是一个可伸缩和可扩展的核心基础治理服务集合 ，使企业能够有效地和高效地满足 Hadoop 中的合规性要求，并允许与整个企业数据生态系统的集成。</p><p>Atlas支持各种Hadoop和非Hadoop元数据类型，并提供了丰富的REST API进行集成，对数据血缘的追溯达到了字段级别。</p><h2 id="2-Atlas-架构原理"><a href="#2-Atlas-架构原理" class="headerlink" title="2. Atlas 架构原理"></a>2. Atlas 架构原理</h2><p><img src="https://images.hnbian.cn/FquinYWJ3Y5fiFktlPY5BtNpqXQX?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" alt="Atlas 架构图"></p><h3 id="2-1-Metatada-Sources"><a href="#2-1-Metatada-Sources" class="headerlink" title="2.1 Metatada Sources"></a>2.1 Metatada Sources</h3><p>Atlas支持与许多元数据源的集成，将来还会添加更多集成。目前，Atlas 支持从以下数据源获取和管理元数据：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>Hive</td><td>通过hive bridge，atlas可以接入Hive的元数据，包括hive_db/hive_table/hive_column/hive_process</td></tr><tr><td>Sqoop</td><td>通过sqoop bridge，atlas可以接入关系型数据库的元数据，包括sqoop_operation_type/ sqoop_dbstore_usage/sqoop_process/sqoop_dbdatastore</td></tr><tr><td>Falcon</td><td>通过falcon bridge，atlas可以接入Falcon的元数据，包括falcon_cluster/falcon_feed/falcon_feed_creation/falcon_feed_replication/ falcon_process</td></tr><tr><td>Storm</td><td>通过storm bridge，atlas可以接入流式处理的元数据，包括storm_topology/storm_spout/storm_bolt</td></tr></tbody></table><p>Atlas集成大数据组件的元数据源需要实现以下两点：</p><ol><li>需要基于atlas的类型系统定义能够表达大数据组件元数据对象的元数据模型(例如Hive的元数据模型实现在org.apache.atlas.hive.model.HiveDataModelGenerator)</li><li>需要提供hook组件去从大数据组件的元数据源中提取元数据对象，实时侦听元数据的变更并反馈给atlas；</li></ol><h3 id="2-2-Apps"><a href="#2-2-Apps" class="headerlink" title="2.2 Apps"></a>2.2 Apps</h3><h4 id="2-2-1-Ranger-Tag-Based-Policies"><a href="#2-2-1-Ranger-Tag-Based-Policies" class="headerlink" title="2.2.1 Ranger Tag Based Policies"></a>2.2.1 Ranger Tag Based Policies</h4><p>Apache Ranger 是针对 Hadoop 生态系统的高级安全管理解决方案，与各种 Hadoop 组件具有广泛的集成。通过与 Atlas 集成，Ranger 允许安全管理员定义元数据驱动的安全策略，以实现有效的治理。 Ranger 是由 Atlas 通知的元数据更改事件的消费者。</p><h4 id="2-2-2-Admin-UI"><a href="#2-2-2-Admin-UI" class="headerlink" title="2.2.2 Admin UI"></a>2.2.2 Admin UI</h4><p>该组件是一个基于 Web 的应用程序，允许数据管理员和科学家发现和注释元数据。Admin UI提供了搜索界面和 类SQL的查询语言，可以用来查询由 Atlas 管理的元数据类型和对象。Admin UI 使用 Atlas 的 REST API 来构建其功能。</p><h4 id="2-2-3-Business-Taxonomy"><a href="#2-2-3-Business-Taxonomy" class="headerlink" title="2.2.3 Business Taxonomy"></a>2.2.3 Business Taxonomy</h4><p>从元数据源获取到 Atlas 的元数据对象主要是一种技术形式的元数据。为了增强可发现性和治理能力，Atlas 提供了一个业务分类界面，允许用户首先定义一组代表其业务域的业务术语，并将其与 Atlas 管理的元数据实体相关联。业务分类法是一种 Web 应用程序，目前是 Atlas Admin UI 的一部分，并且使用 REST API 与 Atlas 集成。<br>在HDP2.5中，Business Taxonomy是提供了Technical Preview版本，需要在Atlas &gt; Configs &gt; Advanced &gt; Custom application-properties中添加atlas.feature.taxonomy.enable=true并重启atlas服务来开启</p><h3 id="2-3-Intergration"><a href="#2-3-Intergration" class="headerlink" title="2.3 Intergration"></a>2.3 Intergration</h3><p>用户可以使用两种方法管理 Atlas 中的元数据：</p><h4 id="2-3-1-Messaging"><a href="#2-3-1-Messaging" class="headerlink" title="2.3.1 Messaging"></a>2.3.1 Messaging</h4><p>除了API之外，用户还可以选择使用基于Kafka的消息接口与Atlas集成。这对于将元数据对象传输到 Atlas 以及从 Atlas 使用可以构建应用程序的元数据更改事件都非常有用。如果希望使用与Atlas更松散耦合的集成，这可以允许更好的可扩展性、可靠性等，消息传递接口是特别有用的。Atlas 使用 Apache Kafka 作为通知服务器用于钩子和元数据通知事件的下游消费者之间的通信。事件由钩子(hook)和 Atlas 写到不同的 Kafka 主题。</p><p>ATLAS_HOOK: 来自各个组件的Hook的元数据通知事件通过写入到名为 ATLAS_HOOK的Kafka topic 发送到 Atlas.<br>ATLAS_ENTITIES：从Atlas到其他集成组件（如Ranger）的事件写入到名为ATLAS_ENTITIES的 Kafka topic</p><h4 id="2-3-2-API"><a href="#2-3-2-API" class="headerlink" title="2.3.2 API"></a>2.3.2 API</h4><p>Atlas的所有功能都可以通过REST API提供给最终用户，允许创建、更新和删除类型和实体。它也是查询和发现通过 Atlas 管理的类型和实体的主要方法。</p><h3 id="2-4-Core"><a href="#2-4-Core" class="headerlink" title="2.4 Core"></a>2.4 Core</h3><h4 id="2-4-1-Ingest-Export"><a href="#2-4-1-Ingest-Export" class="headerlink" title="2.4.1 Ingest/Export"></a>2.4.1 Ingest/Export</h4><p>Ingest 组件允许将元数据添加到Atlas。类似地，Export 组件暴露由 Atlas 检测到的元数据更改，以作为事件引发，消费者可以使用这些更改事件来实时响应元数据更改。</p><h4 id="2-4-2-Type-System"><a href="#2-4-2-Type-System" class="headerlink" title="2.4.2 Type System"></a>2.4.2 Type System</h4><p>Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为“类型” 的定义组成。“类型” （类）的实例被称为 “实体” 表示被管理的实际元数据对象。类型系统是一个组件，允许用户定义和管理类型和实体。由Atlas管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为实体(类对象，一条数据)。</p><h4 id="2-4-3-Graph-Engine"><a href="#2-4-3-Graph-Engine" class="headerlink" title="2.4.3 Graph Engine"></a>2.4.3 Graph Engine</h4><p>在内部，Atlas 通过使用图形模型管理元数据对象。以实现元数据对象之间的巨大灵活性和丰富的关系。图形引擎是负责在类型系统的类型和实体之间进行转换的组件，以及基础图形模型。除了管理图形对象之外，图形引擎还为元数据对象创建适当的索引，以便有效地搜索它们。</p><h4 id="2-4-4-JanusGraph"><a href="#2-4-4-JanusGraph" class="headerlink" title="2.4.4 JanusGraph"></a>2.4.4 JanusGraph</h4><p>图数据库，持久化的数据会保存在JanusGraph中。</p><h3 id="2-5-Medatada-Store"><a href="#2-5-Medatada-Store" class="headerlink" title="2.5 Medatada Store"></a>2.5 Medatada Store</h3><p>采用HBASE存储元数据。</p><h3 id="2-6-Index-Store"><a href="#2-6-Index-Store" class="headerlink" title="2.6 Index Store"></a>2.6 Index Store</h3><p>使用Solr 来创建索引。</p><h2 id="3-核心特性"><a href="#3-核心特性" class="headerlink" title="3. 核心特性"></a>3. 核心特性</h2><p>Apache Atlas为Hadoop的元数据治理提供了以下特性：</p><h3 id="3-1-数据分类"><a href="#3-1-数据分类" class="headerlink" title="3.1    数据分类"></a>3.1    数据分类</h3><p>为元数据导入或定义业务导向的分类注释<br>定义，注释，以及自动捕获数据集和底层元素之间的关系<br>导出元数据到第三方系统</p><h3 id="3-2-集中审计"><a href="#3-2-集中审计" class="headerlink" title="3.2    集中审计"></a>3.2    集中审计</h3><p>捕获与所有应用，过程以及与数据交互的安全访问信息<br>捕获执行，步骤，活动等操作的信息</p><h3 id="3-3-搜索与血缘"><a href="#3-3-搜索与血缘" class="headerlink" title="3.3    搜索与血缘"></a>3.3    搜索与血缘</h3><p>预定义的导航路径用来探索数据分类以及审计信息<br>基于文本的搜索特性来快速和准确的定位相关联的数据和审计事件<br>对数据集血缘关系的可视化浏览使用户可以下钻到操作，安全以及数据起源相关的信息</p><h3 id="3-4-安全与策略引擎"><a href="#3-4-安全与策略引擎" class="headerlink" title="3.4    安全与策略引擎"></a>3.4    安全与策略引擎</h3><p>基于数据分类模式，属性以及角色的运行时合理合规策略<br>基于分类-预测的高级策略定义以防止数据推导<br>基于cell的属性和值的行/列级别的masking</p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-Atlas-概述&quot;&gt;&lt;a href=&quot;#1-Atlas-概述&quot; class=&quot;headerlink&quot; title=&quot;1. Atlas 概述&quot;&gt;&lt;/a&gt;1. Atlas 概述&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://atlas.apache.org/&quot; t
      
    
    </summary>
    
    
      <category term="ambari" scheme="https://www.hnbian.cn/categories/ambari/"/>
    
    
      <category term="atlas" scheme="https://www.hnbian.cn/tags/atlas/"/>
    
  </entry>
  
</feed>
